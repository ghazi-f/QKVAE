{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Instanciating the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean length:  8.900745464443235  Quantiles .25, 0.5, 0.7, and 0.9 : [ 7.  8. 10. 13. 14. 15.] std: 2.6633922182479695 n_examples: 90011\nMean length:  8.924245452728362  Quantiles .25, 0.5, 0.7, and 0.9 : [ 7.  9. 10. 13. 14. 15.] std: 2.655226481623664 n_examples: 5003\nMean length:  8.9166  Quantiles .25, 0.5, 0.7, and 0.9 : [ 7.  9. 10. 13. 14. 15.] std: 2.6672166091264504 n_examples: 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words:  11895 , On device:  cuda\nLoss Type:  VAE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model at step 14784\nUnsupervised training examples:  90112\nUnsupervised val examples:  53376\nNumber of parameters:  23.14 M\nInference parameters:  03.26 M\nGeneration parameters:  21.41 M\nEmbedding parameters:  01.52 M\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import argparse\n",
    "\n",
    "from torch import device\n",
    "import torch\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "\n",
    "from data_prep import NLIGenData2, OntoGenData, HuggingYelp2\n",
    "\n",
    "from disentanglement_transformer.models import DisentanglementTransformerVAE as Model\n",
    "from disentanglement_transformer.h_params import DefaultTransformerHParams as HParams\n",
    "from disentanglement_transformer.graphs import *\n",
    "from components.criteria import *\n",
    "parser = argparse.ArgumentParser()\n",
    "from torch.nn import MultiheadAttention\n",
    "# Training and Optimization\n",
    "k, kz, klstm = 1, 8, 2\n",
    "parser.add_argument(\"--test_name\", default='unnamed', type=str)\n",
    "parser.add_argument(\"--data\", default='nli', choices=[\"nli\", \"ontonotes\", \"yelp\"], type=str)\n",
    "parser.add_argument(\"--max_len\", default=17, type=int)\n",
    "parser.add_argument(\"--batch_size\", default=128, type=int)\n",
    "parser.add_argument(\"--grad_accu\", default=1, type=int)\n",
    "parser.add_argument(\"--n_epochs\", default=10000, type=int)\n",
    "parser.add_argument(\"--test_freq\", default=32, type=int)\n",
    "parser.add_argument(\"--complete_test_freq\", default=160, type=int)\n",
    "parser.add_argument(\"--generation_weight\", default=1, type=float)\n",
    "parser.add_argument(\"--device\", default='cuda:0', choices=[\"cuda:0\", \"cuda:1\", \"cuda:2\", \"cpu\"], type=str)\n",
    "parser.add_argument(\"--embedding_dim\", default=128, type=int)#################\"\n",
    "parser.add_argument(\"--pretrained_embeddings\", default=False, type=bool)#################\"\n",
    "parser.add_argument(\"--z_size\", default=96*kz, type=int)#################\"\n",
    "parser.add_argument(\"--z_emb_dim\", default=192*k, type=int)#################\"\n",
    "parser.add_argument(\"--n_latents\", default=[16, 16, 16], nargs='+', type=int)#################\"\n",
    "parser.add_argument(\"--text_rep_l\", default=3, type=int)\n",
    "parser.add_argument(\"--text_rep_h\", default=192*k, type=int)\n",
    "parser.add_argument(\"--encoder_h\", default=192*k, type=int)#################\"\n",
    "parser.add_argument(\"--encoder_l\", default=2, type=int)#################\"\n",
    "parser.add_argument(\"--decoder_h\", default=192*k, type=int)\n",
    "parser.add_argument(\"--decoder_l\", default=2, type=int)#################\"\n",
    "parser.add_argument(\"--highway\", default=False, type=bool)\n",
    "parser.add_argument(\"--markovian\", default=True, type=bool)\n",
    "parser.add_argument('--minimal_enc', dest='minimal_enc', action='store_true')\n",
    "parser.add_argument('--no-minimal_enc', dest='minimal_enc', action='store_false')\n",
    "parser.set_defaults(minimal_enc=False)\n",
    "parser.add_argument(\"--losses\", default='VAE', choices=[\"VAE\", \"IWAE\"], type=str)\n",
    "parser.add_argument(\"--graph\", default='Normal', choices=[\"Discrete\", \"IndepInfer\", \"Normal\", \"NormalConGen\", \"NormalSimplePrior\",\n",
    "                                                          \"Normal2\",  \"NormalLSTM\"], type=str)\n",
    "parser.add_argument(\"--training_iw_samples\", default=1, type=int)\n",
    "parser.add_argument(\"--testing_iw_samples\", default=5, type=int)\n",
    "parser.add_argument(\"--test_prior_samples\", default=10, type=int)\n",
    "parser.add_argument(\"--anneal_kl0\", default=3000, type=int)\n",
    "parser.add_argument(\"--anneal_kl1\", default=6000, type=int)\n",
    "parser.add_argument(\"--grad_clip\", default=5., type=float)\n",
    "parser.add_argument(\"--kl_th\", default=0/(768*k/2), type=float or None)\n",
    "parser.add_argument(\"--max_elbo1\", default=6.0, type=float)\n",
    "parser.add_argument(\"--max_elbo2\", default=4.0, type=float)\n",
    "parser.add_argument(\"--max_elbo_choice\", default=10, type=int)\n",
    "parser.add_argument(\"--kl_beta\", default=0.35, type=int)\n",
    "parser.add_argument(\"--dropout\", default=0.3, type=float)\n",
    "parser.add_argument(\"--word_dropout\", default=0.1, type=float)\n",
    "parser.add_argument(\"--l2_reg\", default=0, type=float)\n",
    "parser.add_argument(\"--lr\", default=2e-4, type=float)\n",
    "parser.add_argument(\"--lr_reduction\", default=4., type=float)\n",
    "parser.add_argument(\"--wait_epochs\", default=1, type=float)\n",
    "parser.add_argument(\"--save_all\", default=True, type=bool)\n",
    "\n",
    "flags, _ = parser.parse_known_args()\n",
    "\n",
    "# Manual Settings, Deactivate before pushing\n",
    "if True:\n",
    "    flags.batch_size = 128\n",
    "    flags.grad_accu = 1\n",
    "    flags.max_len = 17\n",
    "    flags.graph = \"IndepInfer\"\n",
    "    flags.test_name = \"nliLM/testRepr2\"\n",
    "    flags.data = \"nli\"\n",
    "    flags.n_latents = [4]\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "GRAPH = {\"Discrete\": get_discrete_auto_regressive_graph,\n",
    "         \"IndepInfer\": get_structured_auto_regressive_indep_graph,\n",
    "         \"Normal\": get_structured_auto_regressive_graph,\n",
    "         \"NormalConGen\": get_structured_auto_regressive_graphConGen,\n",
    "         \"Normal2\": get_structured_auto_regressive_graph2,\n",
    "         \"NormalLSTM\": get_lstm_graph,\n",
    "         \"NormalSimplePrior\": get_structured_auto_regressive_simple_prior}[flags.graph]\n",
    "if flags.graph == \"NormalLSTM\":\n",
    "    flags.encoder_h = int(flags.encoder_h/k*klstm)\n",
    "Data = {\"nli\": NLIGenData2, \"ontonotes\": OntoGenData, \"yelp\": HuggingYelp2}[flags.data]\n",
    "MAX_LEN = flags.max_len\n",
    "BATCH_SIZE = flags.batch_size\n",
    "GRAD_ACCU = flags.grad_accu\n",
    "N_EPOCHS = flags.n_epochs\n",
    "TEST_FREQ = flags.test_freq\n",
    "COMPLETE_TEST_FREQ = flags.complete_test_freq\n",
    "DEVICE = device(flags.device)\n",
    "# This prevents illegal memory access on multigpu machines (unresolved issue on torch's github)\n",
    "if flags.device.startswith('cuda'):\n",
    "    torch.cuda.set_device(int(flags.device[-1]))\n",
    "LOSSES = {'IWAE': [IWLBo],\n",
    "          'VAE': [ELBo]}[flags.losses]\n",
    "\n",
    "ANNEAL_KL = [flags.anneal_kl0*flags.grad_accu, flags.anneal_kl1*flags.grad_accu]\n",
    "LOSS_PARAMS = [1]\n",
    "if flags.grad_accu > 1:\n",
    "    LOSS_PARAMS = [w/flags.grad_accu for w in LOSS_PARAMS]\n",
    "\n",
    "data = Data(MAX_LEN, BATCH_SIZE, N_EPOCHS, DEVICE, pretrained=flags.pretrained_embeddings)\n",
    "h_params = HParams(len(data.vocab.itos), len(data.tags.itos) if flags.data == 'yelp' else None, MAX_LEN, BATCH_SIZE, N_EPOCHS,\n",
    "                   device=DEVICE, vocab_ignore_index=data.vocab.stoi['<pad>'], decoder_h=flags.decoder_h,\n",
    "                   decoder_l=flags.decoder_l, encoder_h=flags.encoder_h, encoder_l=flags.encoder_l,\n",
    "                   text_rep_h=flags.text_rep_h, text_rep_l=flags.text_rep_l,\n",
    "                   test_name=flags.test_name, grad_accumulation_steps=GRAD_ACCU,\n",
    "                   optimizer_kwargs={'lr': flags.lr, #'weight_decay': flags.l2_reg, 't0':100, 'lambd':0.},\n",
    "                                     'weight_decay': flags.l2_reg, 'betas': (0.9, 0.99)},\n",
    "                   is_weighted=[], graph_generator=GRAPH,\n",
    "                   z_size=flags.z_size, embedding_dim=flags.embedding_dim, anneal_kl=ANNEAL_KL,\n",
    "                   grad_clip=flags.grad_clip*flags.grad_accu, kl_th=flags.kl_th, highway=flags.highway,\n",
    "                   losses=LOSSES, dropout=flags.dropout, training_iw_samples=flags.training_iw_samples,\n",
    "                   testing_iw_samples=flags.testing_iw_samples, loss_params=LOSS_PARAMS, optimizer=optim.AdamW,\n",
    "                   markovian=flags.markovian, word_dropout=flags.word_dropout, contiguous_lm=False,\n",
    "                   test_prior_samples=flags.test_prior_samples, n_latents=flags.n_latents,\n",
    "                   max_elbo=[flags.max_elbo_choice, flags.max_elbo1],  # max_elbo is paper's beta\n",
    "                   z_emb_dim=flags.z_emb_dim, minimal_enc=flags.minimal_enc, kl_beta=flags.kl_beta)\n",
    "val_iterator = iter(data.val_iter)\n",
    "print(\"Words: \", len(data.vocab.itos), \", On device: \", DEVICE.type)\n",
    "print(\"Loss Type: \", flags.losses)\n",
    "model = Model(data.vocab, data.tags, h_params, wvs=data.wvs, dataset=flags.data)\n",
    "if DEVICE.type == 'cuda':\n",
    "    model.cuda(DEVICE)\n",
    "\n",
    "total_unsupervised_train_samples = len(data.train_iter)*BATCH_SIZE\n",
    "total_unsupervised_val_samples = len(data.val_iter)*BATCH_SIZE\n",
    "print(\"Unsupervised training examples: \", total_unsupervised_train_samples)\n",
    "print(\"Unsupervised val examples: \", total_unsupervised_val_samples)\n",
    "current_time = time()\n",
    "#print(model)\n",
    "number_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: \", \"{0:05.2f} M\".format(number_parameters/1e6))\n",
    "number_parameters = sum(p.numel() for p in model.infer_bn.parameters() if p.requires_grad)\n",
    "print(\"Inference parameters: \", \"{0:05.2f} M\".format(number_parameters/1e6))\n",
    "number_parameters = sum(p.numel() for p in model.gen_bn.parameters() if p.requires_grad)\n",
    "print(\"Generation parameters: \", \"{0:05.2f} M\".format(number_parameters/1e6))\n",
    "number_parameters = sum(p.numel() for p in model.word_embeddings.parameters() if p.requires_grad)\n",
    "print(\"Embedding parameters: \", \"{0:05.2f} M\".format(number_parameters/1e6))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "      \n",
    "# import spacy\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "# predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/openie-model.2020.03.26.tar.gz\")\n",
    "# const_predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/elmo-constituency-parser-2020.02.10.tar.gz\")\n",
    "\n",
    "# def batch_sent_relations(sents):\n",
    "#     target = [{'sentence': sent} for sent in sents]\n",
    "#     preds = predictor.predict_batch_json(target)\n",
    "#     sent_dicts = []\n",
    "#     for pred in preds:\n",
    "#         sent_dict = {'ARG0': '', 'V': '', 'ARG1': '', 'ARG*': ''}\n",
    "#         if len(pred['verbs']):\n",
    "#             el = pred['verbs'][0]\n",
    "#             for v_i in el['description'].split('[')[1:]:\n",
    "#                 in_bracket = v_i.split(']')[0]\n",
    "#                 try:\n",
    "#                     arg_l, arg_str = in_bracket.split(':')\n",
    "#                     if arg_l in sent_dict:\n",
    "#                         sent_dict[arg_l] = arg_str\n",
    "#                     else:\n",
    "#                         sent_dict['ARG*'] = ''.join([sent_dict['ARG*'], arg_str])\n",
    "#                 except ValueError as e:\n",
    "#                     print('this raised an anomaly:', el)\n",
    "#         if sent_dict['ARG0'] == '':\n",
    "#             sent_dict['ARG0'] = sent_dict['ARG1']\n",
    "#             sent_dict['ARG1'] = ''\n",
    "#         sent_dicts.append(sent_dict)\n",
    "#     return sent_dicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "      \n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def shallow_constituents(sents, verbose=0):\n",
    "    target = [{'sentence': sent} for sent in sents]\n",
    "    preds = const_predictor.predict_batch_json(target)\n",
    "    outputs = []\n",
    "    for pred in preds:\n",
    "        root_c = pred['hierplane_tree']['root']['children']\n",
    "        subj, verb, np, pp = '', '', '', ''\n",
    "        parsing_error = False\n",
    "        try:\n",
    "            subj = [c['word'] for c in root_c if c['nodeType']=='NP'][0]\n",
    "            VP_c = [c for c in root_c if c['nodeType']=='VP'][0]['children']\n",
    "            if not any([c['nodeType'].startswith('VB') for c in VP_c]):\n",
    "                outputs.append({'subj':subj, 'verb':'', 'np':'', 'pp':''})\n",
    "                continue\n",
    "            verb = [c['word'] for c in VP_c if c['nodeType'].startswith('VB')][0]\n",
    "            \n",
    "            np = [c['word'] for c in VP_c if c['nodeType']=='NP'][0] if any([c['nodeType']=='NP' for c in VP_c]) else ''\n",
    "            pp = [c['word'] for c in VP_c if c['nodeType']=='PP'][0] if any([c['nodeType']=='PP' for c in VP_c]) else ''\n",
    "            if verbose: \n",
    "                print([[c['nodeType'],c['word']] for c in VP_c])\n",
    "            while any([c['nodeType'] == 'VP' for c in VP_c]):\n",
    "                VP_c = [c for c in VP_c if c['nodeType']=='VP'][0]['children']\n",
    "                if verbose: \n",
    "                    print([[c['nodeType'],c['word']] for c in VP_c])\n",
    "                verb += ' '+[c['word'] for c in VP_c if c['nodeType'].startswith('VB')][0]\n",
    "                if any([c['nodeType']=='NP' for c in VP_c]):\n",
    "                    for np_i in [c['word'] for c in VP_c if c['nodeType']=='NP']:\n",
    "                        np += ' '+np_i\n",
    "                if any([c['nodeType']=='PP' for c in VP_c]):\n",
    "                    for pp_i in [c['word'] for c in VP_c if c['nodeType']=='PP']:\n",
    "                        pp += ' '+pp_i\n",
    "        except IndexError:\n",
    "            parsing_error = True\n",
    "        outputs.append({'subj':subj, 'verb':verb, 'np':np, 'pp':pp, 'err': parsing_error})\n",
    "    return outputs\n",
    "\n",
    "def shallow_dependencies(sents):\n",
    "    docs = nlp.pipe(sents)\n",
    "    relations = []\n",
    "    for doc in docs:\n",
    "        subj, verb, dobj, pobj = ['', []], ['', []], ['', []], ['', []]\n",
    "        for i, tok in enumerate(doc):\n",
    "            if tok.dep_ =='ROOT':\n",
    "                verb = [tok.text, [tok.i]]\n",
    "            if tok.dep_ == 'nsubj' and subj[0] == '':\n",
    "                subj = [' '.join([toki.text for toki in tok.subtree]), [toki.i for toki in tok.subtree]]\n",
    "            if tok.dep_ == 'dobj' and dobj[0] == '':\n",
    "                dobj = [' '.join([toki.text for toki in tok.subtree]), [toki.i for toki in tok.subtree]]\n",
    "            if tok.dep_ == 'pobj' and pobj[0] == '':\n",
    "                pobj = [' '.join([toki.text for toki in tok.subtree]), [toki.i for toki in tok.subtree]]\n",
    "        relations.append({'text':{'subj': subj[0], 'verb': verb[0], 'dobj': dobj[0], 'pobj': pobj[0]},\n",
    "                         'idx':{'subj': subj[1], 'verb': verb[1], 'dobj': dobj[1], 'pobj': pobj[1]}})\n",
    "    return relations\n",
    "\n",
    "def get_sentence_statistics(orig, sen, orig_relations=None, relations=None):\n",
    "    same_struct = True\n",
    "    error = orig_relations.pop('err', None) or relations.pop('err', None)\n",
    "    for k in orig_relations.keys():\n",
    "        if (orig_relations[k] == '' and relations[k] != '') or (orig_relations[k] == '' and relations[k] != ''):\n",
    "            same_struct = False\n",
    "    def get_diff(arg):\n",
    "        if orig_relations[arg] != '' and relations[arg] != '':\n",
    "            return orig_relations[arg] != relations[arg], False\n",
    "        else: \n",
    "            return False, orig_relations[arg] != relations[arg]\n",
    "    return get_diff('subj'), get_diff('verb'), get_diff('np'), get_diff('pp'), same_struct, error\n",
    "    # return get_diff('ARG0'), get_diff('V'), get_diff('ARG1'), get_diff('ARG*'), same_struct\n",
    "\n",
    "def get_sentence_statistics2(orig, sen, orig_relations=None, relations=None):\n",
    "    orig_relations, relations = orig_relations['text'], relations['text']\n",
    "    same_struct = True\n",
    "    for k in orig_relations.keys():\n",
    "        if (orig_relations[k] == '' and relations[k] != '') or (orig_relations[k] == '' and relations[k] != ''):\n",
    "            same_struct = False\n",
    "    def get_diff(arg):\n",
    "        if orig_relations[arg] != '' and relations[arg] != '':\n",
    "            return orig_relations[arg] != relations[arg], False\n",
    "        else: \n",
    "            return False, orig_relations[arg] != relations[arg]\n",
    "    return get_diff('subj'), get_diff('verb'), get_diff('dobj'), get_diff('pobj'), same_struct\n",
    "\n",
    "\n",
    "\n",
    "def _get_stat_data_frame(model, n_samples=20, n_alterations=10, batch_size=10):\n",
    "    stats = []\n",
    "    nlatents = model.h_params.n_latents\n",
    "    # Generating n_samples sentences    \n",
    "    text, samples, _ = model.get_sentences(n_samples=batch_size, gen_len=model.h_params.max_len-1,\n",
    "                                                sample_w=False, vary_z=True, complete=None)\n",
    "    orig_rels = shallow_dependencies(text)\n",
    "    for _ in tqdm(range(int(n_samples / batch_size)), desc=\"Generating original sentences\"):\n",
    "        text_i, samples_i, _ = model.get_sentences(n_samples=batch_size, gen_len=model.h_params.max_len-1,\n",
    "                                                    sample_w=False, vary_z=True, complete=None)\n",
    "        text.extend(text_i)\n",
    "        for k in samples.keys():\n",
    "            samples[k] = torch.cat([samples[k], samples_i[k]])\n",
    "        orig_rels.extend(shallow_dependencies(text_i))\n",
    "    for i in range(int(n_samples / batch_size)):\n",
    "        for j in tqdm(range(sum(nlatents)), desc=\"Processing sample {}\".format(str(i))):\n",
    "            # Altering the sentences\n",
    "            alt_text, _ = model._get_alternative_sentences(\n",
    "                                                       prev_latent_vals={k: v[i * batch_size:(i + 1) * batch_size]\n",
    "                                                                         for k, v in samples.items()},\n",
    "                                                       params=None, var_z_ids=[j], n_samples=n_alterations,\n",
    "                                                       gen_len=model.h_params.max_len-1, complete=None)\n",
    "            alt_rels = shallow_dependencies(alt_text)\n",
    "            # Getting alteration statistics\n",
    "            for k in range(n_alterations * batch_size):\n",
    "                orig_text = text[(i * batch_size) + k % batch_size]\n",
    "                try:\n",
    "                    arg0_diff, v_diff, arg1_diff, arg_star_diff, same_struct = \\\n",
    "                        get_sentence_statistics2(orig_text, alt_text[k], orig_rels[(i * batch_size) + k % batch_size],\n",
    "                                                alt_rels[k])\n",
    "                except RecursionError or IndexError:\n",
    "                    continue\n",
    "                stats.append([orig_text, alt_text[k], j, int(arg0_diff[0]), int(v_diff[0]), \n",
    "                              int(arg1_diff[0]), int(arg_star_diff[0]), int(arg0_diff[1]), int(v_diff[1]), \n",
    "                              int(arg1_diff[1]), int(arg_star_diff[1]), same_struct])\n",
    "\n",
    "    header = ['original', 'altered', 'alteration_id', 'subj_diff', 'verb_diff', 'dobj_diff', 'pobj_diff',\n",
    "              'subj_struct', 'verb_struct', 'dobj_struct', 'pobj_struct', 'same_struct']\n",
    "    df = pd.DataFrame(stats, columns=header)\n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_sent_relations' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-fa1182ff9c90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mex_sens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'The man is breathing'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"a group of people gave the boy a bike in summer\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_sent_relations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mex_sens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'ARG0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'V'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ARG1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m':'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mrels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch_sent_relations' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "ex_sens = ['The man is breathing', \"a group of people gave the boy a bike in summer\"]\n",
    "rels = batch_sent_relations(ex_sens)\n",
    "print(rels)\n",
    "for arg in ['ARG0', 'V', 'ARG1']:\n",
    "    print(arg, ':', rels[0][arg]==rels[1][arg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 6.00 GiB total capacity; 497.50 MiB already allocated; 3.93 GiB free; 544.00 MiB reserved in total by PyTorch)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-67fb25ddea9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_stat_data_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_alterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer_bn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_bn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-44355c0d27fc>\u001b[0m in \u001b[0;36m_get_stat_data_frame\u001b[1;34m(model, n_samples, n_alterations, batch_size)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;31m# Generating n_samples sentences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     text, samples, _ = model.get_sentences(n_samples=batch_size, gen_len=model.h_params.max_len-1,\n\u001b[1;32m---> 96\u001b[1;33m                                                 sample_w=False, vary_z=True, complete=None)\n\u001b[0m\u001b[0;32m     97\u001b[0m     \u001b[0morig_rels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshallow_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Generating original sentences\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\disentanglement_transformer\\models.py\u001b[0m in \u001b[0;36mget_sentences\u001b[1;34m(self, n_samples, gen_len, sample_w, vary_z, complete, contains, max_tries)\u001b[0m\n\u001b[0;32m    592\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m                 self.gen_bn({'x_prev': x_prev, **{k: v.expand(v.shape[0], i + 1, v.shape[-1])\n\u001b[1;32m--> 594\u001b[1;33m                                                  for k, v in z_input.items()}})\n\u001b[0m\u001b[0;32m    595\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msample_w\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m                     \u001b[0msamples_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerated_v\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'logits'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\components\\bayesnets.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, n_iw, target, eval, prev_states, force_iw, complete, lens, plant_posteriors)\u001b[0m\n\u001b[0;32m    164\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapproximator\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprev_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprev_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m                     lv(self.approximator[lv], lv_conditions, gt_samples=gt_lv, complete=(lv in self.child) or complete,\n\u001b[1;32m--> 166\u001b[1;33m                        lens=this_len)\n\u001b[0m\u001b[0;32m    167\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrep_net\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m                         \u001b[0mlv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprev_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapproximator\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\components\\latent_variables.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, link_approximator, inputs, prior, gt_samples, complete, lens)\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sequential_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink_approximator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink_approximator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\components\\latent_variables.py\u001b[0m in \u001b[0;36m_forward\u001b[1;34m(self, link_approximator, inputs, prior, gt_samples, complete, lens)\u001b[0m\n\u001b[0;32m    268\u001b[0m                       torch.cat([v for k, v in inputs.items() if k not in link_approximator.residual['conditions']],\n\u001b[0;32m    269\u001b[0m                                 dim=-1))\n\u001b[1;32m--> 270\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlink_approximator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_log_probas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposterior_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\components\\links.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, z_prev, lens)\u001b[0m\n\u001b[0;32m    753\u001b[0m                 \u001b[0mz_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'logits'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msbn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'logits'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m                 \u001b[0mz_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'logits'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'logits'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    756\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'loc'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mz_params\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatchnorm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[0mout_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 6.00 GiB total capacity; 497.50 MiB already allocated; 3.93 GiB free; 544.00 MiB reserved in total by PyTorch)"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "df = _get_stat_data_frame(model, n_samples=2000, n_alterations=1, batch_size=100)\n",
    "model.infer_bn.clear_values()\n",
    "model.gen_bn.clear_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\nDisentanglement score 0.4224999999999999\nDisentanglement score 0.39999999999999997\nDisentanglement score 0.3625000000000001\nDisentanglement score 0.4574999999999999\nDisentanglement score 0.43500000000000005\n0.4154999999999999 0.0323805497173843\n               subj_diff  verb_diff  dobj_diff  pobj_diff\nalteration_id                                            \n0                 0.4305     0.8855     0.1885     0.2410\n1                 0.4125     0.6960     0.2260     0.3030\n2                 0.4045     0.6700     0.2180     0.2705\n3                 0.6635     0.7305     0.2045     0.2800\nDisentanglement score 0.4189999999999999\nNumber of fixed structure pairs: 4558\n               subj_diff  verb_diff  dobj_diff  pobj_diff\nalteration_id                                            \n0               0.436563   0.830170   0.331668   0.402597\n1               0.407807   0.584718   0.335548   0.438538\n2               0.415776   0.552999   0.314708   0.394412\n3               0.666373   0.607394   0.321303   0.428697\nsubj_diff 3 0.2298098028731832\nverb_diff 0 0.22277546397264703\ndobj_diff 1 0.00387984108914341\npobj_diff 1 0.00984102288147487\nDisentanglement score 0.4663061308164485\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "scores = []\n",
    "div_by = 5\n",
    "for i in range(div_by):\n",
    "    grouped_diff = df[int(i*len(df)/div_by):int((i+1)*len(df)/div_by)].groupby('alteration_id').mean()\n",
    "    [['subj_diff', 'verb_diff', 'dobj_diff', 'pobj_diff']]\n",
    "    # print(grouped_diff)#\n",
    "    disent_score = 0\n",
    "    for lab in ['subj_diff', 'verb_diff', 'dobj_diff', 'pobj_diff']:\n",
    "        top2 = np.array(grouped_diff.nlargest(2, lab)[lab])\n",
    "        diff = top2[0]-top2[1]\n",
    "        # print(lab, diff)\n",
    "        disent_score += diff\n",
    "    print(\"Disentanglement score\", disent_score)\n",
    "    scores.append(disent_score)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "grouped_diff = df.groupby('alteration_id').mean()[['subj_diff', 'verb_diff', 'dobj_diff', 'pobj_diff']]\n",
    "print(grouped_diff)#\n",
    "disent_score = 0\n",
    "for lab in ['subj_diff', 'verb_diff', 'dobj_diff', 'pobj_diff']:\n",
    "    top2 = np.array(grouped_diff.nlargest(2, lab)[lab])\n",
    "    diff = top2[0]-top2[1]\n",
    "    # print(lab, diff)\n",
    "    disent_score += diff\n",
    "print(\"Disentanglement score\", disent_score)\n",
    "\n",
    "df_fix = df[df['same_struct']==True]\n",
    "print(\"Number of fixed structure pairs:\", len(df_fix))\n",
    "grouped_diff = df_fix.groupby('alteration_id').mean()[['subj_diff', 'verb_diff', 'dobj_diff', 'pobj_diff']]\n",
    "print(grouped_diff)#\n",
    "disent_score = 0\n",
    "for lab in ['subj_diff', 'verb_diff', 'dobj_diff', 'pobj_diff']:#, 'arg_star_diff']:\n",
    "    highest_idx = grouped_diff[lab].argmax()\n",
    "    top2 = np.array(grouped_diff.nlargest(2, lab)[lab])\n",
    "    diff = top2[0]-top2[1]\n",
    "    print(lab, highest_idx, diff)\n",
    "    disent_score += diff\n",
    "    #grouped_diff = grouped_diff.drop(highest_idx)\n",
    "print(\"Disentanglement score\", disent_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 4, 2, 18)\n"
     ]
    }
   ],
   "source": [
    "from components.links import CoattentiveTransformerLink, ConditionalCoattentiveTransformerLink\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def get_attention_weights(sentences, lvs):\n",
    "    # Encoding sentences\n",
    "    encoded = []\n",
    "    lens = []\n",
    "    for sen in sentences:\n",
    "        sen_enc = [data.vocab.stoi[w] for w in sen.split(' ')]\n",
    "        lens.append(min(len(sen_enc), MAX_LEN))\n",
    "        if len(sen_enc)>=MAX_LEN:\n",
    "            sen_enc = sen_enc[:MAX_LEN]\n",
    "        else:\n",
    "            sen_enc = sen_enc+[data.vocab.stoi['<pad>']]*(MAX_LEN-len(sen_enc))\n",
    "        encoded.append(sen_enc)\n",
    "    encoded = torch.Tensor(encoded).to(DEVICE).long()\n",
    "    lens = torch.Tensor(lens).to(DEVICE).long()\n",
    "    CoattentiveTransformerLink.get_att, ConditionalCoattentiveTransformerLink.get_att = True, True\n",
    "    model.infer_bn({'x': encoded}, lens=lens)\n",
    "    CoattentiveTransformerLink.get_att, ConditionalCoattentiveTransformerLink.get_att = False, False\n",
    "    all_att_weights = []\n",
    "    for i in range(len(h_params.n_latents)):\n",
    "        trans_mod = model.infer_bn.approximator[model.infer_bn.name_to_v['z{}'.format(i+1)]]\n",
    "        all_att_weights.append(trans_mod.att_vals)\n",
    "    att_weights = []\n",
    "    for lv in lvs:\n",
    "        var_att_weights = []\n",
    "        lv_layer = sum([lv > sum(h_params.n_latents[:i+1]) for i in range(len(h_params.n_latents))])\n",
    "        rank = lv - sum(h_params.n_latents[:lv_layer])\n",
    "        for layer_att_vals in all_att_weights[lv_layer]:\n",
    "            soft_att_vals = layer_att_vals\n",
    "            att_out = torch.cat([soft_att_vals[:, rank, :MAX_LEN], soft_att_vals[:, rank, MAX_LEN:].sum(-1).unsqueeze(-1)]\n",
    "                                , -1)\n",
    "            if lv_layer==2:\n",
    "                att_out[..., -1] *= 0\n",
    "            var_att_weights.append(att_out.cpu().detach().numpy())\n",
    "        att_weights.append(var_att_weights)\n",
    "    return np.transpose(np.array(att_weights), (2, 0, 1, 3))\n",
    "\n",
    "def display_attention(sentence, att_weights, variables):\n",
    "    toked = sentence.split(' ')\n",
    "    toked += ['<pad>']*(MAX_LEN-len(toked))+['<latent>']\n",
    "    index = []\n",
    "    for i in range(len(variables)):\n",
    "        for j in range(len(att_weights[i])):\n",
    "            index.append(str(variables[i])+'_'+str(j))\n",
    "    att_weights = att_weights.reshape(-1, MAX_LEN+1)\n",
    "    data = pd.DataFrame(att_weights#[:, :len(toked)].reshape((len(att_weights), len(toked)))\n",
    "                        , columns=toked, index=index)\n",
    "    sns_plot = plt.figure(figsize=(15, 2.8))\n",
    "    ax = plt.axes()\n",
    "    g = sns.heatmap(data, annot=True, yticklabels=True, ax=ax)\n",
    "    ax.set_title('')\n",
    "    for tick in g.get_xticklabels():\n",
    "        tick.set_color('black')\n",
    "    for tick in g.get_yticklabels():\n",
    "        tick.set_color('black')\n",
    "    g.set_ylim([0, len(index)])\n",
    "    #g.set_xticklabels(data.axes[1], rotation=55, ha=\"center\", labelcolor='white')\n",
    "    # g.get_figure()\n",
    "    # plt.show()\n",
    "    return sns_plot\n",
    "\n",
    "\n",
    "sentences = ['a man is standing .',\n",
    "             'two little girls are standing .',\n",
    "             \"a girl is holding a toy\", \n",
    "              \"a girl with a white hat is holding a toy .\", \n",
    "              \"a girl is playing in a street\", \"a girl with a black coat is playing in a street .\", \n",
    "             \"a girl and a boy are playing in the street .\",\n",
    "             'a group of people are sitting around a table .']\n",
    "vars = [0, 1, 2, 3]\n",
    "att_w = get_attention_weights(sentences, vars)\n",
    "print(att_w.shape)\n",
    "\n",
    "# for sen_idx in range(len(sentences)):\n",
    "#     sns_plot = display_attention(sentences[sen_idx], att_w[sen_idx], vars)\n",
    "#     sns_plot.savefig(\"att_{}.png\".format(sen_idx)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_att_and_rel_idx(text_in):\n",
    "    max_len = text_in.shape[-1]\n",
    "    text_sents = [' '.join([model.index[model.generated_v].itos[w] \n",
    "                            for w in s]).replace(' <pad>', '').replace(' <eos>', '')\n",
    "                  for s in text_in]\n",
    "    # Getting relations' positions\n",
    "    rel_idx = [out['idx'] for out in shallow_dependencies(text_sents)]\n",
    "    # Getting layer wise attention values\n",
    "    \n",
    "    CoattentiveTransformerLink.get_att, ConditionalCoattentiveTransformerLink.get_att = True, True\n",
    "    model.infer_bn({'x': text_in})\n",
    "    CoattentiveTransformerLink.get_att, ConditionalCoattentiveTransformerLink.get_att = False, False\n",
    "    all_att_weights = []\n",
    "    for i in range(len(h_params.n_latents)):\n",
    "        trans_mod = model.infer_bn.approximator[model.infer_bn.name_to_v['z{}'.format(i+1)]]\n",
    "        all_att_weights.append(trans_mod.att_vals)\n",
    "    att_weights = []\n",
    "    for lv in range(sum(model.h_params.n_latents)):\n",
    "        var_att_weights = []\n",
    "        lv_layer = sum([lv > sum(h_params.n_latents[:i+1]) for i in range(len(h_params.n_latents))])\n",
    "        rank = lv - sum(h_params.n_latents[:lv_layer])\n",
    "        for layer_att_vals in all_att_weights[lv_layer]:\n",
    "            soft_att_vals = layer_att_vals\n",
    "            att_out = torch.cat([soft_att_vals[:, rank,\n",
    "                                 :max_len], soft_att_vals[:, rank, max_len:].sum(-1).unsqueeze(-1)]\n",
    "                                , -1)\n",
    "            if lv_layer==2:\n",
    "                att_out[..., -1] *= 0\n",
    "            var_att_weights.append(att_out.cpu().detach().numpy())\n",
    "        att_weights.append(var_att_weights)\n",
    "    # att_vals shape:[sent, lv, layer, tok]\n",
    "    att_vals = np.transpose(np.array(att_weights), (2, 0, 1, 3)).mean(-2)\n",
    "    att_maxes = att_vals.argmax(-1).tolist()\n",
    "    return rel_idx, att_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:   0%|          | 0/417 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:   0%|          | 2/417 [00:00<00:22, 18.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:   1%|          | 5/417 [00:00<00:20, 20.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:   2%|         | 8/417 [00:00<00:19, 20.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:   3%|         | 11/417 [00:00<00:19, 21.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:   3%|         | 14/417 [00:00<00:18, 21.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:   4%|         | 17/417 [00:00<00:18, 21.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:   5%|         | 20/417 [00:00<00:17, 22.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:   6%|         | 23/417 [00:01<00:17, 22.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:   6%|         | 26/417 [00:01<00:17, 22.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:   7%|         | 29/417 [00:01<00:17, 22.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:   8%|         | 32/417 [00:01<00:17, 21.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:   8%|         | 35/417 [00:01<00:17, 22.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:   9%|         | 38/417 [00:01<00:18, 20.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  10%|         | 41/417 [00:01<00:18, 19.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  11%|         | 44/417 [00:02<00:18, 20.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  11%|        | 47/417 [00:02<00:18, 20.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  12%|        | 50/417 [00:02<00:17, 21.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  13%|        | 53/417 [00:02<00:16, 22.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  13%|        | 56/417 [00:02<00:15, 23.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  14%|        | 59/417 [00:02<00:15, 22.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  15%|        | 62/417 [00:02<00:15, 23.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  16%|        | 65/417 [00:02<00:15, 22.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  16%|        | 68/417 [00:03<00:15, 23.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  17%|        | 71/417 [00:03<00:14, 23.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  18%|        | 74/417 [00:03<00:14, 23.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  18%|        | 77/417 [00:03<00:14, 23.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  19%|        | 80/417 [00:03<00:14, 23.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  20%|        | 83/417 [00:03<00:14, 23.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  21%|        | 86/417 [00:03<00:14, 23.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  21%|       | 89/417 [00:03<00:14, 22.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  22%|       | 92/417 [00:04<00:14, 23.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  23%|       | 95/417 [00:04<00:13, 23.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  24%|       | 98/417 [00:04<00:13, 23.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  24%|       | 101/417 [00:04<00:13, 24.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  25%|       | 104/417 [00:04<00:12, 24.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  26%|       | 107/417 [00:04<00:12, 25.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  26%|       | 110/417 [00:04<00:12, 25.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  27%|       | 113/417 [00:04<00:11, 25.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  28%|       | 116/417 [00:05<00:11, 26.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  29%|       | 119/417 [00:05<00:11, 26.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  29%|       | 122/417 [00:05<00:11, 26.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  30%|       | 125/417 [00:05<00:10, 26.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  31%|       | 128/417 [00:05<00:11, 25.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  31%|      | 131/417 [00:05<00:10, 26.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  32%|      | 134/417 [00:05<00:10, 26.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  33%|      | 137/417 [00:05<00:10, 26.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  34%|      | 140/417 [00:05<00:10, 26.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  34%|      | 143/417 [00:06<00:10, 27.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  35%|      | 146/417 [00:06<00:10, 27.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  36%|      | 149/417 [00:06<00:09, 26.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  36%|      | 152/417 [00:06<00:09, 26.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  37%|      | 155/417 [00:06<00:09, 26.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  38%|      | 158/417 [00:06<00:09, 27.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  39%|      | 161/417 [00:06<00:09, 26.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  39%|      | 164/417 [00:06<00:09, 25.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  40%|      | 167/417 [00:06<00:09, 25.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  41%|      | 170/417 [00:07<00:09, 25.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  41%|     | 173/417 [00:07<00:09, 26.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  42%|     | 176/417 [00:07<00:09, 25.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  43%|     | 179/417 [00:07<00:09, 26.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  44%|     | 182/417 [00:07<00:09, 25.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  44%|     | 185/417 [00:07<00:08, 26.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  45%|     | 188/417 [00:07<00:08, 26.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  46%|     | 191/417 [00:07<00:08, 26.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  47%|     | 194/417 [00:07<00:08, 26.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  47%|     | 197/417 [00:08<00:08, 26.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  48%|     | 200/417 [00:08<00:08, 26.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  49%|     | 203/417 [00:08<00:08, 26.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  49%|     | 206/417 [00:08<00:08, 25.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  50%|     | 209/417 [00:08<00:08, 25.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  51%|     | 212/417 [00:08<00:07, 25.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  52%|    | 215/417 [00:08<00:07, 25.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  52%|    | 218/417 [00:08<00:07, 25.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  53%|    | 221/417 [00:09<00:07, 25.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  54%|    | 224/417 [00:09<00:07, 25.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  54%|    | 227/417 [00:09<00:07, 26.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  55%|    | 230/417 [00:09<00:07, 26.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  56%|    | 233/417 [00:09<00:06, 26.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  57%|    | 236/417 [00:09<00:06, 26.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  57%|    | 239/417 [00:09<00:06, 26.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  58%|    | 242/417 [00:09<00:06, 26.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  59%|    | 245/417 [00:09<00:06, 26.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  59%|    | 248/417 [00:10<00:06, 26.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  60%|    | 251/417 [00:10<00:06, 26.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  61%|    | 254/417 [00:10<00:06, 27.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  62%|   | 257/417 [00:10<00:05, 26.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  62%|   | 260/417 [00:10<00:06, 25.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  63%|   | 263/417 [00:10<00:05, 26.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  64%|   | 266/417 [00:10<00:05, 26.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  65%|   | 269/417 [00:10<00:05, 26.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  65%|   | 272/417 [00:10<00:05, 26.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  66%|   | 275/417 [00:11<00:05, 26.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  67%|   | 278/417 [00:11<00:05, 27.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  67%|   | 281/417 [00:11<00:05, 27.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  68%|   | 284/417 [00:11<00:04, 26.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  69%|   | 287/417 [00:11<00:04, 27.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  70%|   | 290/417 [00:11<00:04, 27.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  70%|   | 293/417 [00:11<00:04, 27.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  71%|   | 296/417 [00:11<00:04, 26.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  72%|  | 299/417 [00:11<00:04, 26.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  72%|  | 302/417 [00:12<00:04, 27.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  73%|  | 305/417 [00:12<00:04, 26.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  74%|  | 308/417 [00:12<00:04, 27.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  75%|  | 311/417 [00:12<00:03, 27.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  75%|  | 314/417 [00:12<00:03, 27.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  76%|  | 317/417 [00:12<00:03, 26.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  77%|  | 320/417 [00:12<00:03, 26.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  77%|  | 323/417 [00:12<00:03, 26.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  78%|  | 326/417 [00:12<00:03, 26.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  79%|  | 329/417 [00:13<00:03, 26.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  80%|  | 332/417 [00:13<00:03, 25.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  80%|  | 335/417 [00:13<00:03, 26.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  81%|  | 338/417 [00:13<00:02, 26.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  82%| | 341/417 [00:13<00:02, 26.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  82%| | 344/417 [00:13<00:02, 26.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  83%| | 347/417 [00:13<00:02, 26.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  84%| | 350/417 [00:13<00:02, 26.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  85%| | 353/417 [00:13<00:02, 26.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  85%| | 356/417 [00:14<00:02, 26.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  86%| | 359/417 [00:14<00:02, 26.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  87%| | 362/417 [00:14<00:02, 26.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  88%| | 365/417 [00:14<00:01, 26.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  88%| | 368/417 [00:14<00:01, 25.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  89%| | 371/417 [00:14<00:01, 26.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  90%| | 374/417 [00:14<00:01, 26.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  90%| | 377/417 [00:14<00:01, 25.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  91%| | 380/417 [00:15<00:01, 25.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  92%|| 383/417 [00:15<00:01, 26.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  93%|| 386/417 [00:15<00:01, 26.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  93%|| 389/417 [00:15<00:01, 26.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  94%|| 392/417 [00:15<00:00, 26.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  95%|| 395/417 [00:15<00:00, 26.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  95%|| 398/417 [00:15<00:00, 26.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  96%|| 401/417 [00:15<00:00, 26.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  97%|| 404/417 [00:15<00:00, 26.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  98%|| 407/417 [00:16<00:00, 27.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  98%|| 410/417 [00:16<00:00, 26.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy:  99%|| 413/417 [00:16<00:00, 26.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy: 100%|| 416/417 [00:16<00:00, 26.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Accuracy: 100%|| 417/417 [00:16<00:00, 25.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rel_idx, att_maxes = [], []\n",
    "for i, batch in enumerate(tqdm(data.val_iter, desc=\"Getting model relationship accuracy\")):\n",
    "    rel_idx_i, att_maxes_i = get_att_and_rel_idx(batch.text[..., 1:])\n",
    "    rel_idx.extend(rel_idx_i)\n",
    "    att_maxes.extend(att_maxes_i)\n",
    "    \n",
    "    \n",
    "data.reinit_iterator('valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   0%|          | 0/417 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   0%|          | 2/417 [00:00<00:22, 18.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   1%|          | 5/417 [00:00<00:20, 19.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   2%|         | 8/417 [00:00<00:19, 21.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   3%|         | 11/417 [00:00<00:18, 22.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   3%|         | 14/417 [00:00<00:17, 23.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   4%|         | 17/417 [00:00<00:16, 23.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   5%|         | 20/417 [00:00<00:16, 23.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   6%|         | 23/417 [00:00<00:16, 24.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   6%|         | 26/417 [00:01<00:15, 24.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   7%|         | 29/417 [00:01<00:16, 23.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   8%|         | 32/417 [00:01<00:16, 23.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   8%|         | 35/417 [00:01<00:16, 22.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   9%|         | 38/417 [00:01<00:16, 22.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  10%|         | 41/417 [00:01<00:16, 22.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  11%|         | 44/417 [00:01<00:16, 22.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  11%|        | 47/417 [00:02<00:15, 23.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  12%|        | 50/417 [00:02<00:15, 23.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  13%|        | 53/417 [00:02<00:15, 23.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  13%|        | 56/417 [00:02<00:16, 21.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  14%|        | 59/417 [00:02<00:15, 22.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  15%|        | 62/417 [00:02<00:16, 21.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  16%|        | 65/417 [00:02<00:16, 21.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  16%|        | 68/417 [00:02<00:16, 21.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  17%|        | 71/417 [00:03<00:15, 22.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  18%|        | 74/417 [00:03<00:14, 23.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  18%|        | 77/417 [00:03<00:14, 23.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  19%|        | 80/417 [00:03<00:13, 24.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  20%|        | 83/417 [00:03<00:13, 24.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  21%|        | 86/417 [00:03<00:13, 23.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  21%|       | 89/417 [00:03<00:14, 23.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  22%|       | 92/417 [00:03<00:13, 23.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  23%|       | 95/417 [00:04<00:13, 24.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  24%|       | 98/417 [00:04<00:13, 24.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  24%|       | 101/417 [00:04<00:13, 23.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  25%|       | 104/417 [00:04<00:13, 23.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  26%|       | 107/417 [00:04<00:12, 24.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  26%|       | 110/417 [00:04<00:12, 24.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  27%|       | 113/417 [00:04<00:12, 24.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  28%|       | 116/417 [00:04<00:12, 25.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  29%|       | 119/417 [00:05<00:11, 25.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  29%|       | 122/417 [00:05<00:11, 26.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  30%|       | 125/417 [00:05<00:11, 26.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  31%|       | 128/417 [00:05<00:10, 26.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  31%|      | 131/417 [00:05<00:10, 26.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  32%|      | 134/417 [00:05<00:10, 26.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  33%|      | 137/417 [00:05<00:10, 26.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  34%|      | 140/417 [00:05<00:10, 27.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  34%|      | 143/417 [00:05<00:10, 26.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  35%|      | 146/417 [00:06<00:10, 25.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  36%|      | 149/417 [00:06<00:10, 24.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  36%|      | 152/417 [00:06<00:10, 25.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  37%|      | 155/417 [00:06<00:10, 25.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  38%|      | 158/417 [00:06<00:10, 24.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  39%|      | 161/417 [00:07<00:28,  8.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  39%|      | 164/417 [00:07<00:23, 10.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  40%|      | 167/417 [00:07<00:19, 13.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  41%|      | 170/417 [00:07<00:16, 15.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  41%|     | 173/417 [00:07<00:14, 17.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  42%|     | 176/417 [00:08<00:12, 19.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  43%|     | 179/417 [00:08<00:11, 21.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  44%|     | 182/417 [00:08<00:10, 22.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  44%|     | 185/417 [00:08<00:09, 23.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  45%|     | 188/417 [00:08<00:09, 24.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  46%|     | 191/417 [00:08<00:08, 25.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  47%|     | 194/417 [00:08<00:08, 25.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  47%|     | 197/417 [00:08<00:08, 25.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  48%|     | 200/417 [00:08<00:08, 25.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  49%|     | 203/417 [00:09<00:08, 26.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  49%|     | 206/417 [00:09<00:08, 26.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  50%|     | 209/417 [00:09<00:08, 25.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  51%|     | 212/417 [00:09<00:08, 24.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  52%|    | 215/417 [00:09<00:08, 24.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  52%|    | 218/417 [00:09<00:07, 25.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  53%|    | 221/417 [00:09<00:07, 25.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  54%|    | 224/417 [00:09<00:07, 25.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  54%|    | 227/417 [00:09<00:07, 25.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  55%|    | 230/417 [00:10<00:07, 24.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  56%|    | 233/417 [00:10<00:07, 24.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  57%|    | 236/417 [00:10<00:07, 23.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  57%|    | 239/417 [00:10<00:08, 22.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  58%|    | 242/417 [00:10<00:07, 22.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  59%|    | 245/417 [00:10<00:07, 23.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  59%|    | 248/417 [00:10<00:07, 22.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  60%|    | 251/417 [00:11<00:06, 23.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  61%|    | 254/417 [00:11<00:06, 23.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  62%|   | 257/417 [00:11<00:06, 23.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  62%|   | 260/417 [00:11<00:06, 23.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  63%|   | 263/417 [00:11<00:06, 23.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  64%|   | 266/417 [00:11<00:06, 22.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  65%|   | 269/417 [00:11<00:06, 23.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  65%|   | 272/417 [00:11<00:06, 22.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  66%|   | 275/417 [00:12<00:06, 23.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  67%|   | 278/417 [00:12<00:06, 22.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  67%|   | 281/417 [00:12<00:06, 21.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  68%|   | 284/417 [00:12<00:06, 20.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  69%|   | 287/417 [00:12<00:06, 20.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  70%|   | 290/417 [00:12<00:05, 21.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  70%|   | 293/417 [00:12<00:05, 21.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  71%|   | 296/417 [00:13<00:05, 22.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  72%|  | 299/417 [00:13<00:05, 23.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  72%|  | 302/417 [00:13<00:04, 23.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  73%|  | 305/417 [00:13<00:04, 23.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  74%|  | 308/417 [00:13<00:04, 23.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  75%|  | 311/417 [00:13<00:04, 23.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  75%|  | 314/417 [00:13<00:04, 23.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  76%|  | 317/417 [00:13<00:04, 23.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  77%|  | 320/417 [00:14<00:04, 23.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  77%|  | 323/417 [00:14<00:03, 24.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  78%|  | 326/417 [00:14<00:03, 25.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  79%|  | 329/417 [00:14<00:03, 25.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  80%|  | 332/417 [00:14<00:03, 26.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  80%|  | 335/417 [00:14<00:03, 26.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  81%|  | 338/417 [00:14<00:02, 26.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  82%| | 341/417 [00:14<00:02, 26.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  82%| | 344/417 [00:14<00:02, 26.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  83%| | 347/417 [00:15<00:02, 26.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  84%| | 350/417 [00:15<00:02, 26.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  85%| | 353/417 [00:15<00:02, 26.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  85%| | 356/417 [00:15<00:02, 26.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  86%| | 359/417 [00:15<00:02, 26.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  87%| | 362/417 [00:15<00:02, 25.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  88%| | 365/417 [00:15<00:01, 26.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  88%| | 368/417 [00:15<00:01, 26.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  89%| | 371/417 [00:15<00:01, 26.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  90%| | 374/417 [00:16<00:01, 26.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  90%| | 377/417 [00:16<00:01, 26.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  91%| | 380/417 [00:16<00:01, 26.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  92%|| 383/417 [00:16<00:01, 26.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  93%|| 386/417 [00:16<00:01, 26.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  93%|| 389/417 [00:16<00:01, 26.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  94%|| 392/417 [00:16<00:00, 27.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  95%|| 395/417 [00:16<00:00, 26.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  95%|| 398/417 [00:16<00:00, 26.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  96%|| 401/417 [00:17<00:00, 26.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  97%|| 404/417 [00:17<00:00, 26.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  98%|| 407/417 [00:17<00:00, 26.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  98%|| 410/417 [00:17<00:00, 26.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  99%|| 413/417 [00:17<00:00, 26.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy: 100%|| 416/417 [00:17<00:00, 26.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy: 100%|| 417/417 [00:17<00:00, 23.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Final Model Scores =======\n{'subj': 0.8672220775839625, 'verb': 0.314611233260044, 'dobj': 0.4699812382739212, 'pobj': 0.5666666666666667}\n{'subj': 0.7073678729497527, 'verb': 0.1643014191485109, 'dobj': 0.15384615384615385, 'pobj': 0.2719135802469136}\n{'subj': 3, 'verb': 0, 'dobj': 1, 'pobj': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_encoder_disentanglement_score(data_iter):\n",
    "    rel_idx, att_maxes = [], []\n",
    "    for i, batch in enumerate(tqdm(data_iter, desc=\"Getting model relationship accuracy\")):\n",
    "        rel_idx_i, att_maxes_i = get_att_and_rel_idx(batch.text[..., 1:])\n",
    "        rel_idx.extend(rel_idx_i)\n",
    "        att_maxes.extend(att_maxes_i)\n",
    "        \n",
    "    lv_scores = []\n",
    "    for lv in range(sum(h_params.n_latents)):\n",
    "        found = {'subj':[], 'verb':[], 'dobj':[], 'pobj':[]}\n",
    "        for att, rel_pos in zip(att_maxes, rel_idx):\n",
    "            for k in found.keys():\n",
    "                if len(rel_pos[k]):\n",
    "                    found[k].append(att[lv] in rel_pos[k])\n",
    "        lv_scores.append(found)\n",
    "    enc_att_scores = {'subj':[], 'verb':[], 'dobj':[], 'pobj':[]}\n",
    "    for lv in range(sum(h_params.n_latents)):\n",
    "        for k, v in lv_scores[lv].items():\n",
    "            enc_att_scores[k].append(np.mean(v))\n",
    "    print(\"==== Final Model Scores =======\")\n",
    "    enc_max_score, enc_disent_score, enc_disent_vars = {}, {}, {}\n",
    "    for k, v in enc_att_scores.items():\n",
    "        sort_idx = np.argsort(v) \n",
    "        enc_disent_vars[k], enc_disent_score[k], enc_max_score[k] =\\\n",
    "            sort_idx[-1], v[sort_idx[-1]] - v[sort_idx[-2]], v[sort_idx[-1]]\n",
    "    print(enc_max_score)\n",
    "    print(enc_disent_score)\n",
    "    print(enc_disent_vars)\n",
    "    return enc_att_scores, enc_max_score, enc_disent_score, enc_disent_vars\n",
    "    # # ================= BASELINE ================= \n",
    "    # baseline = []\n",
    "    # for k in ['subj', 'verb', 'dobj', 'pobj']:\n",
    "    #     all_pos = []\n",
    "    #     for pos in rel_idx:\n",
    "    #         all_pos.extend(pos[k])\n",
    "    #     baseline.append(np.median(all_pos))\n",
    "    # baseline_scores = []\n",
    "    # for lv in range(4):\n",
    "    #     found = {'subj':[], 'verb':[], 'dobj':[], 'pobj':[]}\n",
    "    #     for rel_pos in rel_idx:\n",
    "    #         for k in found.keys():\n",
    "    #             if len(rel_pos[k]):\n",
    "    #                 found[k].append(baseline[lv] in rel_pos[k])\n",
    "    #     baseline_scores.append(found)\n",
    "    # \n",
    "    # baseline_enc_att_scores = {'subj':[], 'verb':[], 'dobj':[], 'pobj':[]}\n",
    "    # for lv in range(sum(h_params.n_latents)):\n",
    "    #     for k, v in baseline_scores[lv].items():\n",
    "    #         baseline_enc_att_scores[k].append(np.mean(v))\n",
    "    # print(\"==== Final baseline Scores =======\")\n",
    "    # enc_max_score, enc_disent_score, enc_disent_vars = {}, {}, {}\n",
    "    # for k, v in baseline_enc_att_scores.items():\n",
    "    #     sort_idx = np.argsort(v) \n",
    "    #     enc_disent_vars[k], enc_disent_score[k], enc_max_score[k] =\\\n",
    "    #         sort_idx[-1], v[sort_idx[-1]] - v[sort_idx[-2]], v[sort_idx[-1]]\n",
    "    # print(enc_max_score)\n",
    "    # print(enc_disent_score)\n",
    "    # print(enc_disent_vars)\n",
    "\n",
    "def show_df_hm2(df):\n",
    "    snsplt = sns.heatmap(df, cmap ='Reds', linewidths = 0.20, annot = False)\n",
    "    b, t = plt.ylim() # discover the values for bottom and top\n",
    "    b += 0.5 # Add 0.5 to the bottom\n",
    "    t -= 0.5 # Subtract 0.5 from the top\n",
    "    plt.ylim(b, t) # update the ylim(bottom, top) values\n",
    "    return snsplt.get_figure()\n",
    "enc_att, enc_max, enc_disent, enc_disent_idx = \\\n",
    "    get_encoder_disentanglement_score(data.val_iter)\n",
    "data.reinit_iterator('valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       subj      verb      dobj      pobj\n0  0.159854  0.314611  0.316135  0.238889\n1  0.040614  0.043574  0.469981  0.566667\n2  0.003124  0.004597  0.190432  0.294753\n3  0.867222  0.150310  0.002814  0.001235\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def show_df_hm2(df):\n",
    "    snsplt = sns.heatmap(df, cmap ='Reds', linewidths = 0.20, annot = True)\n",
    "    b, t = plt.ylim() # discover the values for bottom and top\n",
    "    b += 0.5 # Add 0.5 to the bottom\n",
    "    t -= 0.5 # Subtract 0.5 from the top\n",
    "    plt.ylim(b, t) # update the ylim(bottom, top) values\n",
    "    return snsplt.get_figure()\n",
    "att_df = pd.DataFrame(enc_att)\n",
    "print(att_df)\n",
    "sns_plot = show_df_hm2(att_df)\n",
    "sns_plot.savefig(\"enc_att.eps\", dpi=100, format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   0%|          | 0/417 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   0%|          | 2/417 [00:00<00:22, 18.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   1%|          | 5/417 [00:00<00:20, 19.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   2%|         | 8/417 [00:00<00:19, 21.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   3%|         | 11/417 [00:00<00:18, 22.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   3%|         | 14/417 [00:00<00:17, 23.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   4%|         | 17/417 [00:00<00:16, 23.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   5%|         | 20/417 [00:00<00:16, 23.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   6%|         | 23/417 [00:00<00:16, 24.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   6%|         | 26/417 [00:01<00:15, 24.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   7%|         | 29/417 [00:01<00:16, 23.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   8%|         | 32/417 [00:01<00:16, 23.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   8%|         | 35/417 [00:01<00:16, 22.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:   9%|         | 38/417 [00:01<00:16, 22.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  10%|         | 41/417 [00:01<00:16, 22.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  11%|         | 44/417 [00:01<00:16, 22.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  11%|        | 47/417 [00:02<00:15, 23.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  12%|        | 50/417 [00:02<00:15, 23.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  13%|        | 53/417 [00:02<00:15, 23.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  13%|        | 56/417 [00:02<00:16, 21.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  14%|        | 59/417 [00:02<00:15, 22.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  15%|        | 62/417 [00:02<00:16, 21.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  16%|        | 65/417 [00:02<00:16, 21.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  16%|        | 68/417 [00:02<00:16, 21.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  17%|        | 71/417 [00:03<00:15, 22.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  18%|        | 74/417 [00:03<00:14, 23.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  18%|        | 77/417 [00:03<00:14, 23.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  19%|        | 80/417 [00:03<00:13, 24.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  20%|        | 83/417 [00:03<00:13, 24.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  21%|        | 86/417 [00:03<00:13, 23.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  21%|       | 89/417 [00:03<00:14, 23.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  22%|       | 92/417 [00:03<00:13, 23.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  23%|       | 95/417 [00:04<00:13, 24.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  24%|       | 98/417 [00:04<00:13, 24.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  24%|       | 101/417 [00:04<00:13, 23.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  25%|       | 104/417 [00:04<00:13, 23.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  26%|       | 107/417 [00:04<00:12, 24.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  26%|       | 110/417 [00:04<00:12, 24.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  27%|       | 113/417 [00:04<00:12, 24.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  28%|       | 116/417 [00:04<00:12, 25.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  29%|       | 119/417 [00:05<00:11, 25.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  29%|       | 122/417 [00:05<00:11, 26.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  30%|       | 125/417 [00:05<00:11, 26.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  31%|       | 128/417 [00:05<00:10, 26.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  31%|      | 131/417 [00:05<00:10, 26.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  32%|      | 134/417 [00:05<00:10, 26.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  33%|      | 137/417 [00:05<00:10, 26.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  34%|      | 140/417 [00:05<00:10, 27.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  34%|      | 143/417 [00:05<00:10, 26.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  35%|      | 146/417 [00:06<00:10, 25.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  36%|      | 149/417 [00:06<00:10, 24.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  36%|      | 152/417 [00:06<00:10, 25.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  37%|      | 155/417 [00:06<00:10, 25.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  38%|      | 158/417 [00:06<00:10, 24.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  39%|      | 161/417 [00:07<00:28,  8.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  39%|      | 164/417 [00:07<00:23, 10.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  40%|      | 167/417 [00:07<00:19, 13.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  41%|      | 170/417 [00:07<00:16, 15.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  41%|     | 173/417 [00:07<00:14, 17.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  42%|     | 176/417 [00:08<00:12, 19.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  43%|     | 179/417 [00:08<00:11, 21.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  44%|     | 182/417 [00:08<00:10, 22.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  44%|     | 185/417 [00:08<00:09, 23.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  45%|     | 188/417 [00:08<00:09, 24.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  46%|     | 191/417 [00:08<00:08, 25.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  47%|     | 194/417 [00:08<00:08, 25.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  47%|     | 197/417 [00:08<00:08, 25.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  48%|     | 200/417 [00:08<00:08, 25.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  49%|     | 203/417 [00:09<00:08, 26.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  49%|     | 206/417 [00:09<00:08, 26.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  50%|     | 209/417 [00:09<00:08, 25.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  51%|     | 212/417 [00:09<00:08, 24.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  52%|    | 215/417 [00:09<00:08, 24.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  52%|    | 218/417 [00:09<00:07, 25.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  53%|    | 221/417 [00:09<00:07, 25.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  54%|    | 224/417 [00:09<00:07, 25.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  54%|    | 227/417 [00:09<00:07, 25.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  55%|    | 230/417 [00:10<00:07, 24.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  56%|    | 233/417 [00:10<00:07, 24.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  57%|    | 236/417 [00:10<00:07, 23.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  57%|    | 239/417 [00:10<00:08, 22.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  58%|    | 242/417 [00:10<00:07, 22.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  59%|    | 245/417 [00:10<00:07, 23.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  59%|    | 248/417 [00:10<00:07, 22.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  60%|    | 251/417 [00:11<00:06, 23.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  61%|    | 254/417 [00:11<00:06, 23.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  62%|   | 257/417 [00:11<00:06, 23.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  62%|   | 260/417 [00:11<00:06, 23.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  63%|   | 263/417 [00:11<00:06, 23.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  64%|   | 266/417 [00:11<00:06, 22.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  65%|   | 269/417 [00:11<00:06, 23.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  65%|   | 272/417 [00:11<00:06, 22.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  66%|   | 275/417 [00:12<00:06, 23.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  67%|   | 278/417 [00:12<00:06, 22.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  67%|   | 281/417 [00:12<00:06, 21.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  68%|   | 284/417 [00:12<00:06, 20.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  69%|   | 287/417 [00:12<00:06, 20.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  70%|   | 290/417 [00:12<00:05, 21.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  70%|   | 293/417 [00:12<00:05, 21.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  71%|   | 296/417 [00:13<00:05, 22.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  72%|  | 299/417 [00:13<00:05, 23.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  72%|  | 302/417 [00:13<00:04, 23.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  73%|  | 305/417 [00:13<00:04, 23.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  74%|  | 308/417 [00:13<00:04, 23.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  75%|  | 311/417 [00:13<00:04, 23.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  75%|  | 314/417 [00:13<00:04, 23.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  76%|  | 317/417 [00:13<00:04, 23.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  77%|  | 320/417 [00:14<00:04, 23.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  77%|  | 323/417 [00:14<00:03, 24.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  78%|  | 326/417 [00:14<00:03, 25.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  79%|  | 329/417 [00:14<00:03, 25.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  80%|  | 332/417 [00:14<00:03, 26.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  80%|  | 335/417 [00:14<00:03, 26.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  81%|  | 338/417 [00:14<00:02, 26.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  82%| | 341/417 [00:14<00:02, 26.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  82%| | 344/417 [00:14<00:02, 26.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  83%| | 347/417 [00:15<00:02, 26.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  84%| | 350/417 [00:15<00:02, 26.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  85%| | 353/417 [00:15<00:02, 26.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  85%| | 356/417 [00:15<00:02, 26.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  86%| | 359/417 [00:15<00:02, 26.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  87%| | 362/417 [00:15<00:02, 25.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  88%| | 365/417 [00:15<00:01, 26.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  88%| | 368/417 [00:15<00:01, 26.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  89%| | 371/417 [00:15<00:01, 26.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  90%| | 374/417 [00:16<00:01, 26.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  90%| | 377/417 [00:16<00:01, 26.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  91%| | 380/417 [00:16<00:01, 26.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  92%|| 383/417 [00:16<00:01, 26.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  93%|| 386/417 [00:16<00:01, 26.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  93%|| 389/417 [00:16<00:01, 26.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  94%|| 392/417 [00:16<00:00, 27.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  95%|| 395/417 [00:16<00:00, 26.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  95%|| 398/417 [00:16<00:00, 26.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  96%|| 401/417 [00:17<00:00, 26.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  97%|| 404/417 [00:17<00:00, 26.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  98%|| 407/417 [00:17<00:00, 26.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  98%|| 410/417 [00:17<00:00, 26.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy:  99%|| 413/417 [00:17<00:00, 26.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy: 100%|| 416/417 [00:17<00:00, 26.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting model relationship accuracy: 100%|| 417/417 [00:17<00:00, 23.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Final Model Scores =======\n{'subj': 0.8672220775839625, 'verb': 0.314611233260044, 'dobj': 0.4699812382739212, 'pobj': 0.5666666666666667}\n{'subj': 0.7073678729497527, 'verb': 0.1643014191485109, 'dobj': 0.15384615384615385, 'pobj': 0.2719135802469136}\n{'subj': 3, 'verb': 0, 'dobj': 1, 'pobj': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for i, batch in enumerate(data.val_iter):\n",
    "#     text_sents = [' '.join([model.index[model.generated_v].itos[w] \n",
    "#                             for w in s]).replace(' <pad>', '').replace(' <eos>', '')\n",
    "#                   for s in batch.text[:, 1:]]\n",
    "#     # Getting relations' positions\n",
    "#     rel_idx = shallow_dependencies(text_sents)\n",
    "#     for r, t in zip(rel_idx, text_sents):\n",
    "#         # if r['idx']['verb'][0] > 10:\n",
    "#         print(r, t)\n",
    "#     if i>10: break\n",
    "lv_scores = []\n",
    "for lv in range(sum(h_params.n_latents)):\n",
    "    found = {'subj':[], 'verb':[], 'dobj':[], 'pobj':[]}\n",
    "    for att, rel_pos in zip(att_maxes, rel_idx):\n",
    "        for k in found.keys():\n",
    "            if len(rel_pos[k]):\n",
    "                found[k].append(att[lv] in rel_pos[k])\n",
    "    lv_scores.append(found)\n",
    "\n",
    "baseline = []\n",
    "for k in ['subj', 'verb', 'dobj', 'pobj']:\n",
    "    all_pos = []\n",
    "    for pos in rel_idx:\n",
    "        all_pos.extend(pos[k])\n",
    "    baseline.append(np.median(all_pos))\n",
    "print(baseline)\n",
    "\n",
    "baseline_scores = []\n",
    "for lv in range(4):\n",
    "    found = {'subj':[], 'verb':[], 'dobj':[], 'pobj':[]}\n",
    "    for rel_pos in rel_idx:\n",
    "        for k in found.keys():\n",
    "            if len(rel_pos[k]):\n",
    "                found[k].append(baseline[lv] in rel_pos[k])\n",
    "    baseline_scores.append(found)\n",
    "            \n",
    "\n",
    "# found = {'subj':[], 'verb':[], 'dobj':[], 'pobj':[]}\n",
    "# for att, rel_pos in zip(att_maxes, rel_idx):\n",
    "#     for k in found.keys():\n",
    "#         if len(rel_pos[k]):\n",
    "#             found[k].append(att[lv][layer] in rel_pos[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========our Model ========\nScores for lv 0, layer 0:\n{'subj': 0.15490757615204373, 'verb': 0.31960823505896463, 'dobj': 0.3058161350844278, 'pobj': 0.22777777777777777}\nScores for lv 1, layer 0:\n{'subj': 0.03827128351991669, 'verb': 0.04797121726963822, 'dobj': 0.44934333958724204, 'pobj': 0.5645061728395062}\nScores for lv 2, layer 0:\n{'subj': 0.0036448841447539702, 'verb': 0.005996402158704777, 'dobj': 0.19277673545966229, 'pobj': 0.3021604938271605}\nScores for lv 3, layer 0:\n{'subj': 0.8646185889091382, 'verb': 0.15630621627023786, 'dobj': 0.00046904315196998124, 'pobj': 0.0015432098765432098}\n==== Final Scores =======\n{'subj': 0.8646185889091382, 'verb': 0.31960823505896463, 'dobj': 0.44934333958724204, 'pobj': 0.5645061728395062}\n{'subj': 0.7097110127570945, 'verb': 0.16330201878872677, 'dobj': 0.14352720450281425, 'pobj': 0.26234567901234573}\n{'subj': 3, 'verb': 0, 'dobj': 1, 'pobj': 1}\n========our baseline ========\nScores for lv 0, layer 0:\n{'subj': 0.8838844051028378, 'verb': 0.17409554267439536, 'dobj': 0.001876172607879925, 'pobj': 0.002777777777777778}\nScores for lv 1, layer 0:\n{'subj': 0.1780786253579797, 'verb': 0.2988207075754547, 'dobj': 0.2969043151969981, 'pobj': 0.21203703703703702}\nScores for lv 2, layer 0:\n{'subj': 0.05701640197865139, 'verb': 0.05276833899660204, 'dobj': 0.4629455909943715, 'pobj': 0.512962962962963}\nScores for lv 3, layer 0:\n{'subj': 0.028117677688102055, 'verb': 0.033379972016789924, 'dobj': 0.33911819887429645, 'pobj': 0.4648148148148148}\n==== Final Scores =======\n{'subj': 0.8838844051028378, 'verb': 0.2988207075754547, 'dobj': 0.4629455909943715, 'pobj': 0.512962962962963}\n{'subj': 0.7058057797448581, 'verb': 0.12472516490105934, 'dobj': 0.12382739212007504, 'pobj': 0.04814814814814816}\n{'subj': 0, 'verb': 1, 'dobj': 2, 'pobj': 2}\n"
     ]
    }
   ],
   "source": [
    "print(\"========our Model ========\")\n",
    "Enc_att_scores = {'subj':[], 'verb':[], 'dobj':[], 'pobj':[]}\n",
    "for lv in range(sum(h_params.n_latents)):\n",
    "    for layer in range(1):#h_params.encoder_l):\n",
    "        print(\"Scores for lv {}, layer {}:\".format(lv, layer))\n",
    "        print({k:np.mean(v)for k, v in lv_scores[lv].items()})\n",
    "        for k, v in lv_scores[lv].items():\n",
    "            Enc_att_scores[k].append(np.mean(v))\n",
    "print(\"==== Final Scores =======\")\n",
    "enc_max_score = {}\n",
    "enc_disent_score = {}\n",
    "enc_disent_vars = {}\n",
    "for k, v in Enc_att_scores.items():\n",
    "    sort_idx = np.argsort(v) \n",
    "    enc_disent_vars[k] = sort_idx[-1]\n",
    "    enc_disent_score[k] = v[sort_idx[-1]] - v[sort_idx[-2]]\n",
    "    enc_max_score[k] = v[sort_idx[-1]]\n",
    "print(enc_max_score)\n",
    "print(enc_disent_score)\n",
    "print(enc_disent_vars)\n",
    "print(\"========our baseline ========\")\n",
    "\n",
    "baseline_enc_att_scores = {'subj':[], 'verb':[], 'dobj':[], 'pobj':[]}\n",
    "for lv in range(sum(h_params.n_latents)):\n",
    "    for layer in range(1):#h_params.encoder_l):\n",
    "        print(\"Scores for lv {}, layer {}:\".format(lv, layer))\n",
    "        print({k:np.mean(v)for k, v in baseline_scores[lv].items()})\n",
    "        for k, v in baseline_scores[lv].items():\n",
    "            baseline_enc_att_scores[k].append(np.mean(v))\n",
    "print(\"==== Final Scores =======\")\n",
    "enc_max_score = {}\n",
    "enc_disent_score = {}\n",
    "enc_disent_vars = {}\n",
    "for k, v in baseline_enc_att_scores.items():\n",
    "    sort_idx = np.argsort(v) \n",
    "    enc_disent_vars[k] = sort_idx[-1]\n",
    "    enc_disent_score[k] = v[sort_idx[-1]] - v[sort_idx[-2]]\n",
    "    enc_max_score[k] = v[sort_idx[-1]]\n",
    "print(enc_max_score)\n",
    "print(enc_disent_score)\n",
    "print(enc_disent_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 'll never be going back\n(\"i 'll never be going back\", 'nsubj aux neg aux ROOT advmod')\ngreat food, great service\n('great food , service', 'amod ROOT punct appos')\ndecoration is outdated .\n('decoration is outdated .', 'nsubjpass auxpass ROOT punct')\nthe guy in front of us was ordering in spanish .\n('guy was ordering in .', 'nsubj aux ROOT prep punct')\nworst service ever .\n('worst service ever .', 'amod ROOT advmod punct')\nthe worst experience i have ever had at an enterprise location .\n('the worst experience had .', 'det amod ROOT relcl punct')\nwaitresses are slow\n('waitresses are slow', 'nsubj ROOT acomp')\nthis place is awful !\n('place is awful !', 'nsubj ROOT acomp punct')\n"
     ]
    }
   ],
   "source": [
    "ex_sents = [\"i 'll never be going back\", \"great food, great service\",\n",
    "            \"decoration is outdated .\",\n",
    "            \"the guy in front of us was ordering in spanish .\",\n",
    "            \"worst service ever .\", \"the worst experience i have ever had at an enterprise location .\",\n",
    "            'waitresses are slow', \"this place is awful !\"]\n",
    "import itertools\n",
    "def get_children(tok, depth):\n",
    "    if depth == 0:\n",
    "        return list(tok.children)\n",
    "    else:\n",
    "        return list(tok.children) + \\\n",
    "               list(itertools.chain.from_iterable([get_children(c, depth-1) for c in tok.children]))\n",
    "\n",
    "def truncated_template(sents, depth):\n",
    "    docs = nlp.pipe(sents)\n",
    "    templates = []\n",
    "    for doc in docs:\n",
    "        children = None\n",
    "        for i, tok in enumerate(doc):\n",
    "            if tok.dep_ =='ROOT':\n",
    "                children = [tok]+get_children(tok, depth)\n",
    "        if children is not None:\n",
    "            sort_dict_lex = {c.i:c.text for c in children}\n",
    "            sort_dict_syn = {c.i:c.dep_ for c in children}\n",
    "            templates.append({'lex': ' '.join([sort_dict_lex[i] for i in sorted(sort_dict_lex.keys())]),\n",
    "                              'syn': ' '.join([sort_dict_syn[i] for i in sorted(sort_dict_syn.keys())])})\n",
    "        else: \n",
    "            raise NotImplementedError(\"This sentence has no ROOT: \".format(' '.join([t.text for t in doc])))\n",
    "\n",
    "    \n",
    "docs = nlp.pipe(ex_sents)\n",
    "for doc in docs:\n",
    "    print(doc.text)\n",
    "    print(truncated_template(doc, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERB\n[{'text': {'subj': 'the man', 'verb': 'sat', 'dobj': '', 'pobj': 'a chair'}, 'idx': {'subj': [0, 1], 'verb': [3], 'dobj': [], 'pobj': [5, 6]}}, {'text': {'subj': '', 'verb': '', 'dobj': '', 'pobj': 'line'}, 'idx': {'subj': [], 'verb': [], 'dobj': [], 'pobj': [4]}}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "      \n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "ex_sents = ['the man has sat on a chair', 'a girl waiting in line']\n",
    "def shallow_dependencies(sents):\n",
    "    docs = nlp.pipe(sents)\n",
    "    relations = []\n",
    "    for doc in docs:\n",
    "        subj, verb, dobj, pobj = ['', []], ['', []], ['', []], ['', []]\n",
    "        for i, tok in enumerate(doc):\n",
    "            if tok.dep_ =='ROOT' and tok.pos_ == 'VERB':\n",
    "                verb = [tok.text, [tok.i]]\n",
    "            if tok.dep_ == 'nsubj' and subj[0] == '':\n",
    "                subj = [' '.join([toki.text for toki in tok.subtree]), [toki.i for toki in tok.subtree]]\n",
    "            if tok.dep_ == 'dobj' and dobj[0] == '':\n",
    "                dobj = [' '.join([toki.text for toki in tok.subtree]), [toki.i for toki in tok.subtree]]\n",
    "            if tok.dep_ == 'pobj' and pobj[0] == '':\n",
    "                pobj = [' '.join([toki.text for toki in tok.subtree]), [toki.i for toki in tok.subtree]]\n",
    "        relations.append({'text': {'subj': subj[0], 'verb': verb[0], 'dobj': dobj[0], 'pobj': pobj[0]},\n",
    "                         'idx': {'subj': subj[1], 'verb': verb[1], 'dobj': dobj[1], 'pobj': pobj[1]}})\n",
    "    return relations\n",
    "print(shallow_dependencies(ex_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0], [0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10], [1, 1], [1, 2], [1, 3], [1, 4], [1, 5], [1, 6], [1, 7], [1, 8], [1, 9], [1, 10], [2, 2], [2, 3], [2, 4], [2, 5], [2, 6], [2, 7], [2, 8], [2, 9], [2, 10], [3, 3], [3, 4], [3, 5], [3, 6], [3, 7], [3, 8], [3, 9], [3, 10], [4, 4], [4, 5], [4, 6], [4, 7], [4, 8], [4, 9], [4, 10], [5, 5], [5, 6], [5, 7], [5, 8], [5, 9], [5, 10], [6, 6], [6, 7], [6, 8], [6, 9], [6, 10], [7, 7], [7, 8], [7, 9], [7, 10], [8, 8], [8, 9], [8, 10], [9, 9], [9, 10], [10, 10]]\n['A', 'man', 'in', 'a', 'yellow', 'jacket', 'is', 'going', 'to', 'the', 'beach']\n(S (NP (NP (DT A) (NN man)) (PP (IN in) (NP (DT a) (JJ yellow) (NN jacket)))) (VP (VBZ is) (VP (VBG going) (PP (IN to) (NP (DT the) (NN beach))))))\n"
     ]
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a man in a yellow jacket', [0, 1, 2, 3, 4, 5]]] ['throwing', [7]] [['a ball and a towel in the beach', [8, 9, 10, 11, 12, 13, 14, 15]]] [['a yellow jacket', [3, 4, 5]]]\n"
     ]
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a man in a yellow jacket', [0, 1, 2, 3, 4, 5]]] ['throwing', [7]] [['a ball and a towel in the beach', [8, 9, 10, 11, 12, 13, 14, 15]]] [['a yellow jacket', [3, 4, 5]]]\n"
     ]
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a man in a yellow jacket', [0, 1, 2, 3, 4, 5]]] ['throwing', [7]] [['a ball and a towel in the beach', [8, 9, 10, 11, 12, 13, 14, 15]]] [['a yellow jacket', [3, 4, 5]]]\n"
     ]
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
