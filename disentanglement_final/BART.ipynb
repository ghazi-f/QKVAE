{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b97e0f2e99bae8b9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset csv (C:\\Users\\ghazy\\.cache\\huggingface\\datasets\\csv\\default-b97e0f2e99bae8b9\\0.0.0\\2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words:  50265 , On device:  cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Type:  VAE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction net size: 140.31 M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x to z1 size: 140.05 M\nx to zst size: 140.31 M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model at step 947715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupervised training examples:  493080\nUnsupervised val examples:  500.0\nNumber of parameters:  281.25 M\nInference parameters:  179.54 M\nGeneration parameters:  140.31 M\nEmbedding parameters:  38.60 M\n"
     ]
    }
   ],
   "source": [
    "# This file will implement the main training loop for a model\n",
    "from time import time\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "from torch import device\n",
    "import torch\n",
    "from torch import optim\n",
    "from transformers import Adafactor\n",
    "import numpy as np\n",
    "\n",
    "from disentanglement_final.data_prep import NLIGenData2, OntoGenData, HuggingYelp2, ParaNMTCuratedData, BARTYelp, \\\n",
    "    BARTParaNMT, BARTNLI\n",
    "from disentanglement_final.models import DisentanglementTransformerVAE, LaggingDisentanglementTransformerVAE\n",
    "from disentanglement_final.h_params import DefaultTransformerHParams as HParams\n",
    "from disentanglement_final.graphs import *\n",
    "from components.criteria import *\n",
    "parser = argparse.ArgumentParser()\n",
    "from torch.nn import MultiheadAttention\n",
    "# Training and Optimization\n",
    "k, kz, klstm = 2, 4, 2\n",
    "parser.add_argument(\"--test_name\", default='unnamed', type=str)\n",
    "parser.add_argument(\"--data\", default='nli', choices=[\"nli\", \"ontonotes\", \"yelp\", 'paranmt'], type=str)\n",
    "parser.add_argument(\"--csv_out\", default='disentqkv3.csv', type=str)\n",
    "parser.add_argument(\"--max_len\", default=17, type=int)\n",
    "parser.add_argument(\"--init_len\", default=None, type=int)\n",
    "parser.add_argument(\"--batch_size\", default=128, type=int)\n",
    "parser.add_argument(\"--grad_accu\", default=1, type=int)\n",
    "parser.add_argument(\"--n_epochs\", default=20, type=int)\n",
    "parser.add_argument(\"--test_freq\", default=16, type=int)\n",
    "parser.add_argument(\"--complete_test_freq\", default=128, type=int)\n",
    "parser.add_argument(\"--generation_weight\", default=1, type=float)\n",
    "parser.add_argument(\"--device\", default='cuda:0', choices=[\"cuda:0\", \"cuda:1\", \"cuda:2\", \"cpu\"], type=str)\n",
    "parser.add_argument(\"--embedding_dim\", default=128, type=int)#################\"\n",
    "parser.add_argument(\"--pretrained_embeddings\", default=False, type=bool)#################\"\n",
    "parser.add_argument(\"--z_size\", default=96*kz, type=int)#################\"\n",
    "parser.add_argument(\"--z_emb_dim\", default=192*k, type=int)#################\"\n",
    "parser.add_argument(\"--n_keys\", default=4, type=int)#################\"\n",
    "parser.add_argument(\"--n_latents\", default=[4], nargs='+', type=int)#################\"\n",
    "parser.add_argument(\"--text_rep_l\", default=3, type=int)\n",
    "parser.add_argument(\"--text_rep_h\", default=192*k, type=int)\n",
    "parser.add_argument(\"--encoder_h\", default=192*k, type=int)#################\"\n",
    "parser.add_argument(\"--encoder_l\", default=2, type=int)#################\"\n",
    "parser.add_argument(\"--decoder_h\", default=int(192*k), type=int)################\n",
    "parser.add_argument(\"--decoder_l\", default=2, type=int)#################\"\n",
    "parser.add_argument(\"--highway\", default=False, type=bool)\n",
    "parser.add_argument(\"--markovian\", default=True, type=bool)\n",
    "parser.add_argument('--minimal_enc', dest='minimal_enc', action='store_true')\n",
    "parser.add_argument('--no-minimal_enc', dest='minimal_enc', action='store_false')\n",
    "parser.set_defaults(minimal_enc=False)\n",
    "parser.add_argument('--use_bart', dest='use_bart', action='store_true')\n",
    "parser.add_argument('--no-use_bart', dest='use_bart', action='store_false')\n",
    "parser.set_defaults(use_bart=False)\n",
    "parser.add_argument(\"--losses\", default='VAE', choices=[\"VAE\", \"IWAE\" \"LagVAE\"], type=str)\n",
    "parser.add_argument(\"--graph\", default='Normal', choices=[\"Vanilla\", \"IndepInfer\", \"QKV\", \"SQKV\", \"HQKV\", \"HQKVDiscZs\"],\n",
    "                    type=str)\n",
    "parser.add_argument(\"--training_iw_samples\", default=1, type=int)\n",
    "parser.add_argument(\"--testing_iw_samples\", default=5, type=int)\n",
    "parser.add_argument(\"--test_prior_samples\", default=10, type=int)\n",
    "parser.add_argument(\"--anneal_kl0\", default=3000, type=int)\n",
    "parser.add_argument(\"--anneal_kl1\", default=6000, type=int)\n",
    "parser.add_argument(\"--zs_anneal_kl0\", default=7000, type=int)\n",
    "parser.add_argument(\"--zs_anneal_kl1\", default=10000, type=int)\n",
    "parser.add_argument(\"--zg_anneal_kl0\", default=7000, type=int)\n",
    "parser.add_argument(\"--zg_anneal_kl1\", default=10000, type=int)\n",
    "parser.add_argument(\"--anneal_kl_type\", default=\"linear\", choices=[\"linear\", \"sigmoid\"], type=str)\n",
    "parser.add_argument(\"--optimizer\", default=\"adam\", choices=[\"adam\", \"sgd\"], type=str)\n",
    "parser.add_argument(\"--grad_clip\", default=5., type=float)\n",
    "parser.add_argument(\"--kl_th\", default=0., type=float or None)\n",
    "parser.add_argument(\"--max_elbo1\", default=6.0, type=float)\n",
    "parser.add_argument(\"--max_elbo2\", default=4.0, type=float)\n",
    "parser.add_argument(\"--max_elbo_choice\", default=6, type=int)\n",
    "parser.add_argument(\"--kl_beta\", default=0.3, type=float)\n",
    "parser.add_argument(\"--kl_beta_zs\", default=0.1, type=float)\n",
    "parser.add_argument(\"--kl_beta_zg\", default=0.1, type=float)\n",
    "parser.add_argument(\"--dropout\", default=0.3, type=float)\n",
    "parser.add_argument(\"--word_dropout\", default=0.4, type=float)\n",
    "parser.add_argument(\"--l2_reg\", default=0, type=float)\n",
    "parser.add_argument(\"--lr\", default=2e-4, type=float)\n",
    "parser.add_argument(\"--lr_reduction\", default=4., type=float)\n",
    "parser.add_argument(\"--wait_epochs\", default=1, type=float)\n",
    "parser.add_argument(\"--save_all\", default=True, type=bool)\n",
    "\n",
    "flags, _ = parser.parse_known_args()\n",
    "# Manual Settings, Deactivate before pushing\n",
    "\n",
    "if True:\n",
    "    # flags.optimizer=\"sgd\"\n",
    "    flags.use_bart = True\n",
    "    flags.batch_size = 10\n",
    "    flags.max_len = 40\n",
    "    flags.test_name = \"nliLM/ParaQKVBARTmini_beta0.3.0.3.1.8\" #ParaQKVBARTminiThr_beta0.2.0.2.1.8.pth\" \n",
    "    flags.data = \"paranmt\"\n",
    "    flags.n_latents = [8]\n",
    "    flags.graph =\"QKV\"  \n",
    "    flags.kl_beta = 0.3\n",
    "    flags.max_elbo_choice = 6\n",
    "    flags.kl_beta_zs = 0.3\n",
    "    flags.z_size = 192\n",
    "    \n",
    "if flags.use_bart:\n",
    "    flags.decoder_h = 768\n",
    "    flags.encoder_h = 768\n",
    "    flags.embedding_dim = 768\n",
    "\n",
    "\n",
    "if flags.anneal_kl_type == \"sigmoid\" and flags.anneal_kl0 < flags.anneal_kl1:\n",
    "    flags.anneal_kl0, flags.anneal_kl1 = 2000, 500\n",
    "    flags.zs_anneal_kl0, flags.zs_anneal_kl1 = 4000, 500\n",
    "    flags.zg_anneal_kl0, flags.zg_anneal_kl1 = 4000, 500\n",
    "\n",
    "\n",
    "if flags.use_bart and flags.optimizer == \"adam\": flags.optimizer = \"adafactor\"\n",
    "OPTIMIZER = {'sgd': optim.SGD, 'adam': optim.Adam, \"adafactor\": Adafactor}[flags.optimizer]\n",
    "OPT_KWARGS = {'sgd': {'lr': flags.lr, 'weight_decay': flags.l2_reg},  # 't0':100, 'lambd':0.},\n",
    "              'adam': {'lr': flags.lr, 'weight_decay': flags.l2_reg, 'betas': (0.9, 0.99)},\n",
    "              'adafactor': {'lr': flags.lr, 'relative_step': False,\n",
    "                            'weight_decay': flags.l2_reg}}[flags.optimizer]\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "GRAPH = {\"Vanilla\": get_vanilla_graph,\n",
    "         \"IndepInfer\": get_BARTADVAE if flags.use_bart else get_structured_auto_regressive_indep_graph,\n",
    "         \"QKV\": get_qkv_graphBART if flags.use_bart else get_qkv_graph2,\n",
    "         \"SQKV\": get_min_struct_qkv_graphBART if flags.use_bart else None,\n",
    "         \"HQKV\": get_hqkv_graphBART if flags.use_bart else get_hqkv_graph,\n",
    "         \"HQKVDiscZs\": get_hqkv_graph_discrete_zsBART if flags.use_bart else get_hqkv_graph_discrete_zs}[flags.graph]\n",
    "if flags.graph == \"NormalLSTM\":\n",
    "    flags.encoder_h = int(flags.encoder_h/k*klstm)\n",
    "if flags.graph == \"Vanilla\":\n",
    "    flags.n_latents = [flags.z_size]\n",
    "if flags.losses == \"LagVAE\":\n",
    "    flags.anneal_kl0 = 0\n",
    "    flags.anneal_kl1 = 0\n",
    "Data = {\"nli\": BARTNLI if flags.use_bart else NLIGenData2, \"ontonotes\": OntoGenData,\n",
    "        \"yelp\": BARTYelp if flags.use_bart else HuggingYelp2,\n",
    "        \"paranmt\": BARTParaNMT if flags.use_bart else ParaNMTCuratedData}[flags.data]\n",
    "MAX_LEN = flags.max_len\n",
    "BATCH_SIZE = flags.batch_size\n",
    "GRAD_ACCU = flags.grad_accu\n",
    "N_EPOCHS = flags.n_epochs\n",
    "TEST_FREQ = flags.test_freq\n",
    "COMPLETE_TEST_FREQ = flags.complete_test_freq\n",
    "DEVICE = device(flags.device)\n",
    "# This prevents illegal memory access on multigpu machines (unresolved issue on torch's github)\n",
    "if flags.device.startswith('cuda'):\n",
    "    torch.cuda.set_device(int(flags.device[-1]))\n",
    "LOSSES = {'IWAE': [IWLBo],\n",
    "          'VAE': [ELBo],\n",
    "          'LagVAE': [ELBo]}[flags.losses]\n",
    "\n",
    "ANNEAL_KL = [flags.anneal_kl0*flags.grad_accu, flags.anneal_kl1*flags.grad_accu]\n",
    "ZS_ANNEAL_KL = [flags.zs_anneal_kl0*flags.grad_accu, flags.zs_anneal_kl1*flags.grad_accu]\n",
    "ZG_ANNEAL_KL = [flags.zg_anneal_kl0*flags.grad_accu, flags.zg_anneal_kl1*flags.grad_accu]\n",
    "LOSS_PARAMS = [1]\n",
    "if flags.grad_accu > 1:\n",
    "    LOSS_PARAMS = [w/flags.grad_accu for w in LOSS_PARAMS]\n",
    "\n",
    "data = Data(MAX_LEN, BATCH_SIZE, N_EPOCHS, DEVICE, pretrained=flags.pretrained_embeddings)\n",
    "h_params = HParams(len(data.vocab.itos), len(data.tags.itos) if (flags.data == 'yelp' and not flags.use_bart)\n",
    "                   else None, MAX_LEN, BATCH_SIZE, N_EPOCHS,\n",
    "                   device=DEVICE, vocab_ignore_index=data.vocab.stoi['<pad>'], decoder_h=flags.decoder_h,\n",
    "                   decoder_l=flags.decoder_l, encoder_h=flags.encoder_h, encoder_l=flags.encoder_l,\n",
    "                   text_rep_h=flags.text_rep_h, text_rep_l=flags.text_rep_l,\n",
    "                   test_name=flags.test_name, grad_accumulation_steps=GRAD_ACCU,\n",
    "                   optimizer_kwargs=OPT_KWARGS,\n",
    "                   is_weighted=[], graph_generator=GRAPH, z_size=flags.z_size, embedding_dim=flags.embedding_dim,\n",
    "                   anneal_kl=ANNEAL_KL, zs_anneal_kl=ZS_ANNEAL_KL, zg_anneal_kl=ZG_ANNEAL_KL,\n",
    "                   grad_clip=flags.grad_clip*flags.grad_accu, kl_th=flags.kl_th, highway=flags.highway,\n",
    "                   losses=LOSSES, dropout=flags.dropout, training_iw_samples=flags.training_iw_samples,\n",
    "                   testing_iw_samples=flags.testing_iw_samples, loss_params=LOSS_PARAMS, optimizer=OPTIMIZER,\n",
    "                   markovian=flags.markovian, word_dropout=flags.word_dropout, contiguous_lm=False,\n",
    "                   test_prior_samples=flags.test_prior_samples, n_latents=flags.n_latents, n_keys=flags.n_keys,\n",
    "                   max_elbo=[flags.max_elbo_choice, flags.max_elbo1],\n",
    "                   z_emb_dim=flags.z_emb_dim, minimal_enc=flags.minimal_enc, kl_beta=flags.kl_beta,\n",
    "                   kl_beta_zs=flags.kl_beta_zs, kl_beta_zg=flags.kl_beta_zg, anneal_kl_type=flags.anneal_kl_type)\n",
    "val_iterator = iter(data.val_iter)\n",
    "print(\"Words: \", len(data.vocab.itos), \", On device: \", DEVICE.type, flush=True)\n",
    "print(\"Loss Type: \", flags.losses)\n",
    "if flags.losses == 'LagVAE':\n",
    "    model = LaggingDisentanglementTransformerVAE(data.vocab, data.tags, h_params, wvs=data.wvs, dataset=data,\n",
    "                                                 enc_iter=data.enc_train_iter)\n",
    "else:\n",
    "    model = DisentanglementTransformerVAE(data.vocab, data.tags, h_params, wvs=data.wvs, dataset=data)\n",
    "if DEVICE.type == 'cuda':\n",
    "    model.cuda(DEVICE)\n",
    "\n",
    "# Redefining examples lengths:\n",
    "if flags.init_len is not None:\n",
    "    data.redefine_max_len(flags.init_len)\n",
    "    h_params.max_len = flags.init_len\n",
    "\n",
    "total_unsupervised_train_samples = len(data.train_iter)*BATCH_SIZE\n",
    "total_unsupervised_val_samples = len(data.val_iter)*(BATCH_SIZE/data.divide_bs)\n",
    "print(\"Unsupervised training examples: \", total_unsupervised_train_samples)\n",
    "print(\"Unsupervised val examples: \", total_unsupervised_val_samples)\n",
    "number_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: \", \"{0:05.2f} M\".format(number_parameters/1e6))\n",
    "number_parameters = sum(p.numel() for p in model.infer_bn.parameters() if p.requires_grad)\n",
    "print(\"Inference parameters: \", \"{0:05.2f} M\".format(number_parameters/1e6))\n",
    "number_parameters = sum(p.numel() for p in model.gen_bn.parameters() if p.requires_grad)\n",
    "print(\"Generation parameters: \", \"{0:05.2f} M\".format(number_parameters/1e6))\n",
    "number_parameters = sum(p.numel() for p in model.word_embeddings.parameters() if p.requires_grad)\n",
    "print(\"Embedding parameters: \", \"{0:05.2f} M\".format(number_parameters/1e6))\n",
    "\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['how about sorcery?', 'get off of a hamburger!', \"you're not gon na get it.\"]\n"
     ]
    }
   ],
   "source": [
    "model.gen_bn.clear_values(), model.infer_bn.clear_values(), torch.cuda.empty_cache()\n",
    "model.beam_size = 3\n",
    "text, samples, params = model.get_sentences(3, gen_len=20, sample_w=False, vary_z=True, complete=None,\n",
    "                                            contains=None, max_tries=100)\n",
    "\n",
    "# text = [sen.split(model.eos_symbol)[0].replace(model.go_symbol, '') for sen in text]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 6.00 GiB total capacity; 4.25 GiB already allocated; 1.56 MiB free; 4.33 GiB reserved in total by PyTorch)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-b4cc4c666c84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0malt_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malt_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_alternative_sentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_latents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"====== Changing Structure=======\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-->\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'|<'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'><'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malt_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'>'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0malt_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malt_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_alternative_sentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_latents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\disentanglement_qkv\\models.py\u001b[0m in \u001b[0;36m_get_alternative_sentences\u001b[1;34m(self, prev_latent_vals, params, var_z_ids, n_samples, gen_len, complete)\u001b[0m\n\u001b[0;32m    713\u001b[0m         \u001b[1;31m#     x_prev = torch.cat([x_prev, torch.argmax(samples_i, dim=-1)[..., -1].unsqueeze(-1)],\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;31m#                        dim=-1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 715\u001b[1;33m         \u001b[0mx_prev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_z2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode_to_text2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerated_v\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\disentanglement_qkv\\models.py\u001b[0m in \u001b[0;36mgenerate_from_z2\u001b[1;34m(self, z_input, x_prev, gen_len, only_z_sampling, temp, mask_unk, beam_size, keep_beam)\u001b[0m\n\u001b[0;32m   1246\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1247\u001b[0m                 \u001b[0mz_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mz_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1248\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_bn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'x_prev'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mz_i\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_bn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_to_v\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1249\u001b[0m             \u001b[0munk_mask_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munk_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munk_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munk_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1250\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0monly_z_sampling\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\components\\bayesnets.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, n_iw, target, eval, prev_states, force_iw, complete, lens, plant_posteriors)\u001b[0m\n\u001b[0;32m    164\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapproximator\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprev_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprev_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m                     lv(self.approximator[lv], lv_conditions, gt_samples=gt_lv, complete=(lv in self.child) or complete,\n\u001b[1;32m--> 166\u001b[1;33m                        lens=this_len)\n\u001b[0m\u001b[0;32m    167\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrep_net\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m                         \u001b[0mlv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprev_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapproximator\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\components\\latent_variables.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, link_approximator, inputs, prior, gt_samples, complete, lens)\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sequential_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink_approximator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink_approximator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\components\\latent_variables.py\u001b[0m in \u001b[0;36m_forward\u001b[1;34m(self, link_approximator, inputs, prior, gt_samples, complete, lens)\u001b[0m\n\u001b[0;32m    268\u001b[0m                       torch.cat([v for k, v in inputs.items() if k not in link_approximator.residual['conditions']],\n\u001b[0;32m    269\u001b[0m                                 dim=-1))\n\u001b[1;32m--> 270\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlink_approximator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_log_probas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposterior_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\components\\links.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, z_prev, lens)\u001b[0m\n\u001b[0;32m   1063\u001b[0m         \u001b[0mload_BART_kv_hacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer_dec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1064\u001b[0m         outputs = self.transformer_dec(inputs_embeds=targets, encoder_hidden_states=memory,\n\u001b[1;32m-> 1065\u001b[1;33m                                        output_attentions=self.get_att)\n\u001b[0m\u001b[0;32m   1066\u001b[0m         \u001b[0mclear_BART_kv_hacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer_dec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_att\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1051\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m                     \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1053\u001b[1;33m                     \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1054\u001b[0m                 )\n\u001b[0;32m   1055\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinal_layer_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 6.00 GiB total capacity; 4.25 GiB already allocated; 1.56 MiB free; 4.33 GiB reserved in total by PyTorch)"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "alt_text, alt_samples = model._get_alternative_sentences(samples, params, [sum(h_params.n_latents)], 3, 20, complete=None)\n",
    "print(\"====== Changing Structure=======\")\n",
    "for i in range(len(text)):\n",
    "    print(\"-->\", text[i], '|<', '><'.join(alt_text[i::len(text)]), '>')\n",
    "alt_text, alt_samples = model._get_alternative_sentences(samples, params, list(range(sum(h_params.n_latents))), 3, 20, complete=None)\n",
    "print(\"====== Changing Content=======\")\n",
    "for i in range(len(text)):\n",
    "    print(\"-->\", text[i], '|<', '><'.join(alt_text[i::len(text)]), '>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== BEAM SIZE: 2 ==================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 6.00 GiB total capacity; 4.22 GiB already allocated; 1.56 MiB free; 4.33 GiB reserved in total by PyTorch)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-545e1488d069>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeam_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"========== BEAM SIZE: {} ==================\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m \u001b[0msw_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msw_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswap_latents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msw_zs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_unk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-545e1488d069>\u001b[0m in \u001b[0;36mswap_latents\u001b[1;34m(mdl, prev_latent_vals, var_z_ids, gen_len, complete, no_unk)\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[1;31m#     x_prev = torch.cat([x_prev, torch.argmax(samples_i,     dim=-1)[..., -1].unsqueeze(-1)],\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[1;31m#                        dim=-1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[0mx_prev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_z2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m             \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode_to_text2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerated_v\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'z1'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0morig_z\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\disentanglement_qkv\\models.py\u001b[0m in \u001b[0;36mgenerate_from_z2\u001b[1;34m(self, z_input, x_prev, gen_len, only_z_sampling, temp, mask_unk, beam_size, keep_beam)\u001b[0m\n\u001b[0;32m   1244\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1245\u001b[0m                 \u001b[0mz_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mz_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1246\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_bn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'x_prev'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mz_i\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_bn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_to_v\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1247\u001b[0m             \u001b[0munk_mask_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munk_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munk_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munk_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0monly_z_sampling\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\components\\bayesnets.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, n_iw, target, eval, prev_states, force_iw, complete, lens, plant_posteriors)\u001b[0m\n\u001b[0;32m    164\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapproximator\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprev_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprev_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m                     lv(self.approximator[lv], lv_conditions, gt_samples=gt_lv, complete=(lv in self.child) or complete,\n\u001b[1;32m--> 166\u001b[1;33m                        lens=this_len)\n\u001b[0m\u001b[0;32m    167\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrep_net\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m                         \u001b[0mlv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprev_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapproximator\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\components\\latent_variables.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, link_approximator, inputs, prior, gt_samples, complete, lens)\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sequential_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink_approximator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink_approximator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\components\\latent_variables.py\u001b[0m in \u001b[0;36m_forward\u001b[1;34m(self, link_approximator, inputs, prior, gt_samples, complete, lens)\u001b[0m\n\u001b[0;32m    268\u001b[0m                       torch.cat([v for k, v in inputs.items() if k not in link_approximator.residual['conditions']],\n\u001b[0;32m    269\u001b[0m                                 dim=-1))\n\u001b[1;32m--> 270\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlink_approximator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_log_probas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposterior_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\components\\links.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, z_prev, lens)\u001b[0m\n\u001b[0;32m    924\u001b[0m         \u001b[0mload_BART_kv_hacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer_dec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m         outputs = self.transformer_dec(inputs_embeds=targets, encoder_hidden_states=memory,\n\u001b[1;32m--> 926\u001b[1;33m                                        output_attentions=self.get_att)\n\u001b[0m\u001b[0;32m    927\u001b[0m         \u001b[0mclear_BART_kv_hacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer_dec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_att\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1051\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m                     \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1053\u001b[1;33m                     \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1054\u001b[0m                 )\n\u001b[0;32m   1055\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[1;31m# Fully Connected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation_dropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mgelu\u001b[1;34m(input)\u001b[0m\n\u001b[0;32m   1367\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1368\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgelu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1369\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 6.00 GiB total capacity; 4.22 GiB already allocated; 1.56 MiB free; 4.33 GiB reserved in total by PyTorch)"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "def swap_latents(mdl, prev_latent_vals, var_z_ids, gen_len, complete=None, no_unk=True):\n",
    "            has_struct = 'zs' in mdl.gen_bn.name_to_v\n",
    "            has_zg = 'zg' in mdl.gen_bn.name_to_v\n",
    "            \n",
    "            \n",
    "            n_orig_sentences = prev_latent_vals['z1'].shape[0]\n",
    "            n_samples = n_orig_sentences\n",
    "            go_symbol = torch.ones([n_samples * n_orig_sentences]).long() * \\\n",
    "                        mdl.index[mdl.generated_v].stoi[mdl.go_symbol]\n",
    "            go_symbol = go_symbol.to(mdl.h_params.device).unsqueeze(-1)\n",
    "            x_prev = go_symbol\n",
    "            if complete is not None:\n",
    "                for token in complete.split(' '):\n",
    "                    x_prev = torch.cat([x_prev, torch.ones([n_samples * n_orig_sentences, 1]).long().to(mdl.h_params.device) * \\\n",
    "                        mdl.index[mdl.generated_v].stoi[token]], dim=1)\n",
    "                gen_len = gen_len - len(complete.split(' '))\n",
    "            temp = 1.\n",
    "            orig_z = prev_latent_vals['z1'].unsqueeze(1).repeat(1, n_samples, 1)\n",
    "            z_sample = orig_z.reshape(n_samples*n_orig_sentences, -1)\n",
    "            orig_z = orig_z.transpose(0, 1).reshape(n_samples*n_orig_sentences, -1)\n",
    "            if has_struct:\n",
    "                orig_zst = prev_latent_vals['zs'].unsqueeze(1).repeat(1, n_samples, 1)\n",
    "                zst_sample = orig_zst.reshape(n_samples*n_orig_sentences, -1)\n",
    "                orig_zst = orig_zst.transpose(0, 1).reshape(n_samples*n_orig_sentences, -1)\n",
    "            if has_zg:\n",
    "                orig_zg = prev_latent_vals['zg'].unsqueeze(1).repeat(1, n_samples, 1)\n",
    "                orig_zg = orig_zg.transpose(0, 1).reshape(n_samples*n_orig_sentences, -1)\n",
    "            \n",
    "\n",
    "            for id in var_z_ids:\n",
    "                if id < sum(h_params.n_latents):\n",
    "                    z_number = sum([id> sum(h_params.n_latents[:i+1]) for i in range(len(h_params.n_latents))])\n",
    "                    z_index = id - sum(h_params.n_latents[:z_number])\n",
    "                    start, end = int(h_params.z_size/max(h_params.n_latents)*z_index),\\\n",
    "                                 int(h_params.z_size/max(h_params.n_latents)*(z_index+1))\n",
    "                    source, destination = [z_sample][z_number], [orig_z][z_number]\n",
    "                    destination[:, start:end] = source[:, start:end]\n",
    "                elif id == sum(h_params.n_latents) and has_struct:\n",
    "                    orig_zst = zst_sample\n",
    "                else:\n",
    "                    raise IndexError(\"You gave a too high z_id for swapping with this model\")\n",
    "                    \n",
    "            z_input = {'z1': orig_z.unsqueeze(1), **({'zs':orig_zst.unsqueeze(1)} if has_struct else {}), \n",
    "                       **({'zg':orig_zg.unsqueeze(1)} if has_zg else {})}\n",
    "            \n",
    "            x_prev = mdl.generate_from_z2(z_input, x_prev, beam_size=mdl.beam_size)\n",
    "            text = mdl.decode_to_text2(x_prev, mdl.h_params.vocab_size, mdl.index[mdl.generated_v])\n",
    "            return text, {'z1': orig_z}\n",
    "sw_zs = [16]\n",
    "model.infer_bn.clear_values(), model.gen_bn.clear_values()\n",
    "torch.cuda.empty_cache()\n",
    "model.beam_size = 3\n",
    "print(\"========== BEAM SIZE: {} ==================\".format(model.beam_size))\n",
    "sw_text, sw_samples = swap_latents(model, samples, sw_zs, 40, complete=None, no_unk=True)\n",
    "print(text)\n",
    "for i in range(len(text)):\n",
    "    for j in range(len(text)):\n",
    "        if i!=j:\n",
    "            print(\"z_from: \", text[i], \"|z_to: \", text[j], \"|result: \", sw_text[len(text)*i+j])\n",
    "model.beam_size = 1\n",
    "print(\"========== BEAM SIZE: {} ==================\".format(model.beam_size))\n",
    "sw_text, sw_samples = swap_latents(model, samples, sw_zs, 40, complete=None, no_unk=True)\n",
    "print(text)\n",
    "for i in range(len(text)):\n",
    "    for j in range(len(text)):\n",
    "        if i!=j:\n",
    "            print(\"z_from: \", text[i], \"|z_to: \", text[j], \"|result: \", sw_text[len(text)*i+j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:   0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:   5%|         | 1/19 [00:02<00:45,  2.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  11%|         | 2/19 [00:04<00:42,  2.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  16%|        | 3/19 [00:07<00:40,  2.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  21%|        | 4/19 [00:09<00:37,  2.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  26%|       | 5/19 [00:12<00:34,  2.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  32%|      | 6/19 [00:15<00:35,  2.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  37%|      | 7/19 [00:19<00:35,  2.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  42%|     | 8/19 [00:21<00:30,  2.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  47%|     | 9/19 [00:24<00:27,  2.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  53%|    | 10/19 [00:26<00:24,  2.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  58%|    | 11/19 [00:29<00:21,  2.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  63%|   | 12/19 [00:32<00:19,  2.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  68%|   | 13/19 [00:35<00:16,  2.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  74%|  | 14/19 [00:37<00:13,  2.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  79%|  | 15/19 [00:40<00:10,  2.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  84%| | 16/19 [00:43<00:08,  2.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  89%| | 17/19 [00:46<00:05,  2.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  95%|| 18/19 [00:48<00:02,  2.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences: 100%|| 19/19 [00:51<00:00,  2.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences: 100%|| 19/19 [00:51<00:00,  2.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n\rGetting Model Swap TMA:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  10%|         | 1/10 [00:06<00:54,  6.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  20%|        | 2/10 [00:12<00:49,  6.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  30%|       | 3/10 [00:18<00:43,  6.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  40%|      | 4/10 [00:25<00:37,  6.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  50%|     | 5/10 [00:31<00:31,  6.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  60%|    | 6/10 [00:37<00:24,  6.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  70%|   | 7/10 [00:43<00:18,  6.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  80%|  | 8/10 [00:50<00:12,  6.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  90%| | 9/10 [00:56<00:06,  6.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA: 100%|| 10/10 [01:03<00:00,  6.35s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA: 100%|| 10/10 [01:03<00:00,  6.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating zs tma...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\lib\\site-packages\\supar\\utils\\alg.py:522: UserWarning: This overload of nonzero is deprecated:\n\tnonzero()\nConsider using one of the following signatures instead:\n\tnonzero(*, bool as_tuple) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:766.)\n  return [sorted(i.nonzero().tolist(), key=lambda x:(x[0], -x[1])) for i in marginals.permute(3, 0, 1, 2)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating zc tma...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating copy tma...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating bleu scores...\n"
     ]
    }
   ],
   "source": [
    "scores3 = model.get_swap_tma(200, 10, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tma2': {'zs': 53.0, 'zc': 39.0, 'copy': 39.0}, 'tma3': {'zs': 23.0, 'zc': 10.0, 'copy': 5.0}, 'bleu': {'zs': 4.301619841342148, 'zc': 5.329606584392295, 'copy': 2.907042530089797}}\n{'tma2': {'zs': 52.0, 'zc': 27.0, 'copy': 28.000000000000004}, 'tma3': {'zs': 21.0, 'zc': 4.0, 'copy': 2.0}, 'bleu': {'zs': 4.837286465792402, 'zc': 1.06716549568883, 'copy': 4.533625890054019}}\n{'tma2': {'zs': 46.2, 'zc': 38.0, 'copy': 34.699999999999996}, 'tma3': {'zs': 15.4, 'zc': 4.7, 'copy': 9.2}, 'bleu': {'zs': 5.6330959118116475, 'zc': 1.500889607364273, 'copy': 4.732771442981089}}\n"
     ]
    }
   ],
   "source": [
    "print(scores)\n",
    "print(scores2)\n",
    "print(scores3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tma2': {'zs': 56.99999999999999, 'zc': 42.0, 'copy': 41.0}, 'tma3': {'zs': 23.0, 'zc': 8.0, 'copy': 6.0}, 'bleu': {'zs': 7.672990358203783, 'zc': 3.623395667548363, 'copy': 2.1395611292167582}} {'tma2': {'zs': 54.0, 'zc': 43.0, 'copy': 35.0}, 'tma3': {'zs': 26.0, 'zc': 8.0, 'copy': 5.0}, 'bleu': {'zs': 15.2429080729265, 'zc': 0.0, 'copy': 2.7638331671257435}}\n"
     ]
    }
   ],
   "source": [
    "print(scores1, scores3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:   0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:   5%|         | 1/19 [00:03<01:01,  3.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  11%|         | 2/19 [00:06<00:55,  3.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  16%|        | 3/19 [00:09<00:50,  3.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  21%|        | 4/19 [00:12<00:46,  3.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  26%|       | 5/19 [00:15<00:44,  3.17s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  32%|      | 6/19 [00:18<00:40,  3.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  37%|      | 7/19 [00:21<00:36,  3.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  42%|     | 8/19 [00:24<00:32,  2.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  47%|     | 9/19 [00:27<00:29,  2.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  53%|    | 10/19 [00:29<00:26,  2.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  58%|    | 11/19 [00:32<00:23,  2.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  63%|   | 12/19 [00:35<00:20,  2.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  68%|   | 13/19 [00:38<00:17,  2.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  74%|  | 14/19 [00:41<00:14,  2.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  79%|  | 15/19 [00:44<00:11,  2.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  84%| | 16/19 [00:47<00:08,  2.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  89%| | 17/19 [00:50<00:05,  2.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  95%|| 18/19 [00:53<00:02,  2.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences: 100%|| 19/19 [00:56<00:00,  2.99s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences: 100%|| 19/19 [00:56<00:00,  2.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n\rGetting Model Swap TMA:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  10%|         | 1/10 [00:01<00:14,  1.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  20%|        | 2/10 [00:03<00:13,  1.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  30%|       | 3/10 [00:06<00:13,  1.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  40%|      | 4/10 [00:07<00:11,  1.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  50%|     | 5/10 [00:09<00:09,  1.81s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  60%|    | 6/10 [00:11<00:07,  1.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  70%|   | 7/10 [00:13<00:05,  1.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  80%|  | 8/10 [00:14<00:03,  1.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  90%| | 9/10 [00:16<00:01,  1.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA: 100%|| 10/10 [00:18<00:00,  1.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA: 100%|| 10/10 [00:18<00:00,  1.84s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating zs tma...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating zc tma...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating copy tma...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating bleu scores...\n"
     ]
    }
   ],
   "source": [
    "scores1 = model.get_swap_tma(200, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEHCAYAAABbZ7oVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA7T0lEQVR4nO3deXhU9fn38ffNYkARsAghgZogYKJgE0EIWpVYBFEpUdzAqqB9ymPVamn9tfjUq7W/aotVq1baUpcqWiuKLFGLERcCGg0IGGRLRDQoi1FBAsgiy/38cU6GmTBJTjIzmTmT+3VdczFz5iz3J6P5Zs73nO9XVBVjjDEmnFbxLsAYY0ziskbCGGNMnayRMMYYUydrJIwxxtTJGgljjDF1ahPvAqLp+OOP18zMzHiX0aC9e/fSrl27eJcRVZbJHyyTPzR3pmXLln2lql3DvZdUjURmZiZLly6NdxkN2r59O507d453GVFlmfzBMvlDc2cSkQ11vWenm4wxxtTJGgkPrr/+erp160b//v0Dy7Zt28bw4cPp27cvw4cP5+uvvwaguLiYUaNGBda74447OP/889m3b19g2cKFC5uv+GZimfzBMvlDImWyRsKDCRMmUFRUFLJsypQpDBs2jHXr1jFs2DCmTJlyxHZ33303JSUlzJ07l5SUlOYq1xhjoiap+iRi5ZxzzqGysjJkWWFhIcXFxQCMHz+e/Px87rnnnsD7999/P/PmzePVV1+lffv2zVitMQZg//79bNy4kb1798a7lEbr2bMna9eujfp+27VrR8+ePWnbtq3nbayRaKKqqirS0tIASEtL44svvgi8V1JSQkVFBcuWLaNDhw5HbJuVldVsdTYXy+QPLSnTxo0bOfbYY8nMzEREmrmqyOzZsyfqf1yqKlu3bmXjxo306tXL83Z2uikG+vTpg6oyf/78sO9nZ2c3c0WxZ5n8oSVl2rt3L126dPFdAwHE5OyDiNClS5dGf7OyRgL49NNq1q79slHbpKamsmXLFgC2bNlCt27dQt6bN28ekyZNYsGCBUdsW7t/IxlYJn9oaZn82EAAVFdXx2S/Tfl5tPhG4t13P6Nv34c55ZS/89hjyz1vN3r0aKZPnw7A9OnTKSgoCHn/pJNOYvbs2Vx99dWUlZWFvBd8pVOysEz+YJn8IZGmcLBG4t2NfPvtQQAWLgx/P8m4ceM444wzqKiooGfPnjz++ONMnjyZ1157jb59+/Laa68xefLkI7YbNGgQTzzxBKNHj2b9+vUxzWGMSSz5+fm8+uqrIcsefPBBbrzxRtatW8eoUaPo3bs3AwcO5Nxzz2XRokVUVlbSs2dPDh06FLJdbm4uS5YsAeCBBx6gXbt2Id82iouL6dSpE7m5uYHH66+/Hp0gqpo0j4EDB2pjff75Tv3+9x/Xk0+eqsuXb2709k2xYMGCZjlOc7JM/tCSMq1Zs6Z5C6ll2rRpOmHChJBleXl5umjRIu3bt68WFhYGlq9cuVKfeOIJVVUdMmSIzps3L/De2rVr9cQTTwy8HjRokJ511lmB9VWdn8FFF13kqa5wPxdgqdbxe7XFf5NITe3A229fz5o1N3HaaWnNcsz8/PxmOU5zskz+YJnq99ZbG3jmmQ/4/PNdEe/rsssu4+WXXw6cDqusrGTz5s18+OGHnHHGGYwePTqwbv/+/ZkwYQLgnLl48cUXA+/NmDGDcePGAbB+/Xp27drFXXfdxbPPPhtxjV60+EYiHmr3USQDy+QPlqluf/5zCeec8yRXXz2H3NxpfPppZJ3HXbp0YfDgwYGO9RkzZnDllVeyevVqBgwYUOd2V1xxBXPmzOHAgQMAPPfcc4wdOxaAZ599lnHjxnH22WdTUVERcun9W2+9FXK6KVqnuK2RiIMNG+ocS8u3LJM/WKa6PfTQ4sDzqqpveO65VRHvc9y4ccyYMQMI/UYQ7JJLLqF///6MGTMGgO7du5Odnc0bb7xBWVkZbdu2DQwJNGPGDMaOHUurVq0YM2YMM2fODOzn7LPPpqysLPDo3bt3xPWDNRLGGAPAcceFDs39ne9Efq/CxRdfzBtvvMHy5cvZs2cPAwYMoF+/fixffvhKyjlz5vDkk0+ybdu2wLJLL72UGTNmhDQsH3zwAevWrWP48OFkZmYyY8aMZjnlZI2EMcYA//pXAenpxyICV17Zj/HjcyPeZ4cOHcjPz+f6668P/LK/6qqrKCkpCel32L17d8h2o0ePZt68eUecarrzzjuprKwM9G9s2rQp9t8O6+rRjsYD+BfwBbAqaNl3gNeAde6/x9Wx7UigAvgImOzleE25uikedu/eHe8Sos4y+UNLytTUq5u+/fZAJOUcYfbs2Qro2rVrA8vWrl2rF1xwgfbq1UuHDBmiw4cP19deey3w/sGDB3X06NGal5cXWJaZmRmyD1XVSZMm6ZQpU3TBggXasWNHzcnJCTxmzpwZtp7GXt0kGsObNkTkHGAX8JSq9neX/RnYpqpTRGSy20j8utZ2rYEPgeHARuA9YJyqrqnveKeffrr6YdKhzz//nO7du8e7jKiyTP7QkjKtXbuWk08+OQ4VRW7//v2NGoSvMcL9XERkmaqeHm79mJ5uUtVFwLZaiwuA6e7z6cDFYTYdDHykqh+r6rfADHe7pLB48eKGV/IZy+QPlskfvvnmm3iXEBCPPolUVd0C4P7bLcw6PYDPgl5vdJcZY4xpRok6VHi4UajCnhcTkYnARID09HQKCwsD7w0dOhQIneUpKyuL7OxsioqKAje5dOrUifz8fMrKykI6gUaMGEF1dXXIXyo5OTlkZmaGHCc1NZUhQ4ZQWlpKVVVVYHlBQQGVlZWsWLEisCwvLw8gZPuMjAxyc3MpLi4O3GqfkpLCyJEjKS8vp6KiwjJZJsvUyEx79+5l+/btgDOwXadOndizZ0/IWE81Q/nv2nX45rmUlBTat29PdXV1YAyl1q1bc+yxx7J7926+/fbbwLodO3bk4MGDIX/5t2/fnpSUlMCxAdq0aUOHDh3YtWtX4P4HgM6dO7Nv3z727NkTWHbMMccAhGx/1FFHcfTRR7Nz504OHjwYUabdu3dTWFgY8jnVJ6Z9EgAikgm8HNQnUQHkq+oWEUkDilU1q9Y2ZwB3qur57uvbAVT1T/Udyy99EpWVlWRmZsa7jKiyTP7QkjL5uU9i3759MZvNMiZ9EiJyjIi0CnrdSkSObmKNLwLj3efjgcIw67wH9BWRXiJyFDDW3S4pJNv/pGCZ/MIyefDuu9HdXxMk0nTHXvsk3gCCG4WjgQaHGBSRZ4F3gSwR2SgiPwamAMNFZB3O1UtT3HXTRWQegKoeAG4GXgXWAs+r6mqPtSa84K/GycIy+YNlakBFBfzhD9HbXxMFn2qKN6+NRDtVDZzgcp83+E1CVcepapqqtlXVnqr6uKpuVdVhqtrX/Xebu+5mVb0waNt5qnqSqvZW1bsbG8wYYxpt1ix44w2I4qQ/GzdupKCggL59+3LiiSdy8803s2/fPoqLixk1alRgvTvuuIPzzz+f22+/nd///vch+ygrKws5RZSTk3PEEB8TJkygV69egbGbzjzzzKjU77WR+EZEAiNSichAYE896xtjjP/MmgXffgsvvRSV3akqY8aM4eKLL2bdunWsW7eOPXv28Ktf/SpkvbvvvpuSkhLmzp3LhAkTmDNnTsj7M2bM4KqrrgKcPoVDhw6xaNGiIy6VvffeewNjN73zzjtRyeD16qZbgZkistl9nQZcGZUKWqDU1NR4lxB1lskfLFOQpUsheFa7bdugZkyl6dOhV6/Q9Xv1gvT0Rh3izTffpF27dlx33XWAc5XUAw88QEZGBsOHDwfg/vvvZ968ebz66qu0b9+erKwsOnfuzOLFiwNXbz3//POBCYz+85//cM0117B27VpefPHFsIMGRlODjYR79/PZQDaQhXN5armq7o9pZUlsyJAh8S4h6iyTP1imIK1awXXXwbp1R773+uvOo8ZNN8F99zX6EKtXr2bgwIEhyzp27EhmZiYfffQRJSUlVFRUsGzZssClqwA/+tGPmDFjBnl5eZSWltKlSxf69u0LOEOHv/baa1RUVDB16tSQRuJ//ud/uOuuuwDo168fzzzzTKNrrq3B002qehAoUNX9qrpKVVdaAxGZ0tLSeJcQdZbJHyxTkAEDnG8O48fXvU6XLlBYCFOnQrt2da9XB1VF5MjbvmpuPejTpw+qyvz580Pe/+EPf8gLL7zAoUOHQkaCfe+99+jatSsZGRkMGzaM5cuX8/XXXwe2Cz7dFI0GArz3SZSIyFQROVtEBtQ8olJBCxR8g1CysEz+YJlq6dABnnzSaQRqy8yEFSsgaAa5xurXrx+1793asWMHVVVVZGVlkZqayrx585g0aRILFiwIrNO9e3cyMzNZuHAhs2bN4oorrgCckWDLy8vJzMykd+/e7Nixg1mzZjW5Pi+8NhJnAv2A/wXudx+N/+5ljDGJ6NChI5d99ZXzTSICw4YNY/fu3Tz11FMAHDx4kF/+8pfcfPPNtG/vzFdx0kknMXv2bK6++uqQu5/HjRvHpEmT6N27Nz179uTQoUPMnDmTDz74IDBceGFhYcznlPDUSKjquWEeP4hpZcYY01xq/hrPyIAbbgAR2LUL3M7iphIR5syZwwsvvEDfvn3p0qULrVq14je/+U3IeoMGDeKJJ55g9OjRgWlHL7/8clavXh2YT2LRokX06NGDHj0OD2N3zjnnsGbNGrZs2QI4fRLBU5gGDyHSZHWNIa6hczvcCnTE6bR+DFgOjPCybXM+/DKfhDEm9jzPJ1FVpdqqlerll6t+/bWz7LXXVLt3V73mmqjWVFJSoieccIIuXbo0qvttjMbOJ+H1dNP1qroDGIEzaut1uHdKm8arrKyMdwlRZ5n8wTKFMX8+TJsGzz8PnTs7y847Dz74AA4ehP3Ru07nzDPPZMOGDUdc8VRb8IB98ea1kajpnr8QeEJVVxB+pFbjQfAolsnCMvmDZQrjiivgJz85cnnXrvDvf0e27yYKHhU23rw2EstEZD5OI/GqiBwLhOnpMcaYxKFeRrk+6qi63xOBGM0QFw+efh61eG0kfgxMBgap6m7gKJxTTgCISL9GH9kYY2KoXbt2bN26tUm/GJORqrJ161baNfJ+D0/DcqjqIZzO6prXW4GtQas8Ddh9Ex7V3GqfTCyTP7SkTD179mTjxo18+eWXzVxR5A4ePBi4Yima2rVrR8+ePRu1TbRmprP+iUbo1KlTvEuIOsvkDy0pU9u2belVe/wln9izZ0/gPop4i9Yc1/Z9rhFq34KfDCyTP1gmf0ikTNFqJIwxxiShaDUSUbitzxhjTKLx3CchIj2AjOBtVHWR+2/yjT8cQxkZGfEuIeoskz9YJn9IpEzi5fIwEbkHZ5KhNcBBd7GqatOHR4yB008/XWuPuGiMMaZ+IrJMVU8P957X000XA1mqeqGq/tB9JFQD4SfFxcXxLiHqWlKmzz77jHPPPZeTTz6Zfv368dBDDwFw55130qNHj8DgavPmzQvsJ9xcxvEYeqElfU5+lkiZvJ5u+hhoCyTOgCI+Vh3FSdYTRUvK1KZNG+6//34GDBjAzp07GThwYGAqykmTJnHbbbfVuc+auYznzZtHSkpKTOquT0v6nPwskTJ5bSR2A2Ui8gZBDYWq3tLUA4vIrcBPcO6xeFRVH6z1fj5QCHziLpqtqv/b1OMZEy1paWmkpaUBcOyxx3LyySezadOmBrerPZexMX7gtZF40X1EhYj0x2kgBuNcGVUkIv9V1dqTzb6lqqOO2IHPxeMvyFhrqZkqKyt5//33ycvLo6SkhKlTp/LUU09x+umnc//993PccccB1DmXcXNrqZ+T3yRSJq99EluBp1V1evAjguOeDJSq6m5VPQAsBC6JYH++MnLkyHiXEHXJlmnNmi/p02dwvevs2rWLSy+9lAcffJCOHTvy05/+lPXr11NWVkZaWhq//OUvA+vWNZdxc0u2zwksU6x5/SYxFnhIRGbhDBW+NsLjrgLuFpEuwB6c0WXDXZZ0hoisADYDt6nq6toriMhEYCJAeno6hYWFgfeGDh0KwMKFCwPLsrKyyM7OpqioKNBx2KlTJ/Lz8ykrK2PDhg2BdUeMGEF1dTWLFy8OLMvJySEzMzPkOKmpqQwZMoTS0tKQ+XYLCgqorKwMGco4Ly+Pr776KjD7FDiXu+Xm5lJcXBw4F5mSksLIkSMpLy+noqLCMjVTpm+/PcQf//gJZWU7ATj77M5MmpRBq1YSkmnr1q3cddddDBo0iDFjxhyR6corr+TKK6+ksLCQlStXAvDwww8zceJE1q9fT3Z2tn1OlilhMtWrrtmIaj9wZqb7v0Ap8C7OL+ZjvW4fZn8/xhk0cBEwDXggzPE6uM8vBNY1tE+/zEw3d+7ceJcQdcmS6dFHlyncGfJ4+eWKkHUOHTqk11xzjd56660hyzdv3hx4/pe//EWvvPJKVVVdsGCBXnTRRaqqumTJEk1PT9f3338/pjnqkiyfUzDLFDmiMDMd6sxMNwuYAaThnB5aLiI/87qPWvt7XFUHqOo5wDZgXa33d6jqLvf5PKCtiBzflGMZ41Vl5fYGl5WUlPD000/z5ptvhlzu+qtf/YpTTz2V733veyxYsIAHHnjgiH2Fm8vYmETm6XSTiPwQuB7ojTMs+GBV/UJEjgbWAg839sAi0s3dxwnAGOCMWu93B6pUVUVkME7/ydYwuzImasaMOZkpU97m4EHnJtP27dswatRJIeucddZZYecouPDCC8PuMz8/n/z8/MDrESNG8Omnn0avaGNiyGufxOU4p4MWBS9U1d0icn0Tjz3L7ZPYD9ykql+LyA3ufqcBlwE/FZEDOP0WYzXc/5k+VHPOMJkkS6YBA9KYN+9HPPzwEkQOcvvtQ8nI6BzvsqImWT6nYJYptrw2Ej/F+UWNiJwEZAOvqOp+VX2jKQdW1bPDLJsW9HwqMLUp+zYmEiNG9GbEiN5s376dzp07x7scY+LKa5/EIqCdO8jfGzhTlz4Zq6KSXfBVB8nCMvmDZfKHRMrktZEQdea2HgM8rKqXAKfErixjjDGJwHMjISJnAD8C/usui9bUp8YYYxKU10biVuB2YI6qrhaRE4EFsSsruWVlZcW7hKizTP5gmfwhkTJ5mk/CL2w+CWOMabxozCdhoqioqCjeJUSdZfIHy+QPiZTJGok4iMdkM7FmmfzBMvlDImWyRsIYY0yd6r1CSUQeBurstNAIJh1qyTp16hTvEqLOMvmDZfKHRMpUb8e1iIx3n34f576I59zXlwPLVHVSbMtrHOu4NsaYxmtyx7UenlyoL3Cuqj6sqg8Dw4DcqFfaQjQ4frsPWSZ/sEz+kEiZvPZJpAPHBr3u4C4zTRA8aUmysEz+YJn8IZEyeb1regrwvojU3EA3FLgzJhUZY4xJGJ4aCVV9QkReAfLcRZNV9fPYlWWMMSYReL7j2h0BNoOghqX2/BLx5peO6z179tC+fft4lxFVlskfLJM/NHem+jquvc5Mdw9wJbAaOOQuVpwhxE0jVVdXJ91/1JbJHyyTPyRSJq8d1xcDWap6kar+0H2MjmFdSW3x4sXxLiHqLJM/WCZ/SKRMXhuJj4G2sSzEGGNM4vF6ddNuoExE3gACg4rYHdfGGJPcvDYSL7oPEwU5OTnxLiHqLJM/WCZ/SKRMNp+EMca0cBHPJyEifUXkBRFZIyIf1zwiLOpWEVklIqtF5Odh3hcR+auIfCQiH4jIgEiOl0gKCwvjXULUWSZ/sEz+kEiZvHZcPwH8AzgAnAs8BTzd1IOKSH/gJ8BgIAcYJSJ9a612Ac6YUX2Bie7xjTHGNCOvjUR7VX0D5/TUBlW9E/hBBMc9GShV1d2qegBYCFxSa50C4Cl1lAKdRSQtgmMaY4xpJK8d13tFpBWwTkRuBjYB3SI47irgbhHpAuwBLgRqdyb0AD4Ler3RXbYleCURmYjzTYP09PSQr2lDhw4FYOHChYFlWVlZZGdnU1RUFJj9qVOnTuTn51NWVhYysNaIESOorq4OuWY5JyeHzMzMkOOkpqYyZMgQSktLqaqqCiwvKCigsrKSFStWBJbl5eVx/PHHh2yfkZFBbm4uxcXFVFdXA5CSksLIkSMpLy+noqLCMlkmy2SZYpapPp46rkVkELAW6Az8AegI3Ov+hd8kIvJj4CZgF7AG2BM8P4WI/Bf4k6q+7b5+A/iVqi6ra5/WcW2MMY0Xcce1qr6nqrtUdaOqXqeql0bSQLj7fFxVB6jqOcA2YF2tVTYC3w163RPYHMkxE0VpaUQ/uoRkmfzBMvlDImWK2xzXItLN/fcEYAzwbK1VXgSuda9yGgJUq+oWkkDw181kYZn8wTL5QyJl8tonEQuz3D6J/cBNqvq1iNwAoKrTgHk4fRUf4dzxfV3cKjXGmBYqbo2Eqp4dZtm0oOeK02dhjDEmTrx2XP8ZuAvnSqQinHsbfq6q/45teY1jHdfGGNN4EXdcAyNUdQcwCqdD+STgf6JUX4tTWVkZ7xKizjL5g2Xyh0TK5LWRqBkm/ELgWVXdFqN6WoTga6KThWXyB8vkD4mUyWufxEsiUo5zuulGEekK7I1dWcYYYxKB128SvwPOAE5X1f04VxvZzHTGGJPkvDYS76rq16p6EEBVvwFeiV1ZyS0vLy/eJUSdZfIHy+QPiZSp3tNNItIdZ7yk9iJyGiDuWx2Bo2NcW9Lq1KlTvEuIOsvkD5bJHxIpU0PfJM4H7sMZEuMvwP3u4xfA/4ttaclr/vz58S4h6iyTP1gmf0ikTPV+k1DV6cB0EblUVWc1U03GGGMShNerm/qLSL/aC1X1f6NcjzHGmATitZHYFfS8Hc5NdWujX07LkJGREe8Sos4y+YNl8odEyuRpWI4jNhJJAV5U1fOjX1LT2bAcxhjTeNEYlqO2o4ETm15Sy1ZcXBzvEqLOMvmDZfKHRMrk6XSTiKwEar5ytAa6AtYf0UQ10w8mE8vkD5bJHxIpk9c+iVFBzw8AVap6IAb1GGOMSSCeGglV3SAiA4CzcL5RvA28H8vCkllKSkq8S4g6y+QPlskfEimT1/kkfgtcDsx2F10MzFTVu2JXWuNZx7UxxjReNDquxwGDVPV3qvo7YAjwo2gV2NKUl5fHu4Sos0z+YJn8IZEyeW0kKnHuj6iRAqyPejUtREVFRbxLiDrL5A+WyR8SKZPXjut9wGoReQ2nT2I48LaI/BVAVW+JUX3GGGPiyGsjMcd91CiOfinGGGMSjdeO61tV9aGGljXqwCKTgP+D881kJXCdqu4Nej8fKAQ+cRfNbmisKL90XG/fvp3OnTvHu4yoskz+YJn8obkzRaPjenyYZRMiKKgHcAvOTHf9cW7QGxtm1bdUNdd92M17xhjTzOptJERknIi8BPQSkReDHguArREeuw3OZEZtcIb52Bzh/nxj4cKF8S4h6iyTP1gmf0ikTA31SbwDbAGOx5lsqMZO4IOmHlRVN4nIfcCnwB5gvqqGm2XjDBFZgdOA3Kaqq2uvICITgYkA6enpFBYWBt4bOnQoEPoDz8rKIjs7m6KiIvbt2wc4s0Dl5+dTVlbGhg0bAuuOGDGC6upqFi9eHFiWk5NDZmZmyHFSU1MZMmQIpaWlVFVVBZYXFBRQWVnJihUrAstqpiUM3j4jI4Pc3FyKi4sDt+OnpKQwcuRIysvLQ650sEyWyTJZpmhnqpeqNvsDOA54E2cMqLbAXODqWut0BDq4zy8E1jW034EDB6ofzJ07N94lRJ1l8gfL5A/NnQlYqnX8XvXUJyEiO0Vkh/vYKyIHRWSHl23rcB7wiap+qar7ce7kPrNW47VDVXe5z+cBbUXk+AiOmTCysrLiXULUWSZ/sEz+kEiZvI7ddGzwaxG5GBgcwXE/BYaIyNE4p5uGASGXJYlId5yBBFVEBuP0n0TaD5IQsrOz411C1Fkmf7BM/pBImZo0n4SqzgV+0NSDqupi4AVgOc7lr62AR0TkBhG5wV3tMmCV2yfxV2Cs+7XI94qKiuJdQtRZJn+wTP6QSJm8zicxJuhlK+B0Ds8v0STqjAH1u1qLpwW9PxWYGskxElVNx1EysUz+YJn8IZEyeb3j+odBzw/gjOVUEPVqjDHGJBSvfRLXxbqQlqRTp07xLiHqLJM/WCZ/SKRMXofl6Ak8DHyfw5MO3aqqG2NbXuP4ZVgOY4xJJNEYluMJ4EUgHegBvOQuM03Q4M0rPmSZ/MEy+UMiZfLaSHRV1SdU9YD7eBLnRjjTBMF3bCYLy+QPlskfEimT10biKxG5WkRau4+rSZJ7FowxxtTNayNxPXAF8DnOWE6XucuMMcY0s8zMTE499VRyc3M5/XSnK2Hbtm0MHz6cvn37Mnz4cL7++msAiouLGTVqVGDbO+64g/PPP9/zZbaeGglV/VRVR6tqV1XtpqoXq2rifB/ymREjRsS7hKizTP5gmfzBS6YFCxZQVlZGzcU6U6ZMYdiwYaxbt45hw4YxZcqUI7a5++67KSkpYe7cuaSkpHiqpUl3XJvI1IzimEwskz9YJn9oSqbCwkLGj3em/hk/fjxz584Nef/+++9n3rx5vPTSS7Rv397zfq2RiIPgYYWThWXyB8vkDw1lEhFGjBjBwIEDeeSRRwCoqqoiLS0NgLS0NL744ovA+iUlJUybNo1XXnmFDh06NKoWaySMMSZBTJ26hL59H+ayy1Zw5pmP8+qrH4Vdr6SkhOXLl/PKK6/wt7/9jUWLFtW73z59+qCqzJ8fbtqe+nkduykFuBTIDN5GbUpRY4yJij/+8S1+85s3A6/ffXcjF130H1577RrOPbdXyLrp6ekAdOvWjUsuuYQlS5aQmprKli1bSEtLY8uWLXTr1i2wfmpqKs888wzDhg2jS5cunHvuuZ7r8vpNohBnrKYDwDdBD9MEOTk58S4h6iyTP1imxLR37wHuu++dI5YfPKhMmVISsuybb75h586dgefz58+nf//+jB49munTpwMwffp0CgpCh9c76aSTmD17NldffXWjbtbzOsBfT1Ud6Xmvpl6ZmZnxLiHqLJM/WKbEtGnTDr7+em/Y91aurAp5XVVVxSWXXALAgQMHuOqqqxg5ciSDBg3iiiuu4PHHH+eEE05g5syZR+xr0KBBPPHEE4wePZoFCxbQu3fvBmvzOnbTI8DDqrqywZXjyC9jNxUWFh7RyvudZfIHy5SYdu/eT/fu97Fz57dHvDd0aAbFxRNievxojN10FrBMRCpE5AMRWSkiH0SvRGOMabmOProtN9006IjlInDbbWeG2aL5eD3ddEFMqzDGmBbu7ruH0a5dG6ZOfY+vvtpNVlYX7rwzn1GjToprXV7vuN4AfBf4gft8t9dtzZFSU1PjXULUWSZ/sEyJq1Ur4Xe/y+fzz3/J668Po7z8ZsaO7R/vsjz3SfwOZ8rSLFU9SUTSgZmq+v1YF9gYfumTMMaYRBKNPolLgNG4l72q6mbg2OiU1/KUlpbGu4Sos0z+YJn8IZEyeW0kvlXnK4cCiMgxsSsp+VVVVTW8ks9YJn+wTP6QSJm8NhLPi8g/gc4i8hPgdeDRSA4sIpNEZLWIrBKRZ0WkXa33RUT+KiIfuVdUDYjkeMYYYxrPa8f1fcALwCwgC/itqj7c1IOKSA/gFuB0Ve0PtAbG1lrtAqCv+5gI/KOpxzPGGNM0njquAUQkA+irqq+LyNFAa1Xd2aSDOo1EKZAD7ADmAn9V1flB6/wTKFbVZ93XFUC+qm6pa7/WcW2MMY1XX8e11wH+foLz1/x3gN5AD2AaMKwpBanqJhG5D/gU2APMD24gXD2Az4Jeb3SXhTQSIjLRrY309HQKCwsD7w0dOhSAhQsXBpZlZWWRnZ1NUVFRYGamTp06kZ+fT1lZWcjcsiNGjKC6ujpk2N6cnBwyMzNDjpOamsqQIUMoLS0NOZdYUFBAZWUlK1asCCzLy8tj586drFmzJrAsIyOD3NxciouLA+PIp6SkMHLkSMrLy6moqLBMlskyWaaYZaqXqjb4AMqAo4D3g5at9LJtHfs7DngT6Aq0xfkmcXWtdf4LnBX0+g1gYH37HThwoPrB3Llz411C1Fkmf7BM/tDcmYClWsfvVa8d1/tUNTCoiIi0wb3SqYnOAz5R1S9VdT8wG6h97/lGnBv4avQENkdwTGOMMY3ktZFYKCL/D2gvIsOBmcBLERz3U2CIiBwtIoJz2mptrXVeBK51r3IaAlRrPf0Rxhhjos9rIzEZ+BJYCfxfYB5wR1MPqqqLca6WWu7usxXwiIjcICI3uKvNAz4GPsK53PbGph4v0eTl5cW7hKizTP5gmfwhkTJ5HZbjB0Cpqu6OfUlN55erm/bs2dOoicj9wDL5g2Xyh+bOFI1hOSYAZSLyroj8WUR+KCLHRa3CFqYp88wmOsvkD5bJHxIpk6dLYFX1WgB3YL/LgL8B6V63N8YY409e75O4GjgbOBX4CpgKvBXDuowxxiQAr98EHgTW49xAt0BVK2NVUEuQkZER7xKizjL5g2Xyh0TK1JhhOfoB5+BMZdoXqFDVa2JYW6P5pePaGGMSScQd1yLSETgByAAygU5EdjNdi1ZcXBzvEqLOMvmDZfKHRMrk9XTT20GPqaq6MXYlJb+asVeSiWXyB8vkD4mUyeslsHep6o2q+p+aBkJELo9hXca0HAk0C5kxtTXmjuvabo9mIS1JSkpKvEuIOsvURKrw4x/D/v2xPxb2OflFImWqt+NaRC4ALgSuAJ4LeqsjcIqqDo5teY1jHdfGd0pK4Kyz4NVXYcSIeFdjWqhIOq43A0uBvcCyoMeLwPnRLLIlKS8vj3cJUWeZmmjWrNB/Y8w+J39IpEz1NhKqukJVpwN9gOdxxm+arqqzVfXrZqkwCQVPEJIsLFMTzZ7t/Dt3Lhw6FPPD2efkD4mUyWufxEiciYeKAEQkV0RejFVRxrQI770HNbOcffEFLFoU33qMCcNrI3EnMBjYDqCqZTj3Sxhjmqr2KaZmOuVkTGN4vU/igKpWO/MDmUjVzEGbTCxTGOvXw8GDdb9fu1GYPRt+9rO612/VCvr0iagk+5z8IZEyeW0kVonIVUBrEekL3AK8E7uyjEkCn30GV18NmzZ5W3/zZsjKCv9eaio89VTEjYQxjeX1dNPPgH7APuBZYAfw8xjVlPQWLlwY7xKizjKFkZ8PK1ZAQUFk+zn/fGc/UbhE1j4nf0ikTJ4aCVXdraq/wZmL+lxV/Y2q7o1tacYkgS5dnCuXpk6Fdu0at23btnDvvfDKK843CWPiwOsAf4NEZCXwAbBSRFaIyMDYlmZMErnpJliyBE45xdv6ffrAO+/AbbeB9QWaOPJ6uulx4EZVzVTVTOAm4ImYVZXksuo67+xjlsmDU0+FpUvhBz+of70zzoD334fTw94AGxH7nPwhkTJ5bSR2qmpgJjpVfRvYGZuSkl92dna8S4g6y+RR+/awfXv962zdCh06RP/Y2OfkF4mUqd5GQkQGiMgAYImI/FNE8kVkqIj8HShu6kFFJEtEyoIeO0Tk57XWyReR6qB1ftvU4yWaoqKieJcQdZbJo08+geXL61/nww9h5croHxv7nPwikTI1dAns/bVe/y7oeZMnHVLVCiAXQERaA5uAOWFWfUtVRzX1OIlq37598S4h6iyTR7XvjRCBCy90OqeDh+WYNcs5PRVl9jn5QyJlqreRUNVzm6GGYcB6Vd3QDMcyJr6CG4nu3Z17H4YPh4ULnXsqNm48vN6dd8alRGOCeZ7jOmYFiPwLWK6qU2stzwdmARtxRqO9TVVXh9l+IjARID09feDf//73wHs1dy0GX3OclZVFdnY2RUVFgda6U6dO5OfnU1ZWxoYNh9uqESNGUF1dzeLFiwPLcnJyyMzMpLCwMLAsNTWVIUOGUFpaSlVVVWB5QUEBlZWVrFixIrAsLy+PNWvWsHPn4S6djIwMcnNzKS4uDsxIlZKSwsiRIykvLw8Z7Msy+TdTv86d6XPuuaBK1YABLL/lFtpnZAQybV61itOmTiXNzfHl22/zzldfJXSmZPycWmKm0047rc6hwuPaSIjIUTgNQD9Vrar1XkfgkKruEpELgYdUtW99+7P5JExCe/hh55LWP/0JJk2q+9LWf/wDfvEL+O1v4Xab28vEXiTzScTaBTjfIqpqv6GqO1R1l/t8HtBWRI5v7gJjoaysLN4lRJ1l8mDlSnj3XacBqO/eh5/+1BkhNgbDRdvn5A+JlKnBRkJEuojIz0Tkb+7jZhHpEqXjj8MZ5iPccbuLO6KgiAx2a90apePGVfDX1WRhmTx46CEYMMDbuv37w7Rp0T0+9jn5RSJlaugS2JOBVcBA4ENgHTAI567riC7kFZGjgeHA7KBlN4jIDe7Ly3AGFlwB/BUYq/HuQDEmEu3bN279xg7jYUwMNHQJ7B+AW1X1+eCFInIpcDdwaVMPrKq7gS61lk0Lej4VmFp7O2OMMc2n3o5rEalQ1bD3h9f3Xrz4peN6z549tG/sX5UJzjL5g2Xyh+bOFEnH9TdNfM/Uo+YStmRimfzBMvlDImVqqJHoJiK/CPP4JdC1OQpMRsHXVCcLy+QPlskfEilTQ30SjwLH1vHeY1GuxRhjTIJpaFiO3zdXIcYYYxJPQ5fAPh/0/J5a782PVVHJLicnJ94lRJ1l8gfL5A+JlKmhPongYTCG13rP+iSaKDMzM94lRJ1l8gfL5A+JlKmhRqK+m9fsxrYmCh74K1lYJn+wTP6QSJka6rg+WkROw2lM2rvPxX0k14XJxhhjjtBQI7EF+Iv7/POg5zWvjTHGJLGGGonbVbW0WSppQVJTU+NdQtRZJn+wTP6QSJkaGpZjuap6HLYy/vwyLIcxxiSSSIblqGfQe9NUpaXJ9+XMMvmDZfKHRMrU0OmmXiLyYl1vquroKNfTIgRPX5gsLJM/WCZ/SKRMDTUSXwL3N0chxhhjEk9DjcQuVV3YwDrGGGOSVEMd17NVdUwz1hMR67g2xpjGi6Tj+k8i0j1oR9eKSKGI/FVEvhPVKluQysrKeJcQdZbJHyyTPyRSpoYaiX8C3wKIyDnAFOApoBp4JLalJa8VK1bEu4Sos0z+YJn8IZEyNdQn0VpVt7nPrwQeUdVZwCwRKYtpZcYYY+KuoW8SrUWkpiEZBrwZ9F5DDYwxxhifa6iReBZYKCKFwB7gLQAR6YNzyqlJRCRLRMqCHjtE5Oe11hG37+MjEflARHxz53dD8vLy4l1C1Fkmf7BM/pBImRqame5uEXkDSAPm6+FLoVoBP2vqQVW1AsgFEJHWwCZgTq3VLsCZz6IvkAf8w/3X9zp16hTvEqLOMvmDZfKHRMrU0DcJVLVUVeeo6jdByz5U1eVRqmEYsF5VN9RaXgA8pY5SoLOIpEXpmHE1f37yTepnmfzBMvlDImVKhH6FsTintWrrAXwW9Hqju2xL8EoiMhGYCJCenh4yWcfQoUMBWLjw8P2AWVlZZGdnU1RUxL59+wCn1c7Pz6esrIwNGw63VSNGjKC6uprFixcHluXk5JCZmRlynNTUVIYMGUJpaWnI7fQFBQVUVlaGXKlQ8zUyePuMjAxyc3MpLi6muto5i5eSksLIkSMpLy+noqLCMlkmy2SZYpapXqoatwdwFPAVkBrmvf8CZwW9fgMYWN/+Bg4cqH4wd+7ceJcQdZbJHyxTbFx33XXatWtX7devX2DZ1q1b9bzzztM+ffroeeedp9u2bQu898c//lF79+6tJ510khYVFQWWZ2Rk6Jdffqlz587VpUuXamZmpi5fvjzm9QNLtY7fqw2eboqxC4DlqhpuNKuNwHeDXvcENjdLVTGWkZER7xKizjL5g2WKjQkTJlBUVBSybMqUKQwbNox169YxbNgwpkyZAsCaNWuYMWMGq1evpqioiBtvvJGDBw+GbLtv3z4uu+wynnvuOU477bRmyxFOvBuJcYQ/1QTwInCte5XTEKBaVbfUsa6v5ObmxruEqLNM/mCZGufgwUM8+WQZeXmP0b793XTuPIVrr53D8uWhv4rOOeccvvOd0EEoCgsLGT9+PADjx49n7ty5geVjx44lJSWFXr160adPH5YsWRLYbu3atUyePJmnn36awYMHxyybV3FrJETkaGA4MDto2Q0icoP7ch7wMfAR8ChwY7MXGSPFxcXxLiHqLJM/WCbv9u8/yMUXP8d11xWyZMkm9u49QHX1Pp5++gPy8h7jP/9ZWe/2VVVVpKU519qkpaXxxRdfALBp0ya++93DJ0l69uzJpk2bAq8LCgqYOHEiZ511VgxSNV7cGglV3a2qXVS1OmjZNFWd5j5XVb1JVXur6qmqmjQj99V0PCUTy+QPlsm7e+4p4eWXPwz73oEDh5gwYS4bNmxv9H41zKCqIofndzvvvPMoLCw84hRUvMT7dJMxxiScAwcOMW1a/X+X7t9/iH/+c1md76emprJli3NaasuWLXTr1g1wvjl89tnhCzc3btxIenp64PXUqVMBuPHGxDh5Yo1EHKSkpMS7hKizTP5gmbz56KNtbNq0s8H1Fi6sfXvXYaNHj2b69OkATJ8+nYKCgsDyGTNmsG/fPj755BPWrVsX0vfQqlUrbr/9dioqKvjtb38bYZLIJcJ9Ei3OyJEj411C1Fkmf7BM0VVz6mjcuHEUFxfz1Vdf0bNnT37/+98zefJkrrjiCh5//HFOOOEEZs6cCUC/fv244oorOOWUU2jTpg1/+9vfaN26dch+R48ezdChQxk6dCipqancdNNNzZ6tRr2TDvmNXyYdKi8vJzs7O95lRJVl8gfL5M2BA4c44YQH2LJlV73r/frX32fKlPOiemxo/s8pkkmHTAwE3x2ZLCyTP1gmb9q0acUNN4T9ndmodZoqkT4naySMMSaMyZPPYuTIPmHfa91aePzx0WRmdm7eouLAGgljjAnjqKNa89JL43jkkVGcdlp3WrcWjjmmLWPH9qek5HquvTYn3iU2C+uTiIPt27fTuXPneJcRVZbJHyyTPzR3JuuTMMYY0yTWSMRB8BC+ycIy+YNl8odEymSNhDHGmDpZI2GMMaZOSdVxLSJfAnXfJ584jseZbCmZWCZ/sEz+0NyZMlS1a7g3kqqR8AsRWVrXlQR+ZZn8wTL5QyJlstNNxhhj6mSNhDHGmDpZIxEfj8S7gBiwTP5gmfwhYTJZn4Qxxpg62TcJY4wxdbJGwhhjTJ2skYgiERkpIhUi8pGITA7z/o9E5AP38Y6I5LjLvysiC0RkrYisFpFbm7/68JqaKej91iLyvoi83HxV1y+STCLSWUReEJFy9/M6o3mrr1uEuSa5/+2tEpFnRaRd81YfnodMBW6eMhFZKiJned02XpqaKW6/J1TVHlF4AK2B9cCJwFHACuCUWuucCRznPr8AWOw+TwMGuM+PBT6sva3fMgW9/wvgP8DL8c4TjUzAdOD/uM+PAjrHO1MU/vvrAXwCtHdfPw9M8EmmDhzuW/0eUO51Wx9misvvCfsmET2DgY9U9WNV/RaYARQEr6Cq76jq1+7LUqCnu3yLqi53n+8E1uL8jxtvTc4EICI9gYuAx5qpXi+anElEOgLnAI+7632rqtubq/AGRPRZ4cx3315E2gBHA5uboeaGeMm0S93fmsAxgHrdNk6anClevyeskYieHsBnQa83Uv8H+GPgldoLRSQTOA1YHM3imijSTA8CvwIORb2yposk04nAl8AT7im0x0TkmNiU2WhNzqWqm4D7gE+BLUC1qs6PUZ2N4SmTiFwiIuXAf4HrG7NtHESSKfj9TJrp94Q1EtEjYZaFvb5YRM7F+Z/017WWdwBmAT9X1R1Rr7DxmpxJREYBX6jqstiV1ySRfE5tgAHAP1T1NOAbIFHOdUfyWR2H89dsLyAdOEZEro5RnY3hKZOqzlHVbOBi4A+N2TYOIsnk7KCZf09YIxE9G4HvBr3uSZiv7CLyPZzTLwWqujVoeVucD/4ZVZ0d41q9iiTT94HRIlKJ85X6ByLy79iW60kkmTYCG1W15q+3F3AajUQQSa7zgE9U9UtV3Q/Mxum/iDdPmWqo6iKgt4gc39htm1EkmeLzeyLeHTnJ8sD5K/NjnL/Gajqk+tVa5wTgI+DMWssFeAp4MN45opWp1jr5JE7HdUSZgLeALPf5ncC98c4Uhf/+8oDVOH0RgtM5/zOfZOrD4U7eAcAmN0OD2/owU1x+T8T1B5ZsD+BCnCsO1gO/cZfdANzgPn8M+Boocx9L3eVn4Xzl/CDovQvjnSeSTLX2kTCNRKSZgFxgqftZzcW9WigRHhHm+j1QDqwCngZS4p3HY6Zf4zRwZcC7wFn1bZsIj6ZmitfvCRuWwxhjTJ2sT8IYY0ydrJEwxhhTJ2skjDHG1MkaCWOMMXWyRsIYY0ydrJEwxhhTJ2skTINE5KA7bPEqEZkpIkfXWr5CRJaLyBF36YpIpoisauTxJohIerTqby4icrGInBLB9p1F5MZo1uThmMUicnpzHtP4izUSxos9qpqrqv2Bb3Fu/AlengPcDvwpSsebgDOGkN9cDDS5kQA6A83aSCQ6d1RaE0fWSJjGegtn2IDaOuLczRtOGxGZ7k6k8kLQN5GBIrJQRJaJyKsikiYilwGnA8+431KGishsd/0CEdkjIkeJSDsR+dhd3ltEitz9vCUi2e7yriIyS0Tecx/fd5ffKSL/cv+K/lhEbglXtIiME5GV7jeoe4KW7wp6fpmIPOl+ixoN3OvW3dvd/4PiTPCzSkQGBx3/tqB9rHJH9ZyCM05PmYjc6/48FgV9izs7TI2/dbOtEpFHRETc5cUico+ILBGRD2u2FZH2IjLD/SyeA9rXkX2KiKxx17vPw89zuojMF5FKERkjIn92f3ZF7nhDYdVxnCdF5C8isgC4R0T6iMjrQd9Ye9e1PxMD8b5F3R6J/wB2uf+2AQqBn7qvD+IMDVAOVAMDw2ybiTOUwPfd1/8CbgPaAu8AXd3lVwL/cp8XA6cHHfMT9/l9wHs4gwcOBZ51l78B9HWf5wFvus//w+EhDU4A1rrP73SPnQIcD2wF2taqOx1n6Oyubg1vAhcH/zzc55cBT7rPnwQuC3qvGHjUfX4OsCro+LcFrbfK/Tll1qzjLv8lh4dtaA0cG+bn+52g508DPww69v3u8wuB193nvwj6OX8POFDzsw7eJ1DB4fGDOnv4eb7tfqY5wG7gAve9OTU/t3C113GcJ4GXgdbu68XAJe7zdsDR8f5/oiU97Kuc8aK9iJS5z9/CnXQH93QTgDjTeD4lIv3V/b85yGeqWuI+/zdwC1AE9Adec//4bY0zl0EIVT0gzjSPJ+NM2PIXnF+4rYG3xBk2+UxgprsfcH75gzO66SlByzuKyLHu8/+q6j5gn4h8AaTijNBZYxBQrKpfuvmecY87t56fUzjPujkWiUhHEenciG3fA/7l/iU+V1XLwqxzroj8Cmdwvu/gjPnzkvtezSihy3AaIHAy/NWt6QMR+SDMPncAe4HHROS/OL+wof6f5yuqul9EVuJ8NkXu8pVBx/Z6HICZqnrQ3X8PVZ3j1ry3jn2ZGLFGwngRaAzqoqrvijOccVfgi9pvh3ktwGpV9TJH9Fs4023uB17H+UuzNc43klbA9jrqawWcoap7ghe6v+T2BS06yJH/L4Qb9z+4/hoNzQUdLvsBQk/1ht2H27CcgzO739Micq+qPhUo0JmH+u843wQ+E5E7a+2rJmPtfPUO2OY2zIOBYcBY4GbgB3j4earqIRHZH/SHwiHq+D1Tz3HAmasD6v8cTDOwPgkTFW4/QGucUze1neB+0wAYh3NqogLoWrNcRNqKSD93nZ04c/jWWAT8HHjX/cu+C5CN08jsAD4Rkcvd/YiI5Ljbzcf5xVNTY24jIi0GhorI8SLS2q17oftelYicLCKtgEuCtqldNzin0RBnMvtqVa0GKnHnoRCRATjDRh+xvYhk4Ezc9CjOt7fac1fUNAhfud+oLvOQaxHwI3f//XFOOYVw99VJVefh/Nxz3bci+XkeoZ7jBLif70YRudjdJkXcPi3TPOybhIlE8GkoAcar6sEw660FxovIP4F1ODO7fStOJ/VfRaQTzn+LD+KcLnkSmCYie4AzcH5hp+L8ggNnqOQvgv5a/RHwDxG5A+e8+AyccfpvAf7mnlJp425fc2VWvVR1i4jcDixws81T1UL37ck4p0Y+w+lP6OAunwE8Kk5HeM0v7K9F5B2cjv2aaShnAde6P7v3cIaNRlW3ikiJOJcMv+Lu+39EZD+wC7i2Vo3bReRRnFM6le6+GvIPnOlXa4abXhJmnWOBQvebigCT3OVN/nnWoa7j1HYN8E8R+V+cb5OX48zJYJqBDRVuTIyISDFOB/XSeNdiTFPZ6SZjjDF1sm8SxpiYE5E5HO57qfFrVX01HvUY76yRMMYYUyc73WSMMaZO1kgYY4ypkzUSxhhj6mSNhDHGmDr9f4t6dQGDZrUYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ParaBART score to STED figure\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\"\"\"\n",
    "Scores to show for VGVAE[10, 25, 50, 75, 100, 435] and QKVAE:\n",
    "\n",
    "\"\"\"\n",
    "my_STED_syn = [7.6]\n",
    "my_STED_targ = [9.07]\n",
    "my_PB_sem = [0.27]\n",
    "my_PB_targ = [0.27]\n",
    "Last=True\n",
    "if Last:\n",
    "    n = ['10K', '25K', '50K', #'75', \n",
    "         '100K', #'200K', #'493K'\n",
    "         ]\n",
    "    sizes = [10, 25, 50, #75,\n",
    "                        100, #200, #493\n",
    "             ]\n",
    "    STED_syn = [10.17, 9.47, 8.18, #7.05, \n",
    "                6.87, #7.16, #3.34\n",
    "                ]\n",
    "    STED_targ = [11.12, 10.87, 9.85, #9.7, \n",
    "                 9.29, #9.54, #6.66\n",
    "                 ]\n",
    "    PB_sem = [0.21, 0.26, 0.32, #0.14, \n",
    "              0.31, #0.32, #0.58\n",
    "              ]\n",
    "    PB_targ = [0.21, 0.27, 0.32, #0.16, \n",
    "               0.32, #0.33, #0.58\n",
    "               ]\n",
    "else:\n",
    "    n = ['10K', '25K', '50K', #'75', \n",
    "         '100K', '200K', #'493K'\n",
    "         ]\n",
    "    sizes = [10, 25, 50, 100, 200]\n",
    "    STED_syn = [10.05, 9.15, 8.98, 8.91, 6.87]\n",
    "    STED_targ = [11.06, 10.43, 10.22, 10.35, 9.33]\n",
    "    PB_sem = [0.21, 0.26, 0.30, 0.28, 0.32]\n",
    "    PB_targ = [0.21, 0.26, 0.30, 0.28, 0.32]\n",
    "    \n",
    "z, y = PB_sem, STED_syn\n",
    "plt.scatter(z, y,\n",
    "               c = 'navy',#'['cyan', 'skyblue', 'blue', 'navy', 'black'],\n",
    "               s = sizes,\n",
    "               marker = 'o', edgecolors = 'none', label=\"VGVAE\")\n",
    "for i, txt in enumerate(n):\n",
    "    plt.annotate(txt, (z[i]+0.002,\n",
    "                       y[i]))#\"+0.05))\n",
    "plt.xlim(plt.xlim()[0], plt.xlim()[1]+0.005)\n",
    "plt.grid(linewidth=1, linestyle='--')\n",
    "\n",
    "plt.gca().set_axisbelow(True)\n",
    "plt.scatter(my_PB_sem, my_STED_syn,\n",
    "               c = 'red',#'['cyan', 'skyblue', 'blue', 'navy', 'black'],\n",
    "               s=493, marker = '*', edgecolors = 'none', label=\"QKVAE\")\n",
    "plt.legend(loc='upper right', markerscale=0.6)\n",
    "plt.xlabel(\"PB between outputs and sem_src\")\n",
    "plt.ylabel(\"STED between outputs and syn_src\")\n",
    "plt.savefig('PBvsSTED.pdf')\n",
    "# plt.plot([0, 4], [0, 8], color = 'red', linestyle = 'solid')\n",
    "# plt.title('styles variables et droite')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'STED between outputs and syn_src')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEKCAYAAADn+anLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAyZklEQVR4nO3deXhV1b3/8feXQUABUYQ0gBgERAQVmVosKoio9VIGRQSHC2q1irbWoRavPv3ZW2vxWuuELc7iBIgIUYuARRDEMUhEEDEiWEDKIFRBkfH7+2PvhJNwTrIznJyT5PN6nvOw99rT55xwsrL32nstc3dERETiqZXqACIikr5USYiISEKqJEREJCFVEiIikpAqCRERSUiVhIiIJKRKIknM7Akz22hmS2PKDjez180sL/z3sLC8j5m9GrPeHWY2y8zqpSK7iEg+VRLJ8xRwdpGyMcAcd28PzAnnCzGzW4GfAoPdfWeyQ4qIFMeq08N0RxxxhGdlZaU6RoGdO3fy+eef06lTJwCWLl1Khw4dqFu3Lrt372bFihV07tyZbdu2sWHDBho1asTWrVtp3749tWvXTnF6EakpFi1atNndm8VbVqeywyRTVlYWOTk5qY5RYPXq1QwYMKAgU5MmTfjoo48Klh922GHk5OQwb948hgwZQv369fnqq69o3LhxqiKLSA1kZl8mWqbLTWmiXbt2uDuzZ89OdRQRkQKqJCpRRkYG69evB2D9+vU0b9680LIZM2Zw/fXXM3fu3FRFFBEpRJVEJRo4cCATJkwAYMKECQwaNKjQ8mOOOYaXXnqJiy++mNzc3BQkFBEprFq1SaSTESNGMG/ePDZv3kyrVq34wx/+wJgxYxg2bBiPP/44rVu3ZsqUKQds16NHD5588kkGDhzI3Llzadu2bQrSi1R9u3fvZu3atfzwww+pjpI26tevT6tWrahbt27kbarV3U3du3f3dGq4FpHUWbVqFY0aNaJp06aYWarjpJy78/XXX7Nt2zbatGlTaJmZLXL37vG20+UmEamWfvjhB1UQMcyMpk2blvrMqkZXEsuWbWTNmm9SHUNEkkQVRGFl+TxqbCXxt799QOfOf+eYY8aRk/NVquOIiKSlGltJvPlm8OzIDz/s4d1316Y4jYhUV2vXrmXQoEG0b9+eo48+mmuvvZadO3cyb948BgwYULDebbfdxllnncUtt9zCLbfcUmgfubm5dOzYsWD+xBNPZMSIEYXWGTVqFG3atKFLly506dKFk08+uULy19hK4qabetGhQ1NOOaU1w4d3TnUcEUkD//rXN7zzzhp27txTIftzd84991wGDx5MXl4eeXl57Nixg5tvvrnQen/6059YuHAh06dPZ9SoUUyePLnQ8kmTJnHhhRcCsHz5cvbt28f8+fP57rvvCq139913k5ubS25uLm+//XaFvIcaewtsjx4t+fTTa1MdQ0TSwO7de7n00myef/5j3OGIIw7myScHMWDAMeXa7xtvvEH9+vW59NJLAahduzb33nsvRx11FP379wfgnnvuYcaMGcyaNYsGDRrQoUMHmjRpwnvvvcePf/xjAF544QVmzZoFwPPPP88ll1zC8uXLefnllw84o6hoNfZMQkQk3wMPvMdzzwUVBMDmzd8zYsRUvvmmfM9YLFu2jG7duhUqa9y4MVlZWXz++ecsXLiQ8ePH89prr9GwYcOCdUaMGMGkSZMAePfdd2natCnt27cHYPLkyVxwwQWMGDGCiRMnFtr3b3/724LLTRdddFG5sudTJSEiNd706SsOKNu+fRdz5qwq137dPe4dRfnPpyXqs2348OG8+OKL7Nu3j0mTJhWcLXzwwQc0a9aMo446in79+vHhhx+ydevWgu1iLzc999xz5cqeT5WEiNR4hx/eIG75YYfVL9d+O3XqdEDP1N9++y0bNmygQ4cOCftsO/LII8nKyuLNN99k6tSpDBs2DICJEyfy6aefkpWVRdu2bfn222+ZOnVquTKWRJWEiNR4117bg6J/8J94YgZ9+mSVa7/9+vXj+++/5+mnnwZg79693HjjjVx77bU0aBBUTIn6bBsxYgTXX389bdu2pVWrVuzbt48pU6awZMkSVq9ezerVq8nOzj7gklNFUyUhIjVe//5tmT59OCeffCStWx/KL35xErNmXVzuh/HMjGnTpvHiiy/Svn17mjZtSq1atbj11lsLrRfbZ9vKlSsBOP/881m2bBnDhw8HYP78+bRs2ZKWLVsWbHfqqafyySefFPQuHdsm0aVLF3bt2lWu/KC+m0Skmlq+fHmhZwvSwdtvv82IESN46aWXDmjQrizxPpeU9d1kZk+Y2UYzWxpTdr6ZLTOzfWYWN1S43tlmtsLMPjezA8aCFhGpak4++WS+/PLLlFUQZZHsy01PAWcXKVsKnAvMT7SRmdUGHgJ+BhwHjDCz45KUUUREEkhqJeHu84EtRcqWu/uB95sV1hP43N2/cPddwCRgUAnbiIhIBUvXhuuWwJqY+bVh2QHM7EozyzGznE2bNlVKOJFYa9asoW/fvnTs2JFOnTpx//33A3D77bfTsmXLgkbEGTNmACTss2fnzp0pyS9SnEjdcpjZIcAOd98XztcC6rv790nKFe+Wgrgt7O7+CPAIBA3XScojklCdOnW455576Nq1K9u2baNbt24FXS5cf/313HTTTQm3ze+zZ8aMGdSrV6+yIktx3nkHevVKdYq0EfVMYg5wcMz8wcA/Kz5OgbXAkTHzrQD15y1pKTMzk65duwLQqFEjOnbsyLp160rcLr/PnldeeaXgnnlJsRUr4I9/THWKtBK1kqjv7tvzZ8Lpg4tZv7w+ANqbWRszOwgYDrycxOOJVIjVq1ezePHigo7Zxo0bxwknnMBll11WqPuERH32SIpNnQpz5sA35R+MrE+fPgWd8uW77777GD16NHl5eQwYMIC2bdvSrVs3+vbty/z581m9enXBg3OxunTpwvvvvw/AvffeS/369fkmJuO8efM49NBDCz0j8c9/Vszf8VErie/MrGv+jJl1A3aUtJGZTQTeATqY2Vozu9zMhpjZWqAX8A8zmxWu28LMZgC4+x7gWmAWsBx4wd2XleaNiVS27du3c95553HffffRuHFjrr76alauXElubi6ZmZnceOONBesm6rNHUmzqVNi1C155pdy7iu2kL19+P0z/9V//xZVXXsnKlStZtGgRDz74IF988QVZWVkceeSRLFiwoGCbTz/9lG3bttGzZ08g6JqjR48eTJs2rdC+TznllIJ+m3JzcznjjDPK/R4gelfh1wFTzCz/kk8mcEFJG7l7oj5spxUtcPevgHNi5mcAMyLmE0mp3bt3c95553HRRRdx7rnnApCRkVGw/IorrijUWJ2RkcFzzz1Hv379aNq0KX379q30zDVeTg7E3iywZQt8+GEwPWECtGlTeP02baBFi8i7Hzp0KLfddhs7d+6kXr16rF69mq+++orPPvuMXr16MXDgwIJ1O3fuTOfOwbg2+ZXLaaedBlCog7+VK1eyfft27r77bu68805GjRpV+vddSiWeSYTPLJwCHAtcDYwGOrr7oiRnE6kS3J3LL7+cjh07csMNNxSU53eVADBt2rSCXwL5EvXZI5WkVi249FLo3Tt4xfzS5p//3F/euzdMnAiHH16q3Tdt2pSePXsyc+ZMIPhlf8EFF7Bs2bKCNqx4hg0bxvTp09mzJxj4aPLkyQVdc0ycOJERI0ZwyimnsGLFCjZu3Fiw3YIFCwpdbsrv3qO8Sqwk3H0vMMjdd7v7Unf/2N13V8jRRaqBhQsX8swzz/DGG28Uut315ptv5vjjj+eEE05g7ty53HvvvQdsG6/PHqkkXbsGZw4jRyZep2lTyM6GceOgful7hI295BR7RhBryJAhdO7cueAM9Ec/+hGdOnVizpw55ObmUrdu3YI/MCZNmsTw4cOpVasW5557LlOmTCnYT9HLTW3bti113niiXm5aaGbjgMlAwXh57v5hhaQQqcJ69+5NvD7QzjnnnDhrBw2affr0KZg/88wz+de//pWseFKchg3hqaegRw+4tshIlVlZ8NZb0DLuI1qRDB48mBtuuIEPP/yQHTt20LVrVxYvXsz8+fs7nJg2bRo5OTmFbpXOr1wyMjIKKpYlS5aQl5dXcHv1rl27OProo7nmmmvKnC+KqA3XJwOdgP8F7glff0lWKJFk2LVrL3v37it5Ral59sX5f7F5c3AmUQ4NGzakT58+XHbZZQW/7C+88EIWLlzIyy/vv2Hz++8LP3J23nnnMWPGjAMuNd1+++0F3YR/9dVXrFu3ji+//LJcGUsSqZJw975xXqcnNZlIBdmzZx+//OUrNGx4J82a3c24ce+nOpKkm/yBe446Cq66Csxg+3YocgtrWYwYMYKPPvqo4Jd9gwYNePXVVxk/fjxHH300vXr14o477uC2224r2KZJkyb85Cc/ISMjgzZhA/qkSZMYMmRIoX0PGTKk4HJW0TaJF198sdzZIWJX4WZ2HfAksA14FOgKjHH3tLp/T12FSzyPPrqIK698tVDZsmWjOe64ZilKJJUhclfhGzdCZiacdx488gg0aRI0XF9yCfTvD+GAQdVFsroKv8zdvwXOBJoDlwJjyxNUpLLk5Bz4sP6iRXqAX0KzZ8P48fDCC0EFAXDGGbBkCezdC7tr9n06USuJ/L6UzgGedPePiN+/kkja6du38P3uderU4pRTjkpRGkk7w4bBFVccWN6sGTz7bOXnSTNR725aZGazgTbALWbWCFALoFQJw4d35vPPtzB+fA6HHlqfP/6xL1lZTVIdSyqBu5c8BOlBByVeZgZ161ZsqBQqy0ikUdskagFdgC/c/T9m1hRo6e5LwuWd0qHbDLVJiEi+VatW0ahRI5o2bVrusaqrA3fn66+/Ztu2bQWN4fmKa5OIdCYRdhH+Ycz818DXMas8Q9CYLSKSFlq1asXatWvRODP71a9fn1atWpVqm6iXm0qialpE0krdunUP+ItZSq+iRqbTYD8iItVQug5fKiIiaaCiKoldFbQfERFJI5HbJMysJXBU7DbuPj/89ycVH01ERFItUiVhZncRDDL0CbA3LHZgfsKNRESkyot6JjEY6ODuO0taUUREqo+obRJfANXnsUMREYkk6pnE90Cumc0BCs4m3P3XSUklIiJpIWol8XL4EhGRGiRqJfE1MCPsnkNERGqIqG0Sw4E8M/s/M4swioeIiFQHUYcvvRg4CVgJPGlm75jZlWGX4SIiUk1FfuI6HJluKjAJyASGAB+a2a+SlE1ERFIsUiVhZj83s2nAGwS3wvZ0958BJwI3JTGfiIikUNSG6/OBe/O74cjn7t+b2WUVH0tERNJB1EriamAHgJkdAxwLvObuu919TrLCiYhIakVtk5gP1A87+ZsDXAo8laxQIiKSHqJWEubu3wPnAg+6+xDguOTFEhGRdBC5kjCzXsBFwD/Csooa+lRERNJU1EriOuAWYJq7LzOzo4G5yYslIiLpINLZQHhX0/yY+S8Ade4nIlLNaYxrERFJSJWEiIgkpEpCREQSKrZNwsweJBjLOi4NOiQiUr2VdCaRAywC6gNdgbzw1QXYm9RkIiKScsWeSbj7BAAzGwX0dffd4fx4YHbS04mISEpFbZNoAcSOHdEwLCuWmT1hZhvNbGlM2eFm9rqZ5YX/HpZg29Vm9rGZ5ZpZTsScIiJSgaJWEmOBxWb2lJk9BXwI3Blhu6eAs4uUjQHmuHt7gn6gxhSzfV937+Lu3SPmFBGRChT1Ybonzew14Mdh0Rh3/3eE7eabWVaR4kFAn3B6AjAP+F2UHCIiUrlKcwtsbWATsBU4xsxOLeMxM9x9PUD4b/ME6zkw28wWmdmViXYWDqOaY2Y5mzZtKmMkERGJJ9KZhJndBVwALAP2hcVOTFcdSfBTd//KzJoDr5vZp0UHPQJw90eARwC6d++e8HZdEREpvag9uQ4GOrj7zgo45gYzy3T39WaWCWyMt5K7fxX+uzEcOrUnya2URESkiKiXm74gGNu6IrwMjAynRwLZRVcws0PMrFH+NHAmsLToeiIiklxRzyS+B3LNbA5QcDZR0hPXZjaRoJH6CDNbC/w/gjulXjCzy4F/EYyfjZm1AB5z93OADGCameVnfN7dZ5bifYmISAWIWkm8HL5Kxd1HJFjUL866XwHnhNNfACeW9ngiIlKxot4COyHZQUREJP1EvbupPfBngnGt6+eXu/vRScolIiJpIGrD9ZPA34E9QF/gaeCZZIUSEZH0ELWSaODucwBz9y/d/Xbg9OTFEhGRdBC14foHM6sF5JnZtcA6Ej8pLSIi1UTUM4nfAAcDvwa6ARez/1kHERGppqLe3fRBOLkduDR5cUREJJ1ojGsREUlIlYSIiCSkSkJERBKKVEmY2f+ZWWMzq2tmc8xss5ldnOxwIiKSWlHPJM5092+BAcBa4Bjgt0lLJSIiaSFqJZHfTfg5wER335KkPCIikkaiPkz3ipl9CuwARptZM+CH5MUSEZF0EPVM4v8BvYDu7r6bYHyJgUlLJSIiaSFqJfGOu291970A7v4d8FryYomISDoo9nKTmf0IaAk0MLOTAAsXNSbopkNERKqxktokzgJGAa2Av8aUbwP+J0mZREQkTRRbSYQj0k0ws/PcfWolZRIRkTQR9e6mzmbWqWihu/9vBecREZE0ErWS2B4zXZ/gobrlFR9HRETSSdSuwu+JnTezvwAvJyWRiIikjbJ28HcwcHRFBhERkfQT6UzCzD4GPJytDTQD1B4hIlLNRW2TGBAzvQfY4O57kpBHRETSSNQ2iS/NrCvQm+CM4i1gcTKDiYhI6kUdT+L3wASgKXAE8JSZ3ZbMYCIiknpRLzeNAE5y9x8AzGws8CFwR7KCiYhI6kW9u2k1wfMR+eoBKys8jYiIpJWoZxI7gWVm9jpBm0R/4C0zewDA3X+dpHwiIpJCUSuJaeEr37yKjyIiIukmaiXRxN3vjy0ws+uKlomISPUStU1iZJyyURWYQ0RE0lBJgw6NAC4E2phZbF9NjYCvkxlMRERSr6TLTW8D6wmejYjt5G8bsCRZoUREJD2UNOjQl8CXQK/KiSMiIukkagd/29jfwd9BQF3gO3dvnKxgIiKSelH7bmoUO29mg4GeyQgkIiLpo0zjSbj7dOD0io0iIiLpJurlpnNjZmsB3dl/+am47Z4g6GZ8o7t3DssOByYDWQTdfQxz961xtj0buJ9g/IrH3H1slKwiIlJxop5J/DzmdRbB3U2DImz3FHB2kbIxwBx3bw/MCecLMbPawEPAz4DjgBFmdlzErCIiUkGitklcWpadu/t8M8sqUjwI6BNOTyDo4uN3RdbpCXzu7l8AmNmkcLtPypJDRETKJup4Eq3MbJqZbTSzDWY21cxalfGYGe6+HiD8t3mcdVoCa2Lm14Zl8bJdaWY5ZpazadOmMkYSEZF4ol5uehJ4GWhB8Mv6lbAsWSxOWdw2EHd/xN27u3v3Zs2aJTGSiEjNE7WSaObuT7r7nvD1FFDW38gbzCwTIPx3Y5x11gJHxsy3Ar4q4/FERKSMolYSm83sYjOrHb4upux9N73M/g4DRwLZcdb5AGhvZm3M7CBgeLidiEipZWVlcfzxx9OlSxe6d+8OwJYtW+jfvz/t27enf//+bN0a3GQ5b948BgwYULDtbbfdxllnncXOnTtTkj3VolYSlwHDgH8T9OU0NCwrlplNBN4BOpjZWjO7HBgL9DezPILBi8aG67YwsxkA7r4HuBaYBSwHXnD3ZaV5YyIisebOnUtubi45OTkAjB07ln79+pGXl0e/fv0YO/bAu+z/9Kc/sXDhQqZPn069evUqO3JaiHp307+AgaXdubuPSLCoX5x1vwLOiZmfAcwo7TFFRKLIzs5m3rx5AIwcOZI+ffpw1113FSy/5557mDFjBrNmzaJBgwYpSpl6UQcdEhGpssyMM888EzPjl7/8JVdeeSUbNmwgMzMTgMzMTDZu3N88unDhQlasWMGiRYto2LBhqmKnBVUSIlLtLVy4kBYtWrBx40b69+/PscceW+z67dq1Y+vWrcyePZuhQ4dWUsr0VKa+m0REqpIWLVoA0Lx5c4YMGcL7779PRkYG69evB2D9+vU0b77/ka2MjAxmzJjB9ddfz9y5c1OSOV1EfZiunpldaGb/Y2a/z38lO5yISHl99913bNu2rWB69uzZdO7cmYEDBzJhwgQAJkyYwKBBhXsaOuaYY3jppZe4+OKLyc3NrezYaSPq5aZs4BtgEVAz7wMTkSppw4YNDBkyBIA9e/Zw4YUXcvbZZ9OjRw+GDRvG448/TuvWrZkyZcoB2/bo0YMnn3ySgQMHMnfuXNq2bVvZ8VPO3EvszBUzW5rfi2s66969u+ff3iYiVcMbb6zi8ccXs2XLDs44ow1XXtmNRo1q5u2mqWJmi9y9e7xlUc8k3jaz49394wrMJSI13F//+g433ji7YH7mzM95+uklLFhwKY0bq6JIB1EbrnsDi8xshZktMbOPzWxJMoOJSPX2n//8wG23vXFA+ZIlG3jkkUUpSCTxRD2T+FlSU4hIjbNw4b/YsWNP3GWvv/4FN910ciUnknginUm4+5cEHe6dHk5/H3VbEZF4Djss8VPMhx1WvxKTSHGi3gL7/wgGBrolLKoLPJusUCJS/fXq1Ypjjz0i7rLLLjupktNIIlHPBoYQ9N30HRT0s9QoWaFEpPozM6ZNu4AOHZoWlNWvX4exY/tx5pk171bTdBW1TWKXu7uZOYCZHZLETCJSQxx77BEsX34NCxeuYcuWHfTu3ZrDD6+5nemlo6iVxAtm9jDQxMyuIOgm/NHkxRKRmsLM6N27dapjSAJRuwr/i5n1B74FOgC/d/fXk5pMRERSrjS9wH4GuLv/08wONrNG7r4tWcFERCT1ot7ddAXwIvBwWNQSmJ6kTCIikiai3t10DfBTgstNuHse0LzYLUREpMqLWknsdPdd+TNmVgcouWdAERGp0qJWEm+a2f8ADcIG7CnAK8mLJSIi6SBqJTEG2AR8DPwSmAHclqxQIiKSHqLe3dQHeM7d9WyEiEgNErWSGAWMN7OvgQXh6y1335qsYCIiknpRH6b7bwAzawEMBR4CWkTdXkREqqZIv+TN7GLgFOB4YDMwjuBsQkREqrGoZwL3ASuB8cBcd1+drEAiIpI+og46dARBp371gT+Z2ftm9kxSk4mISMpF7ZajMdAaOArIAg5FD9OJSA20Zs0a+vbtS8eOHenUqRP3338/AFu2bKF///60b9+e/v37s3Xr/vt6/vznP9OuXTs6dOjArFmzCsqzsrLYvHkzAIsWLaJNmzYsXry4ct9QCaI+J/EW8HNgCXCBu3fIb8wWEalJ6tSpwz333MPy5ct59913eeihh/jkk08YO3Ys/fr1Iy8vj379+jF27FgAPvnkEyZNmsSyZcuYOXMmo0ePZu/evYX2uWTJEoYOHcrkyZM56aT0GpUvaiVxh7uPdvfn3X0tgJmdn8RcIiJpKTMzk65duwLQqFEjOnbsyLp168jOzmbkyJEAjBw5kunTpwOQnZ3N8OHDqVevHm3atKFdu3a8//77Bftbvnw5gwcP5plnnqFnz56V/n5KUponrou6JU6ZiEiNsXr1ahYvXsyPf/xjNmzYQGZmJhBUJBs3bgRg3bp1HHnkkQXbtGrVinXr1hXMDxo0iHHjxtG7d+/KDR9RsXc3mdnPgHOAlmb2QMyixsCeZAYTESmLffucBQu+ZO3ab6lTpxYdOzbjhBMyKvw427dv57zzzuO+++6jcePGCddzP7D51swKps844wwee+wxzjrrLGrXrl3hOcurpDOJr4Ac4AdgUczrZeCs5EYTEYlu+/ZdjB37Fm3bPkCfPhO4+OJpDB8+lRNPHM9PfvIYzz67pMKOtXv3bs477zwuuugizj33XAAyMjJYv349AOvXr6d582A0hVatWrFmzZqCbdeuXUuLFi0K5seNGwfA6NGjKyxfRSq2knD3j9x9AtAOeAF4190nuPtL6pJDRNLFpk3fcdppT3HLLXNYvfo/Byx/7711XHLJNC65ZBp79+4r17Hcncsvv5yOHTtyww03FJQPHDiQCRMmADBhwgQGDRpUUD5p0iR27tzJqlWryMvLK9T2UKtWLSZOnMiKFSv4/e9/X65syRD1Ybqzgb8ABwFtzKwL8L/uPjBZwUREoti1ay8DBkzkww/Xl7jus88uoUmTejz44DllPt7ChQt55plnOP744+nSpQsAd955J2PGjGHYsGE8/vjjtG7dmilTpgDQqVMnhg0bxnHHHUedOnV46KGHDrisVK9ePbKzsznttNPIyMjgmmuuKXO+imbxrpcdsJLZIuB0YJ67nxSWLXH3E5Kcr1S6d+/uOTk5qY4hIpXoueeWcPHF0yKvX6uWsXLlr8nKapK8UFWMmS1y9+7xlkW9u2mPu39TgZlERCrE3/5Wuj8M9+1zHn5Yf0xGFbWSWGpmFwK1zay9mT0IvJ3EXCIiJVq/fhtvv72m5BWLePHF5UlIUz1FrSR+BXQCdgITgW+B3yQpk4hIJF9/vaOM231fwUmqr6gd/H3v7rcC/YC+7n6ru/9QngOb2XVmttTMlpnZb+Is72Nm35hZbvhKv2Z/EUmpBg3KNqRNgwZ1KzhJ9RV1PIkewBNAo3D+G+Ayd19UloOaWWfgCqAnsAuYaWb/cPe8IqsucPcBZTmGiFR/rVsfyo9+1JB//3t7qbbr2bNlkhJVP1EvNz0OjHb3LHfPAq4BnizHcTsSPHPxvbvvAd4EhpRjfyJSA9WtW5tf/KL0HeJdfXXcG3kkjqiVxDZ3LxiJzt3fAraV47hLgVPNrKmZHUzQ9ceRcdbrZWYfmdlrZtapHMcTkWrql7/sziGHRL981Llzc/r3PzqJiaqXYisJM+tqZl2B983s4bCd4DQz+xswr6wHdfflwF3A68BM4CMO7AvqQ+Aodz8ReBCYniDjlWaWY2Y5mzZtKmskEamiWrVqzOTJQznooJL7PcrMbEh29vBCfSdJ8Yp9mM7M5hazrbv76RUSwuxOYK27/62YdVYD3d19c6J19DCdSM01d+4qrr76H6xY8XXc5aef3oYnnhjIUUc1qdxgVUBxD9MV23Dt7n2TEwnMrLm7bzSz1sC5QK8iy38EbHB3N7OeBGc98X/6IlLj9e3bhk8/vZY33ljF009/xLp126hTpxbHHtuUK6/sRseOzVIdsUoq2/1jFWOqmTUFdgPXuPtWM7sKwN3HA0OBq81sD7ADGO5R+hARkRrt9NPbcPrpbVIdo9pIWSXh7qfEKRsfMz0OGFepoUREpJCodzeJiEgNVOKZRHhJ6ELg2LBoOTDR3dU+ICJSzZV0C2xHgmcaugGfAXlAD+BjMzu2uG1FRKTqK+ly0x+B69x9lLvf7+73uftIgg7//pT8eCIi5XPZZZfRvHlzOnfuXFC2ZcsW+vfvT/v27enfvz9bt+4faPPPf/4z7dq1o0OHDsyaNaugPCsri82bgzvwFy1aRJs2bVi8eHHlvZEUKamSON7dXyha6O5Tgc5x1hcRSSujRo1i5syZhcrGjh1Lv379yMvLo1+/fowdOxaATz75hEmTJrFs2TJmzpzJ6NGj2bt3b6FtlyxZwtChQ5k8eTInnVT6LkGqmpIqie/KuExEJC2ceuqpHH744YXKsrOzGTlyJAAjR45k+vTpBeXDhw+nXr16tGnThnbt2vH+++8XbLd8+XIGDx7MM888U2ic6uqspIbr5mZ2Q5xyA/RkiohUSRs2bCAzMxOAzMxMNm7cCMC6dev4yU9+UrBeq1atWLduXcH8oEGDePbZZ+ndu3flBk6hks4kHiXoHrzoqyHwWHKjiYhUrnjP68b283TGGWfw2GOPHXAJqjorqVuOP1RWEBGRypKRkcH69evJzMxk/fr1NG/eHAjOHNas2T8c6tq1a2nRokXB/Lhx47jqqqsYPXo0Dz/8cKXnToWSboF9IWb6riLLZicrlIjULHl5X7NkyQa2bdtZKccbOHAgEyZMAGDChAkMGjSooHzSpEns3LmTVatWkZeXV6jtoVatWkycOJEVK1bw+9/XjMEyS2qTaB8z3R/4Xcy82iREpFyefHIxf/nLO3zySdDN/yGH1OXCC4/njjtOp3nzQyrkGCNGjGDevHls3ryZVq1a8Yc//IExY8YwbNgwHn/8cVq3bs2UKVMA6NSpE8OGDeO4446jTp06PPTQQ9SuXbgL8nr16pGdnc1pp51GRkYG11xzTYXkTFcldRX+obt3LTodbz4dqKtwkarj1lvncOedb8Vd1rbtYbz99uUVVlFI8YrrKrykhuuDzewkM+sGNAinu+bPV3hSEakRlizZkLCCAFi5ciu33jqnEhNJIiVdbloP/DWc/nfMdP68iEipjR9f8hn/888v5Z57zqJx43qVkEgSKamSuMXd362UJCJSY3z88cYS1/n++92sXLmFk07KrIREkkhJl5sSDicqIlJW9etHG8qmQYO6SU4iJSmpktBo4SJS4QYOPKbEdTp0aEqHDk0rIY0Up6TqvI2ZvZxoobsPrOA8IlIDjBzZhTvuWMDGjYm7gLvxxl6FnnaW1CipktgE3FMZQUSk5mjcuB4zZlzIOec8H7ei+O1vT+aKK7qlIJkUVVIlsd3d36yUJCJSo3Tr1oLPPruWCRM+Ijt7BTt27Ob445tz1VXd1VidRkp6mO4ldz+3EvOUix6mExEpvfI8TPdnM/tRzI7+28yyzewBMzu8uA1FRKTqK6mSeBjYBWBmpwJjgaeBb4BHkhtNRERSraQ2idruviWcvgB4JBy6dKqZ5SY1mYiIpFxJZxK1zSy/IukHvBGzLNrTMCIiUmWVVElMBN40s2xgB7AAwMzaEVxyEqk6Xn0VNm1KdQqRKqWkken+ZGZzgExgtu+/FaoW8KtkhxOpUC+8AOvXwxVXpDqJSJVR4iWjeB38uftnyYkjkiS7dsErr8CGDaokREqhpMtNItXDnDnwn//A3LmwdWuq04hUGaokpGaYOjX4d/dueDlhd2QiUoQqCan+9u6F7Oz98/kVhoiUSJWEVH9vvgmbN++fnz0btm1LXR6RKkTPOkjVt3x50OaQyKuvFp7fuRPGjIGOHeOvX6sWjBgBhx1WcRlFqihVElL1dewYnB387ndBBRDF3xIMupiZCU8/rQpCJKTLTVI9XHcdvPsudOhQ9n2ccw589BGccUbF5RKp4lRJSPXRpQssWgSXXVa67Q46CO69N7gs1axZUqKJVFWqJKR6OeQQePxxmDQJDj205PU7dAjOQH7zG9BQmSIHUJuEVE8XXBBUGD//eeJ1ateGt9+GwzU0ikgiOpOQ6mvBguKX790L77xTOVlEqqiUVRJmdp2ZLTWzZWb2mzjLLRwB73MzW2JmXVMQU6qyKA/N6cE6kWKlpJIws87AFUBP4ERggJm1L7Laz4D24etK4O+VGlKqttxcWLly/3ytWnDzzTBwYOH1srNhz55KjSZSlaTqTKIj8K67f+/ue4A3gSFF1hkEPO2Bd4EmZpZZ2UGlioo9Q2jRAl5/He66K6gUHngA6tULlm3ZEnT6JyJxpaqSWAqcamZNzexg4BzgyCLrtATWxMyvDctESpZfSQwYEDz7cPrp+5f96lfw/vv7n7jWJSeRhFJSSbj7cuAu4HVgJvARUPScP979iF60wMyuNLMcM8vZpFHHBIJuOr74Au6/PxhD4ogjDlznhBMgJwd+8QuYPh327av0mCJVQcoart39cXfv6u6nAluAvCKrrKXw2UUr4Ks4+3nE3bu7e/dmehBKAJYtg/feg1//uvj1Dj4YHn0UHnwQli6tnGwiVUzKnpMws+buvtHMWgPnAr2KrPIycK2ZTQJ+DHzj7usrO6dUQUOHlm79889PTg6RasD2D1tdyQc2WwA0BXYDN7j7HDO7CsDdx5uZAeOAs4HvgUvdPaeEfW4Cvkxu8kiOADaXuFZqKWPFqQo5lbHiVIWcpc14lLvHvRSTskqiOjOzHHfvnuocxVHGilMVcipjxakKOSsyo564FhGRhFRJiIhIQqokkuORVAeIQBkrTlXIqYwVpyrkrLCMapMQEZGEdCYhIiIJqZIQEZGEVEmUgpmdbWYrwu7Lx8RZflHYrfkSM3vbzE4My480s7lmtjzsGv26dMsYs7y2mS02s1eTlbG8Oc2siZm9aGafhp9p0Qcx0yHj9eHPeqmZTTSz+inKOCjMlxt2X9M76rbpkDPNvjsJP8twedK/O+X8eZfte+PuekV4AbWBlcDRwEEE/U0dV2Sdk4HDwumfAe+F05lA13C6EfBZ0W1TnTFm+Q3A88Cr6fhZhvMTgF+E0wcBTdIpI0FHlKuABuH8C8CoFGVsyP62xxOAT6NumyY50+m7EzdjzPKkfnfKm7Gs3xudSUTXE/jc3b9w913AJILuzAu4+9vuvjWcfZegvyncfb27fxhObwOWk5webcucEcDMWgH/BTyWhGwVktPMGgOnAo+H6+1y9/+kU8ZQHaCBmdUBDiZOv2OVlHG7h78VgEPY30lmidumQ840++4k+iwr67tT5ozl+d6okoiutF2XXw68VrTQzLKAk4D3KjJcqLwZ7wNuBpLdJWp5ch4NbAKeDE/tHzOzQ9Ipo7uvA/4C/AtYT9Dv2OxUZTSzIWb2KfAP4LLSbJsGOWOXZ5Hi704xGe8j+d+d8mQs8/dGlUR0kbouBzCzvgS/NH5XpLwhMBX4jbt/W+EJy5HRzAYAG919URJyHXD4OGVRP8s6QFfg7+5+EvAdkIzr6eX5LA8j+AuvDdACOMTMLk5VRnef5u7HAoOBP5Zm2wpSnpzBDtLkuxMvYyV+d8rzOZb5e6NKIrpIXZeb2QkEp5yD3P3rmPK6BP/Jn3P3l9Iw40+BgWa2muA09nQzezYNc64F1rp7/l+TLxL850+njGcAq9x9k7vvBl4iaL9IScZ87j4faGtmR5R223IqT860+u4kyFhZ353y/rzL9r1JRgNLdXwR1MRfEPx1mN9o1KnIOq2Bz4GTi5Qb8DRwX7pmLLJOH5LbcF2unMACoEM4fTtwdzplJOjafhlBW4QRNBj+KkUZ27G/IbMrsC7MVOK2aZIznb47cTMWWSdp353yZizr9yZpH3p1fBEMs/oZwR0Gt4ZlVwFXhdOPAVuB3PCVE5b3JjgtXBKz7Jx0ylhkH0n7j14ROYEuQE74eU4nvMMozTL+AfiUYKjeZ4B6Kcr4O4IKKxd4B+hd3LYp/HnHzZlm352En2XMPpL63Snnz7tM3xt1yyEiIgmpTUJERBJSJSEiIgmpkhARkYRUSYiISEKqJEREJCFVElIiM9sb9iq51MymmNnBRco/MrMPzeyAB8bMLMvMlpbyeKPMrEVF5a8sZjbYzI4rx/ZNzGx0RWaKcMx5Zta9Mo8pVYsqCYlih7t3cffOwC6C+7Jjy08EbgH+XEHHG0XQnUVVMxgocyUBNAEqtZJId2EHiZJCqiSktBYQPNVZVGOCB8viqWNmE8J+7l+MORPpZmZvmtkiM5tlZplmNhToDjwXnqWcZmYvhesPMrMdZnaQmdU3sy/C8rZmNjPczwIzOzYsb2ZmU83sg/D107D8djN7Ivwr+gsz+3W80GY2wsw+Ds+g7oop3x4zPdTMngrPogYCd4e524b7v8+CsSaWmlnPmOPfFLOPpWHndWMJulHINbO7w89jfsxZ3ClxMv4+fG9LzewRM7OwfJ6Z3WVm75vZZ/nbmlkDM5sU/iwmAw0SvPexZvZJuN5fInyeE8xstpmtNrNzzez/ws9uZtitRlwJjvOUmf3VzOYCd5lZOzP7Z8wZa9tE+5MkSOZTlnpVjxewPfy3DpANXB3O7yV4svNT4BugW5xtswiemP1pOP8EcBNQF3gbaBaWXwA8EU7PA7rHHHNVOP0X4AOCvnJOAyaG5XOA9uH0j4E3wunn2f/kbmtgeTh9e3jsesARwNdA3SK5WxD04toszPAGMDj28winhwJPhdNPAUNjls0DHg2nTwWWxhz/ppj1loafU1b+OmH5jex/qrY20CjO53t4zPQzwM9jjn1POH0O8M9w+oaYz/kEYE/+Zx27T2AF+7tzaBLh83wr/JmeCHwP/CxcNi3/c4uXPcFxngJeBWqH8+8BQ8Lp+sDBqf5O1KSXTuUkigZmlhtOLyDsk57wchOABaNcPW1mnT38NsdY4+4Lw+lngV8DM4HOwOvhH7+1CbrVLsTd91gwCldHgv70/0rwC7c2sMCC3kFPBqaE+4Hglz8EHe0dF1Pe2MwahdP/cPedwE4z2whkEHSClq8HMM/dN4Xv77nwuNOL+ZzimRi+j/lm1tjMmpRi2w+AJ8K/xKe7e26cdfqa2c0E/UQdTtAlwyvhsvzO8BYRVEAQvIcHwkxLzGxJnH1+C/wAPGZm/yD4hQ3Ff56vuftuM/uY4GczMyz/OObYUY8DMMXd94b7b+nu08LMPyTYlySJKgmJoqAySMTd37Ggt8lmwMaii+PMG7DM3aMMobiAYOS33cA/Cf7SrE1wRlIL+E+CfLWAXu6+I7Yw/CW3M6ZoLwd+F+J1yxybP19Jw5LGe+97KHypN+4+worlVILBbJ4xs7vd/emCgMGQqH8jOBNYY2a3F9lX/nss+v6K7YsnrJh7Av2A4cC1wOlE+DzdfZ+Z7Y75Q2EfCX7PFHMcCLqyhuJ/DlIJ1CYhFSJsB6hNcOmmqNa2fzzdEQSXJlYAzfLLzayumXUK19lGMFRlvvnAb4B3wr/smwLHElQy3wKrzOz8cD9m+8eank3wiyc/Y5dSvKX3gNPM7Agzqx3mfjNctsHMOppZLWBIzDZFc0NwGQ0Lxhr+xt2/AVYTdtNsZl0JevU8YHszO4pgnIJHCc7einbtnF8hbA7PqIZGeF/zgYvC/XcmuORUSLivQ919BsHn3iVcVJ7P8wDFHKdA+PNda2aDw23qWdimJZVDZxJSHrGXoQwY6e5746y3HBhpZg8DeQQDn+yyoJH6ATM7lOD/4n0El0ueAsab2Q6gF8Ev7AyCX3AQ9GK5Meav1YuAv5vZbQTXxScRdKP8a+Ch8JJKnXD7/DuziuXu683sFmBu+N5muHt2uHgMwaWRNQTtCQ3D8knAoxY0hOf/wt5qZm8TNOznjxI2Ffjv8LP7gKBXT9z9azNbaMEtw6+F+/6tme0GtgP/XSTjf8zsUYJLOqvDfZXk7wSjk+X3qvp+nHUaAdnhmYoB14flZf48E0h0nKIuAR42s/8lOJs8n6DLbKkE6gVWJEnMbB5BA3VOqrOIlJUuN4mISEI6kxCRpDOzaexve8n3O3eflYo8Ep0qCRERSUiXm0REJCFVEiIikpAqCRERSUiVhIiIJKRKQkREEvr/qNCce1PYpSwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "z, y = PB_targ, STED_targ\n",
    "plt.scatter(z, y,\n",
    "               c = 'navy',#'['cyan', 'skyblue', 'blue', 'navy', 'black'],\n",
    "               s = sizes,\n",
    "               marker = 'o', edgecolors = 'none', label=\"VGVAE\")\n",
    "for i, txt in enumerate(n):\n",
    "    plt.annotate(txt, (z[i]+0.01, y[i]+0.05))\n",
    "plt.xlim(plt.xlim()[0], plt.xlim()[1]+0.03)\n",
    "plt.grid(linewidth=1, linestyle='--')\n",
    "\n",
    "plt.gca().set_axisbelow(True)\n",
    "plt.scatter(my_PB_targ, my_STED_targ,\n",
    "               c = 'red',#'['cyan', 'skyblue', 'blue', 'navy', 'black'],\n",
    "               s=493, marker = '*', edgecolors = 'none', label=\"QKVAE\")\n",
    "plt.legend(loc='upper right', markerscale=0.6)\n",
    "plt.xlabel(\"PB between outputs and sem_src\")\n",
    "plt.ylabel(\"STED between outputs and syn_src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
