{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b97e0f2e99bae8b9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset csv (C:\\Users\\ghazy\\.cache\\huggingface\\datasets\\csv\\default-b97e0f2e99bae8b9\\0.0.0\\2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words:  50265 , On device:  cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Type:  VAE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction net size: 140.31 M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x to z1 size: 140.05 M\nx to zst size: 140.31 M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model at step 947715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupervised training examples:  493080\nUnsupervised val examples:  500.0\nNumber of parameters:  281.25 M\nInference parameters:  179.54 M\nGeneration parameters:  140.31 M\nEmbedding parameters:  38.60 M\n"
     ]
    }
   ],
   "source": [
    "# This file will implement the main training loop for a model\n",
    "from time import time\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "from torch import device\n",
    "import torch\n",
    "from torch import optim\n",
    "from transformers import Adafactor\n",
    "import numpy as np\n",
    "\n",
    "from disentanglement_final.data_prep import NLIGenData2, OntoGenData, HuggingYelp2, ParaNMTCuratedData, BARTYelp, \\\n",
    "    BARTParaNMT, BARTNLI\n",
    "from disentanglement_final.models import DisentanglementTransformerVAE, LaggingDisentanglementTransformerVAE\n",
    "from disentanglement_final.h_params import DefaultTransformerHParams as HParams\n",
    "from disentanglement_final.graphs import *\n",
    "from components.criteria import *\n",
    "parser = argparse.ArgumentParser()\n",
    "from torch.nn import MultiheadAttention\n",
    "# Training and Optimization\n",
    "k, kz, klstm = 2, 4, 2\n",
    "parser.add_argument(\"--test_name\", default='unnamed', type=str)\n",
    "parser.add_argument(\"--data\", default='nli', choices=[\"nli\", \"ontonotes\", \"yelp\", 'paranmt'], type=str)\n",
    "parser.add_argument(\"--csv_out\", default='disentqkv3.csv', type=str)\n",
    "parser.add_argument(\"--max_len\", default=17, type=int)\n",
    "parser.add_argument(\"--init_len\", default=None, type=int)\n",
    "parser.add_argument(\"--batch_size\", default=128, type=int)\n",
    "parser.add_argument(\"--grad_accu\", default=1, type=int)\n",
    "parser.add_argument(\"--n_epochs\", default=20, type=int)\n",
    "parser.add_argument(\"--test_freq\", default=16, type=int)\n",
    "parser.add_argument(\"--complete_test_freq\", default=128, type=int)\n",
    "parser.add_argument(\"--generation_weight\", default=1, type=float)\n",
    "parser.add_argument(\"--device\", default='cuda:0', choices=[\"cuda:0\", \"cuda:1\", \"cuda:2\", \"cpu\"], type=str)\n",
    "parser.add_argument(\"--embedding_dim\", default=128, type=int)#################\"\n",
    "parser.add_argument(\"--pretrained_embeddings\", default=False, type=bool)#################\"\n",
    "parser.add_argument(\"--z_size\", default=96*kz, type=int)#################\"\n",
    "parser.add_argument(\"--z_emb_dim\", default=192*k, type=int)#################\"\n",
    "parser.add_argument(\"--n_keys\", default=4, type=int)#################\"\n",
    "parser.add_argument(\"--n_latents\", default=[4], nargs='+', type=int)#################\"\n",
    "parser.add_argument(\"--text_rep_l\", default=3, type=int)\n",
    "parser.add_argument(\"--text_rep_h\", default=192*k, type=int)\n",
    "parser.add_argument(\"--encoder_h\", default=192*k, type=int)#################\"\n",
    "parser.add_argument(\"--encoder_l\", default=2, type=int)#################\"\n",
    "parser.add_argument(\"--decoder_h\", default=int(192*k), type=int)################\n",
    "parser.add_argument(\"--decoder_l\", default=2, type=int)#################\"\n",
    "parser.add_argument(\"--highway\", default=False, type=bool)\n",
    "parser.add_argument(\"--markovian\", default=True, type=bool)\n",
    "parser.add_argument('--minimal_enc', dest='minimal_enc', action='store_true')\n",
    "parser.add_argument('--no-minimal_enc', dest='minimal_enc', action='store_false')\n",
    "parser.set_defaults(minimal_enc=False)\n",
    "parser.add_argument('--use_bart', dest='use_bart', action='store_true')\n",
    "parser.add_argument('--no-use_bart', dest='use_bart', action='store_false')\n",
    "parser.set_defaults(use_bart=False)\n",
    "parser.add_argument(\"--losses\", default='VAE', choices=[\"VAE\", \"IWAE\" \"LagVAE\"], type=str)\n",
    "parser.add_argument(\"--graph\", default='Normal', choices=[\"Vanilla\", \"IndepInfer\", \"QKV\", \"SQKV\", \"HQKV\", \"HQKVDiscZs\"],\n",
    "                    type=str)\n",
    "parser.add_argument(\"--training_iw_samples\", default=1, type=int)\n",
    "parser.add_argument(\"--testing_iw_samples\", default=5, type=int)\n",
    "parser.add_argument(\"--test_prior_samples\", default=10, type=int)\n",
    "parser.add_argument(\"--anneal_kl0\", default=3000, type=int)\n",
    "parser.add_argument(\"--anneal_kl1\", default=6000, type=int)\n",
    "parser.add_argument(\"--zs_anneal_kl0\", default=7000, type=int)\n",
    "parser.add_argument(\"--zs_anneal_kl1\", default=10000, type=int)\n",
    "parser.add_argument(\"--zg_anneal_kl0\", default=7000, type=int)\n",
    "parser.add_argument(\"--zg_anneal_kl1\", default=10000, type=int)\n",
    "parser.add_argument(\"--anneal_kl_type\", default=\"linear\", choices=[\"linear\", \"sigmoid\"], type=str)\n",
    "parser.add_argument(\"--optimizer\", default=\"adam\", choices=[\"adam\", \"sgd\"], type=str)\n",
    "parser.add_argument(\"--grad_clip\", default=5., type=float)\n",
    "parser.add_argument(\"--kl_th\", default=0., type=float or None)\n",
    "parser.add_argument(\"--max_elbo1\", default=6.0, type=float)\n",
    "parser.add_argument(\"--max_elbo2\", default=4.0, type=float)\n",
    "parser.add_argument(\"--max_elbo_choice\", default=6, type=int)\n",
    "parser.add_argument(\"--kl_beta\", default=0.3, type=float)\n",
    "parser.add_argument(\"--kl_beta_zs\", default=0.1, type=float)\n",
    "parser.add_argument(\"--kl_beta_zg\", default=0.1, type=float)\n",
    "parser.add_argument(\"--dropout\", default=0.3, type=float)\n",
    "parser.add_argument(\"--word_dropout\", default=0.4, type=float)\n",
    "parser.add_argument(\"--l2_reg\", default=0, type=float)\n",
    "parser.add_argument(\"--lr\", default=2e-4, type=float)\n",
    "parser.add_argument(\"--lr_reduction\", default=4., type=float)\n",
    "parser.add_argument(\"--wait_epochs\", default=1, type=float)\n",
    "parser.add_argument(\"--save_all\", default=True, type=bool)\n",
    "\n",
    "flags, _ = parser.parse_known_args()\n",
    "# Manual Settings, Deactivate before pushing\n",
    "\n",
    "if True:\n",
    "    # flags.optimizer=\"sgd\"\n",
    "    flags.use_bart = True\n",
    "    flags.batch_size = 10\n",
    "    flags.max_len = 40\n",
    "    flags.test_name = \"nliLM/ParaQKVBARTmini_beta0.3.0.3.1.8\" #ParaQKVBARTminiThr_beta0.2.0.2.1.8.pth\" \n",
    "    flags.data = \"paranmt\"\n",
    "    flags.n_latents = [8]\n",
    "    flags.graph =\"QKV\"  \n",
    "    flags.kl_beta = 0.3\n",
    "    flags.max_elbo_choice = 6\n",
    "    flags.kl_beta_zs = 0.3\n",
    "    flags.z_size = 192\n",
    "    \n",
    "if flags.use_bart:\n",
    "    flags.decoder_h = 768\n",
    "    flags.encoder_h = 768\n",
    "    flags.embedding_dim = 768\n",
    "\n",
    "\n",
    "if flags.anneal_kl_type == \"sigmoid\" and flags.anneal_kl0 < flags.anneal_kl1:\n",
    "    flags.anneal_kl0, flags.anneal_kl1 = 2000, 500\n",
    "    flags.zs_anneal_kl0, flags.zs_anneal_kl1 = 4000, 500\n",
    "    flags.zg_anneal_kl0, flags.zg_anneal_kl1 = 4000, 500\n",
    "\n",
    "\n",
    "if flags.use_bart and flags.optimizer == \"adam\": flags.optimizer = \"adafactor\"\n",
    "OPTIMIZER = {'sgd': optim.SGD, 'adam': optim.Adam, \"adafactor\": Adafactor}[flags.optimizer]\n",
    "OPT_KWARGS = {'sgd': {'lr': flags.lr, 'weight_decay': flags.l2_reg},  # 't0':100, 'lambd':0.},\n",
    "              'adam': {'lr': flags.lr, 'weight_decay': flags.l2_reg, 'betas': (0.9, 0.99)},\n",
    "              'adafactor': {'lr': flags.lr, 'relative_step': False,\n",
    "                            'weight_decay': flags.l2_reg}}[flags.optimizer]\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "GRAPH = {\"Vanilla\": get_vanilla_graph,\n",
    "         \"IndepInfer\": get_BARTADVAE if flags.use_bart else get_structured_auto_regressive_indep_graph,\n",
    "         \"QKV\": get_qkv_graphBART if flags.use_bart else get_qkv_graph2,\n",
    "         \"SQKV\": get_min_struct_qkv_graphBART if flags.use_bart else None,\n",
    "         \"HQKV\": get_hqkv_graphBART if flags.use_bart else get_hqkv_graph,\n",
    "         \"HQKVDiscZs\": get_hqkv_graph_discrete_zsBART if flags.use_bart else get_hqkv_graph_discrete_zs}[flags.graph]\n",
    "if flags.graph == \"NormalLSTM\":\n",
    "    flags.encoder_h = int(flags.encoder_h/k*klstm)\n",
    "if flags.graph == \"Vanilla\":\n",
    "    flags.n_latents = [flags.z_size]\n",
    "if flags.losses == \"LagVAE\":\n",
    "    flags.anneal_kl0 = 0\n",
    "    flags.anneal_kl1 = 0\n",
    "Data = {\"nli\": BARTNLI if flags.use_bart else NLIGenData2, \"ontonotes\": OntoGenData,\n",
    "        \"yelp\": BARTYelp if flags.use_bart else HuggingYelp2,\n",
    "        \"paranmt\": BARTParaNMT if flags.use_bart else ParaNMTCuratedData}[flags.data]\n",
    "MAX_LEN = flags.max_len\n",
    "BATCH_SIZE = flags.batch_size\n",
    "GRAD_ACCU = flags.grad_accu\n",
    "N_EPOCHS = flags.n_epochs\n",
    "TEST_FREQ = flags.test_freq\n",
    "COMPLETE_TEST_FREQ = flags.complete_test_freq\n",
    "DEVICE = device(flags.device)\n",
    "# This prevents illegal memory access on multigpu machines (unresolved issue on torch's github)\n",
    "if flags.device.startswith('cuda'):\n",
    "    torch.cuda.set_device(int(flags.device[-1]))\n",
    "LOSSES = {'IWAE': [IWLBo],\n",
    "          'VAE': [ELBo],\n",
    "          'LagVAE': [ELBo]}[flags.losses]\n",
    "\n",
    "ANNEAL_KL = [flags.anneal_kl0*flags.grad_accu, flags.anneal_kl1*flags.grad_accu]\n",
    "ZS_ANNEAL_KL = [flags.zs_anneal_kl0*flags.grad_accu, flags.zs_anneal_kl1*flags.grad_accu]\n",
    "ZG_ANNEAL_KL = [flags.zg_anneal_kl0*flags.grad_accu, flags.zg_anneal_kl1*flags.grad_accu]\n",
    "LOSS_PARAMS = [1]\n",
    "if flags.grad_accu > 1:\n",
    "    LOSS_PARAMS = [w/flags.grad_accu for w in LOSS_PARAMS]\n",
    "\n",
    "data = Data(MAX_LEN, BATCH_SIZE, N_EPOCHS, DEVICE, pretrained=flags.pretrained_embeddings)\n",
    "h_params = HParams(len(data.vocab.itos), len(data.tags.itos) if (flags.data == 'yelp' and not flags.use_bart)\n",
    "                   else None, MAX_LEN, BATCH_SIZE, N_EPOCHS,\n",
    "                   device=DEVICE, vocab_ignore_index=data.vocab.stoi['<pad>'], decoder_h=flags.decoder_h,\n",
    "                   decoder_l=flags.decoder_l, encoder_h=flags.encoder_h, encoder_l=flags.encoder_l,\n",
    "                   text_rep_h=flags.text_rep_h, text_rep_l=flags.text_rep_l,\n",
    "                   test_name=flags.test_name, grad_accumulation_steps=GRAD_ACCU,\n",
    "                   optimizer_kwargs=OPT_KWARGS,\n",
    "                   is_weighted=[], graph_generator=GRAPH, z_size=flags.z_size, embedding_dim=flags.embedding_dim,\n",
    "                   anneal_kl=ANNEAL_KL, zs_anneal_kl=ZS_ANNEAL_KL, zg_anneal_kl=ZG_ANNEAL_KL,\n",
    "                   grad_clip=flags.grad_clip*flags.grad_accu, kl_th=flags.kl_th, highway=flags.highway,\n",
    "                   losses=LOSSES, dropout=flags.dropout, training_iw_samples=flags.training_iw_samples,\n",
    "                   testing_iw_samples=flags.testing_iw_samples, loss_params=LOSS_PARAMS, optimizer=OPTIMIZER,\n",
    "                   markovian=flags.markovian, word_dropout=flags.word_dropout, contiguous_lm=False,\n",
    "                   test_prior_samples=flags.test_prior_samples, n_latents=flags.n_latents, n_keys=flags.n_keys,\n",
    "                   max_elbo=[flags.max_elbo_choice, flags.max_elbo1],\n",
    "                   z_emb_dim=flags.z_emb_dim, minimal_enc=flags.minimal_enc, kl_beta=flags.kl_beta,\n",
    "                   kl_beta_zs=flags.kl_beta_zs, kl_beta_zg=flags.kl_beta_zg, anneal_kl_type=flags.anneal_kl_type)\n",
    "val_iterator = iter(data.val_iter)\n",
    "print(\"Words: \", len(data.vocab.itos), \", On device: \", DEVICE.type, flush=True)\n",
    "print(\"Loss Type: \", flags.losses)\n",
    "if flags.losses == 'LagVAE':\n",
    "    model = LaggingDisentanglementTransformerVAE(data.vocab, data.tags, h_params, wvs=data.wvs, dataset=data,\n",
    "                                                 enc_iter=data.enc_train_iter)\n",
    "else:\n",
    "    model = DisentanglementTransformerVAE(data.vocab, data.tags, h_params, wvs=data.wvs, dataset=data)\n",
    "if DEVICE.type == 'cuda':\n",
    "    model.cuda(DEVICE)\n",
    "\n",
    "# Redefining examples lengths:\n",
    "if flags.init_len is not None:\n",
    "    data.redefine_max_len(flags.init_len)\n",
    "    h_params.max_len = flags.init_len\n",
    "\n",
    "total_unsupervised_train_samples = len(data.train_iter)*BATCH_SIZE\n",
    "total_unsupervised_val_samples = len(data.val_iter)*(BATCH_SIZE/data.divide_bs)\n",
    "print(\"Unsupervised training examples: \", total_unsupervised_train_samples)\n",
    "print(\"Unsupervised val examples: \", total_unsupervised_val_samples)\n",
    "number_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: \", \"{0:05.2f} M\".format(number_parameters/1e6))\n",
    "number_parameters = sum(p.numel() for p in model.infer_bn.parameters() if p.requires_grad)\n",
    "print(\"Inference parameters: \", \"{0:05.2f} M\".format(number_parameters/1e6))\n",
    "number_parameters = sum(p.numel() for p in model.gen_bn.parameters() if p.requires_grad)\n",
    "print(\"Generation parameters: \", \"{0:05.2f} M\".format(number_parameters/1e6))\n",
    "number_parameters = sum(p.numel() for p in model.word_embeddings.parameters() if p.requires_grad)\n",
    "print(\"Embedding parameters: \", \"{0:05.2f} M\".format(number_parameters/1e6))\n",
    "\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['how about sorcery?', 'get off of a hamburger!', \"you're not gon na get it.\"]\n"
     ]
    }
   ],
   "source": [
    "model.gen_bn.clear_values(), model.infer_bn.clear_values(), torch.cuda.empty_cache()\n",
    "model.beam_size = 3\n",
    "text, samples, params = model.get_sentences(3, gen_len=20, sample_w=False, vary_z=True, complete=None,\n",
    "                                            contains=None, max_tries=100)\n",
    "\n",
    "# text = [sen.split(model.eos_symbol)[0].replace(model.go_symbol, '') for sen in text]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 6.00 GiB total capacity; 4.25 GiB already allocated; 1.56 MiB free; 4.33 GiB reserved in total by PyTorch)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-b4cc4c666c84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0malt_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malt_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_alternative_sentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_latents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"====== Changing Structure=======\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-->\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'|<'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'><'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malt_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'>'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0malt_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malt_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_alternative_sentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_latents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\disentanglement_qkv\\models.py\u001b[0m in \u001b[0;36m_get_alternative_sentences\u001b[1;34m(self, prev_latent_vals, params, var_z_ids, n_samples, gen_len, complete)\u001b[0m\n\u001b[0;32m    713\u001b[0m         \u001b[1;31m#     x_prev = torch.cat([x_prev, torch.argmax(samples_i, dim=-1)[..., -1].unsqueeze(-1)],\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;31m#                        dim=-1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 715\u001b[1;33m         \u001b[0mx_prev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_z2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode_to_text2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerated_v\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\disentanglement_qkv\\models.py\u001b[0m in \u001b[0;36mgenerate_from_z2\u001b[1;34m(self, z_input, x_prev, gen_len, only_z_sampling, temp, mask_unk, beam_size, keep_beam)\u001b[0m\n\u001b[0;32m   1246\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1247\u001b[0m                 \u001b[0mz_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mz_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1248\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_bn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'x_prev'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mz_i\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_bn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_to_v\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1249\u001b[0m             \u001b[0munk_mask_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munk_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munk_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munk_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1250\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0monly_z_sampling\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\components\\bayesnets.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, n_iw, target, eval, prev_states, force_iw, complete, lens, plant_posteriors)\u001b[0m\n\u001b[0;32m    164\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapproximator\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprev_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprev_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m                     lv(self.approximator[lv], lv_conditions, gt_samples=gt_lv, complete=(lv in self.child) or complete,\n\u001b[1;32m--> 166\u001b[1;33m                        lens=this_len)\n\u001b[0m\u001b[0;32m    167\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrep_net\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m                         \u001b[0mlv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprev_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapproximator\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\components\\latent_variables.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, link_approximator, inputs, prior, gt_samples, complete, lens)\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sequential_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink_approximator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink_approximator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\components\\latent_variables.py\u001b[0m in \u001b[0;36m_forward\u001b[1;34m(self, link_approximator, inputs, prior, gt_samples, complete, lens)\u001b[0m\n\u001b[0;32m    268\u001b[0m                       torch.cat([v for k, v in inputs.items() if k not in link_approximator.residual['conditions']],\n\u001b[0;32m    269\u001b[0m                                 dim=-1))\n\u001b[1;32m--> 270\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlink_approximator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_log_probas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposterior_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\components\\links.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, z_prev, lens)\u001b[0m\n\u001b[0;32m   1063\u001b[0m         \u001b[0mload_BART_kv_hacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer_dec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1064\u001b[0m         outputs = self.transformer_dec(inputs_embeds=targets, encoder_hidden_states=memory,\n\u001b[1;32m-> 1065\u001b[1;33m                                        output_attentions=self.get_att)\n\u001b[0m\u001b[0;32m   1066\u001b[0m         \u001b[0mclear_BART_kv_hacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer_dec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_att\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1051\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m                     \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1053\u001b[1;33m                     \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1054\u001b[0m                 )\n\u001b[0;32m   1055\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinal_layer_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 6.00 GiB total capacity; 4.25 GiB already allocated; 1.56 MiB free; 4.33 GiB reserved in total by PyTorch)"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "alt_text, alt_samples = model._get_alternative_sentences(samples, params, [sum(h_params.n_latents)], 3, 20, complete=None)\n",
    "print(\"====== Changing Structure=======\")\n",
    "for i in range(len(text)):\n",
    "    print(\"-->\", text[i], '|<', '><'.join(alt_text[i::len(text)]), '>')\n",
    "alt_text, alt_samples = model._get_alternative_sentences(samples, params, list(range(sum(h_params.n_latents))), 3, 20, complete=None)\n",
    "print(\"====== Changing Content=======\")\n",
    "for i in range(len(text)):\n",
    "    print(\"-->\", text[i], '|<', '><'.join(alt_text[i::len(text)]), '>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== BEAM SIZE: 2 ==================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 6.00 GiB total capacity; 4.22 GiB already allocated; 1.56 MiB free; 4.33 GiB reserved in total by PyTorch)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-545e1488d069>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeam_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"========== BEAM SIZE: {} ==================\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m \u001b[0msw_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msw_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswap_latents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msw_zs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_unk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-545e1488d069>\u001b[0m in \u001b[0;36mswap_latents\u001b[1;34m(mdl, prev_latent_vals, var_z_ids, gen_len, complete, no_unk)\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[1;31m#     x_prev = torch.cat([x_prev, torch.argmax(samples_i,     dim=-1)[..., -1].unsqueeze(-1)],\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[1;31m#                        dim=-1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[0mx_prev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_z2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m             \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode_to_text2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerated_v\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'z1'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0morig_z\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\disentanglement_qkv\\models.py\u001b[0m in \u001b[0;36mgenerate_from_z2\u001b[1;34m(self, z_input, x_prev, gen_len, only_z_sampling, temp, mask_unk, beam_size, keep_beam)\u001b[0m\n\u001b[0;32m   1244\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1245\u001b[0m                 \u001b[0mz_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mz_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1246\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_bn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'x_prev'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mz_i\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_bn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_to_v\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1247\u001b[0m             \u001b[0munk_mask_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munk_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munk_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munk_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0monly_z_sampling\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\components\\bayesnets.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, n_iw, target, eval, prev_states, force_iw, complete, lens, plant_posteriors)\u001b[0m\n\u001b[0;32m    164\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapproximator\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprev_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprev_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m                     lv(self.approximator[lv], lv_conditions, gt_samples=gt_lv, complete=(lv in self.child) or complete,\n\u001b[1;32m--> 166\u001b[1;33m                        lens=this_len)\n\u001b[0m\u001b[0;32m    167\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrep_net\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m                         \u001b[0mlv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprev_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapproximator\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\components\\latent_variables.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, link_approximator, inputs, prior, gt_samples, complete, lens)\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sequential_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink_approximator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink_approximator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\components\\latent_variables.py\u001b[0m in \u001b[0;36m_forward\u001b[1;34m(self, link_approximator, inputs, prior, gt_samples, complete, lens)\u001b[0m\n\u001b[0;32m    268\u001b[0m                       torch.cat([v for k, v in inputs.items() if k not in link_approximator.residual['conditions']],\n\u001b[0;32m    269\u001b[0m                                 dim=-1))\n\u001b[1;32m--> 270\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlink_approximator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_log_probas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposterior_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Experiments\\GLUE_BENCH\\components\\links.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, z_prev, lens)\u001b[0m\n\u001b[0;32m    924\u001b[0m         \u001b[0mload_BART_kv_hacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer_dec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m         outputs = self.transformer_dec(inputs_embeds=targets, encoder_hidden_states=memory,\n\u001b[1;32m--> 926\u001b[1;33m                                        output_attentions=self.get_att)\n\u001b[0m\u001b[0;32m    927\u001b[0m         \u001b[0mclear_BART_kv_hacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer_dec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_att\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1051\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m                     \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1053\u001b[1;33m                     \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1054\u001b[0m                 )\n\u001b[0;32m   1055\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[1;31m# Fully Connected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation_dropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mgelu\u001b[1;34m(input)\u001b[0m\n\u001b[0;32m   1367\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1368\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgelu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1369\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 6.00 GiB total capacity; 4.22 GiB already allocated; 1.56 MiB free; 4.33 GiB reserved in total by PyTorch)"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "def swap_latents(mdl, prev_latent_vals, var_z_ids, gen_len, complete=None, no_unk=True):\n",
    "            has_struct = 'zs' in mdl.gen_bn.name_to_v\n",
    "            has_zg = 'zg' in mdl.gen_bn.name_to_v\n",
    "            \n",
    "            \n",
    "            n_orig_sentences = prev_latent_vals['z1'].shape[0]\n",
    "            n_samples = n_orig_sentences\n",
    "            go_symbol = torch.ones([n_samples * n_orig_sentences]).long() * \\\n",
    "                        mdl.index[mdl.generated_v].stoi[mdl.go_symbol]\n",
    "            go_symbol = go_symbol.to(mdl.h_params.device).unsqueeze(-1)\n",
    "            x_prev = go_symbol\n",
    "            if complete is not None:\n",
    "                for token in complete.split(' '):\n",
    "                    x_prev = torch.cat([x_prev, torch.ones([n_samples * n_orig_sentences, 1]).long().to(mdl.h_params.device) * \\\n",
    "                        mdl.index[mdl.generated_v].stoi[token]], dim=1)\n",
    "                gen_len = gen_len - len(complete.split(' '))\n",
    "            temp = 1.\n",
    "            orig_z = prev_latent_vals['z1'].unsqueeze(1).repeat(1, n_samples, 1)\n",
    "            z_sample = orig_z.reshape(n_samples*n_orig_sentences, -1)\n",
    "            orig_z = orig_z.transpose(0, 1).reshape(n_samples*n_orig_sentences, -1)\n",
    "            if has_struct:\n",
    "                orig_zst = prev_latent_vals['zs'].unsqueeze(1).repeat(1, n_samples, 1)\n",
    "                zst_sample = orig_zst.reshape(n_samples*n_orig_sentences, -1)\n",
    "                orig_zst = orig_zst.transpose(0, 1).reshape(n_samples*n_orig_sentences, -1)\n",
    "            if has_zg:\n",
    "                orig_zg = prev_latent_vals['zg'].unsqueeze(1).repeat(1, n_samples, 1)\n",
    "                orig_zg = orig_zg.transpose(0, 1).reshape(n_samples*n_orig_sentences, -1)\n",
    "            \n",
    "\n",
    "            for id in var_z_ids:\n",
    "                if id < sum(h_params.n_latents):\n",
    "                    z_number = sum([id> sum(h_params.n_latents[:i+1]) for i in range(len(h_params.n_latents))])\n",
    "                    z_index = id - sum(h_params.n_latents[:z_number])\n",
    "                    start, end = int(h_params.z_size/max(h_params.n_latents)*z_index),\\\n",
    "                                 int(h_params.z_size/max(h_params.n_latents)*(z_index+1))\n",
    "                    source, destination = [z_sample][z_number], [orig_z][z_number]\n",
    "                    destination[:, start:end] = source[:, start:end]\n",
    "                elif id == sum(h_params.n_latents) and has_struct:\n",
    "                    orig_zst = zst_sample\n",
    "                else:\n",
    "                    raise IndexError(\"You gave a too high z_id for swapping with this model\")\n",
    "                    \n",
    "            z_input = {'z1': orig_z.unsqueeze(1), **({'zs':orig_zst.unsqueeze(1)} if has_struct else {}), \n",
    "                       **({'zg':orig_zg.unsqueeze(1)} if has_zg else {})}\n",
    "            \n",
    "            x_prev = mdl.generate_from_z2(z_input, x_prev, beam_size=mdl.beam_size)\n",
    "            text = mdl.decode_to_text2(x_prev, mdl.h_params.vocab_size, mdl.index[mdl.generated_v])\n",
    "            return text, {'z1': orig_z}\n",
    "sw_zs = [16]\n",
    "model.infer_bn.clear_values(), model.gen_bn.clear_values()\n",
    "torch.cuda.empty_cache()\n",
    "model.beam_size = 3\n",
    "print(\"========== BEAM SIZE: {} ==================\".format(model.beam_size))\n",
    "sw_text, sw_samples = swap_latents(model, samples, sw_zs, 40, complete=None, no_unk=True)\n",
    "print(text)\n",
    "for i in range(len(text)):\n",
    "    for j in range(len(text)):\n",
    "        if i!=j:\n",
    "            print(\"z_from: \", text[i], \"|z_to: \", text[j], \"|result: \", sw_text[len(text)*i+j])\n",
    "model.beam_size = 1\n",
    "print(\"========== BEAM SIZE: {} ==================\".format(model.beam_size))\n",
    "sw_text, sw_samples = swap_latents(model, samples, sw_zs, 40, complete=None, no_unk=True)\n",
    "print(text)\n",
    "for i in range(len(text)):\n",
    "    for j in range(len(text)):\n",
    "        if i!=j:\n",
    "            print(\"z_from: \", text[i], \"|z_to: \", text[j], \"|result: \", sw_text[len(text)*i+j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:   0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:   5%|         | 1/19 [00:02<00:45,  2.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  11%|         | 2/19 [00:04<00:42,  2.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  16%|        | 3/19 [00:07<00:40,  2.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  21%|        | 4/19 [00:09<00:37,  2.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  26%|       | 5/19 [00:12<00:34,  2.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  32%|      | 6/19 [00:15<00:35,  2.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  37%|      | 7/19 [00:19<00:35,  2.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  42%|     | 8/19 [00:21<00:30,  2.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  47%|     | 9/19 [00:24<00:27,  2.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  53%|    | 10/19 [00:26<00:24,  2.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  58%|    | 11/19 [00:29<00:21,  2.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  63%|   | 12/19 [00:32<00:19,  2.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  68%|   | 13/19 [00:35<00:16,  2.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  74%|  | 14/19 [00:37<00:13,  2.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  79%|  | 15/19 [00:40<00:10,  2.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  84%| | 16/19 [00:43<00:08,  2.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  89%| | 17/19 [00:46<00:05,  2.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  95%|| 18/19 [00:48<00:02,  2.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences: 100%|| 19/19 [00:51<00:00,  2.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences: 100%|| 19/19 [00:51<00:00,  2.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n\rGetting Model Swap TMA:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  10%|         | 1/10 [00:06<00:54,  6.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  20%|        | 2/10 [00:12<00:49,  6.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  30%|       | 3/10 [00:18<00:43,  6.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  40%|      | 4/10 [00:25<00:37,  6.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  50%|     | 5/10 [00:31<00:31,  6.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  60%|    | 6/10 [00:37<00:24,  6.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  70%|   | 7/10 [00:43<00:18,  6.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  80%|  | 8/10 [00:50<00:12,  6.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  90%| | 9/10 [00:56<00:06,  6.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA: 100%|| 10/10 [01:03<00:00,  6.35s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA: 100%|| 10/10 [01:03<00:00,  6.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating zs tma...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\lib\\site-packages\\supar\\utils\\alg.py:522: UserWarning: This overload of nonzero is deprecated:\n\tnonzero()\nConsider using one of the following signatures instead:\n\tnonzero(*, bool as_tuple) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:766.)\n  return [sorted(i.nonzero().tolist(), key=lambda x:(x[0], -x[1])) for i in marginals.permute(3, 0, 1, 2)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating zc tma...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating copy tma...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating bleu scores...\n"
     ]
    }
   ],
   "source": [
    "scores3 = model.get_swap_tma(200, 10, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tma2': {'zs': 53.0, 'zc': 39.0, 'copy': 39.0}, 'tma3': {'zs': 23.0, 'zc': 10.0, 'copy': 5.0}, 'bleu': {'zs': 4.301619841342148, 'zc': 5.329606584392295, 'copy': 2.907042530089797}}\n{'tma2': {'zs': 52.0, 'zc': 27.0, 'copy': 28.000000000000004}, 'tma3': {'zs': 21.0, 'zc': 4.0, 'copy': 2.0}, 'bleu': {'zs': 4.837286465792402, 'zc': 1.06716549568883, 'copy': 4.533625890054019}}\n{'tma2': {'zs': 46.2, 'zc': 38.0, 'copy': 34.699999999999996}, 'tma3': {'zs': 15.4, 'zc': 4.7, 'copy': 9.2}, 'bleu': {'zs': 5.6330959118116475, 'zc': 1.500889607364273, 'copy': 4.732771442981089}}\n"
     ]
    }
   ],
   "source": [
    "print(scores)\n",
    "print(scores2)\n",
    "print(scores3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tma2': {'zs': 56.99999999999999, 'zc': 42.0, 'copy': 41.0}, 'tma3': {'zs': 23.0, 'zc': 8.0, 'copy': 6.0}, 'bleu': {'zs': 7.672990358203783, 'zc': 3.623395667548363, 'copy': 2.1395611292167582}} {'tma2': {'zs': 54.0, 'zc': 43.0, 'copy': 35.0}, 'tma3': {'zs': 26.0, 'zc': 8.0, 'copy': 5.0}, 'bleu': {'zs': 15.2429080729265, 'zc': 0.0, 'copy': 2.7638331671257435}}\n"
     ]
    }
   ],
   "source": [
    "print(scores1, scores3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:   0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:   5%|         | 1/19 [00:03<01:01,  3.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  11%|         | 2/19 [00:06<00:55,  3.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  16%|        | 3/19 [00:09<00:50,  3.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  21%|        | 4/19 [00:12<00:46,  3.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  26%|       | 5/19 [00:15<00:44,  3.17s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  32%|      | 6/19 [00:18<00:40,  3.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  37%|      | 7/19 [00:21<00:36,  3.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  42%|     | 8/19 [00:24<00:32,  2.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  47%|     | 9/19 [00:27<00:29,  2.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  53%|    | 10/19 [00:29<00:26,  2.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  58%|    | 11/19 [00:32<00:23,  2.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  63%|   | 12/19 [00:35<00:20,  2.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  68%|   | 13/19 [00:38<00:17,  2.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  74%|  | 14/19 [00:41<00:14,  2.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  79%|  | 15/19 [00:44<00:11,  2.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  84%| | 16/19 [00:47<00:08,  2.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  89%| | 17/19 [00:50<00:05,  2.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences:  95%|| 18/19 [00:53<00:02,  2.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences: 100%|| 19/19 [00:56<00:00,  2.99s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGenerating original sentences: 100%|| 19/19 [00:56<00:00,  2.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n\rGetting Model Swap TMA:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  10%|         | 1/10 [00:01<00:14,  1.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  20%|        | 2/10 [00:03<00:13,  1.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  30%|       | 3/10 [00:06<00:13,  1.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  40%|      | 4/10 [00:07<00:11,  1.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  50%|     | 5/10 [00:09<00:09,  1.81s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  60%|    | 6/10 [00:11<00:07,  1.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  70%|   | 7/10 [00:13<00:05,  1.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  80%|  | 8/10 [00:14<00:03,  1.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA:  90%| | 9/10 [00:16<00:01,  1.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA: 100%|| 10/10 [00:18<00:00,  1.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rGetting Model Swap TMA: 100%|| 10/10 [00:18<00:00,  1.84s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating zs tma...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating zc tma...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating copy tma...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating bleu scores...\n"
     ]
    }
   ],
   "source": [
    "scores1 = model.get_swap_tma(200, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ParaBART score to STED figure\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\"\"\"\n",
    "Scores to show for VGVAE[10, 25, 50, 75, 100, 435] and QKVAE:\n",
    "\n",
    "\"\"\"\n",
    "my_STED_syn = [7.6]\n",
    "my_STED_targ = [9.07]\n",
    "my_PB_sem = [0.27]\n",
    "my_PB_targ = [0.27]\n",
    "Last=True\n",
    "if Last:\n",
    "    n = ['10K', '25K', '50K', '75', \n",
    "         '100K', #'200K', #'493K'\n",
    "         ]\n",
    "    sizes = [10, 25, 50, 75,\n",
    "                        100, #200, #493\n",
    "             ]\n",
    "    STED_syn = [10.17, 9.47, 8.18, 7.05, \n",
    "                6.87, #7.16, #3.34\n",
    "                ]\n",
    "    STED_targ = [11.12, 10.87, 9.85, 9.7, \n",
    "                 9.29, #9.54, #6.66\n",
    "                 ]\n",
    "    PB_sem = [0.21, 0.26, 0.32, 0.14, \n",
    "              0.31, #0.32, #0.58\n",
    "              ]\n",
    "    PB_targ = [0.21, 0.27, 0.32, 0.16, \n",
    "               0.32, #0.33, #0.58\n",
    "               ]\n",
    "else:\n",
    "    n = ['10K', '25K', '50K', #'75', \n",
    "         '100K', '200K', #'493K'\n",
    "         ]\n",
    "    sizes = [10, 25, 50, 100, 200]\n",
    "    STED_syn = [10.05, 9.15, 8.98, 8.91, 6.87]\n",
    "    STED_targ = [11.06, 10.43, 10.22, 10.35, 9.33]\n",
    "    PB_sem = [0.21, 0.26, 0.30, 0.28, 0.32]\n",
    "    PB_targ = [0.21, 0.26, 0.30, 0.28, 0.32]\n",
    "    \n",
    "z, y = PB_sem, STED_syn\n",
    "plt.scatter(z, y,\n",
    "               c = 'navy',#'['cyan', 'skyblue', 'blue', 'navy', 'black'],\n",
    "               s = sizes,\n",
    "               marker = 'o', edgecolors = 'none', label=\"VGVAE\")\n",
    "for i, txt in enumerate(n):\n",
    "    plt.annotate(txt, (z[i]+0.002,\n",
    "                       y[i]))#\"+0.05))\n",
    "plt.xlim(plt.xlim()[0], plt.xlim()[1]+0.005)\n",
    "plt.grid(linewidth=1, linestyle='--')\n",
    "\n",
    "plt.gca().set_axisbelow(True)\n",
    "plt.scatter(my_PB_sem, my_STED_syn,\n",
    "               c = 'red',#'['cyan', 'skyblue', 'blue', 'navy', 'black'],\n",
    "               s=493, marker = '*', edgecolors = 'none', label=\"QKVAE\")\n",
    "plt.legend(loc='upper right', markerscale=0.6)\n",
    "plt.xlabel(\"PB between outputs and sem_src\")\n",
    "plt.ylabel(\"STED between outputs and syn_src\")\n",
    "plt.savefig('PBvsSTED.pdf')\n",
    "# plt.plot([0, 4], [0, 8], color = 'red', linestyle = 'solid')\n",
    "# plt.title('styles variables et droite')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'STED between outputs and syn_src')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "z, y = PB_targ, STED_targ\n",
    "plt.scatter(z, y,\n",
    "               c = 'navy',#'['cyan', 'skyblue', 'blue', 'navy', 'black'],\n",
    "               s = sizes,\n",
    "               marker = 'o', edgecolors = 'none', label=\"VGVAE\")\n",
    "for i, txt in enumerate(n):\n",
    "    plt.annotate(txt, (z[i]+0.01, y[i]+0.05))\n",
    "plt.xlim(plt.xlim()[0], plt.xlim()[1]+0.03)\n",
    "plt.grid(linewidth=1, linestyle='--')\n",
    "\n",
    "plt.gca().set_axisbelow(True)\n",
    "plt.scatter(my_PB_targ, my_STED_targ,\n",
    "               c = 'red',#'['cyan', 'skyblue', 'blue', 'navy', 'black'],\n",
    "               s=493, marker = '*', edgecolors = 'none', label=\"QKVAE\")\n",
    "plt.legend(loc='upper right', markerscale=0.6)\n",
    "plt.xlabel(\"PB between outputs and sem_src\")\n",
    "plt.ylabel(\"STED between outputs and syn_src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
